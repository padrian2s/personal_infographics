Hello everyone. Today we have Terrence Tao here again. Uh it's an honor to have the chance to interview him again. &gt;&gt; Okay.

&gt;&gt; And we're going to be talking about the application of AI for science, especially with the Sarah kickoff in just a few days. Now we are excited to bring a few new perspectives to how AI may be used in science and what we can do about it moving forward. So if you don't mind if you could introduce yourself really quickly that'd be great. &gt;&gt; Okay.

So I'm Terrence Tao. I'm a profess professor of mathematics here at UCLA. um and um in traditionally I mean um I've been interested in pure mathematics uh but I've gotten more and more involved in um new ways to do mathematics and more broadly new ways to do science uh using AI and other technologies. Um so um recently I got involved with uh several other um um scientists and donors to uh to help found SE this new foundation uh to uh um to support um AI for science different ways new ways to to integrate um these new technologies into scientific workflows and we're having our first uh kickoff event in a in a few days here at IPAM institute for pure black mathematics at UCLA.

&gt;&gt; Thank you. And I think this may be a question for a lot of people. What made you decide to want to co-ound sir? &gt;&gt; Well, it was a combination of of many things.

So, uh, as I said, in the past few years, I've uh um, you know, I've I've I've increasingly become convinced that uh that these technologies are now ready to uh to transform science and and we have to be ready and prepared to uh to to to uh to adopt them. Um but &gt;&gt; and we we need to learn how to do it the right way and the wrong and to avoid doing it the wrong way. And unfortunately there are many many more wrong ways to incorporate AI than correct ways. So we do need to do it correctly.

Um and the um academic community has to be really involved. Uh we can't just wait for the tech companies to give us a product uh and and we'll just use it. Um uh I mean uh I we we need to really interact and and and and learn what what we really need. Um what types of science will AI help and what types um um will human methods um continue to be to to work just fine.

Um and then um in the last year in particular um yeah simultaneously with that um there was suddenly a lot of funding uncertainty um with um um so IPAM for example where I'm I'm a director of special projects uh we we had a a suspension of um of our funding um and a lot of the the programs we were planning to run uh was not actually clear we could actually run them. Uh so um it was it was it was time to find new sources of funding and and reach out to to many new uh investors and uh and partners. Um so uh the silver lining of all that chaotic period is is that we now have a lot of new initiatives at IPAM um including um this uh the partnership with &gt;&gt; that's great and I think that for mathematics specifically AI is just exceptionally powerful. Would you agree that's the case?

I think there's exceptionally there's an exceptional potential. Um so the big Achilles heel of modern AI tools large large language models in particular is that they are sarcastic and um they they produce excellent answers some of the time but complete rubbish um other parts of the time. They they're not grounded by reality. They are stat statistically matching um what they think is is a good answer and sometimes they give extremely good answers.

Um so what so because of this um the use cases of AI in many other disciplines have been a lot less um um they've turned out to to to be um not as as uh satisfactory as as we had first hoped uh because of this unreliability issue. Um but mathematics almost uniquely among all applications we we we have a very wellhoned um ability to verify outputs. So if if you give me a mathematical proof or a claimed proof of of a mathematical statement, we have the laws of logic and the laws of mathematics, we can check whether the argument is correct or not. And now we can even do that by computer.

We have we have these formal proof assistant languages that that do that automatically. Um and this keeps the AI honest in a way that uh it's it's it's harder to do in in in any other discipline. Um so uh mathematics has the has the best shot at filtering out all the bad use cases of AI and and keeping the um the good ones. It it's not perfect.

Not every aspect of mathematics can be formally verified. Um proofs are an important part of mathematics but um there are um other things for um if you want to try to propose new conjectures or um um or explain things in in in in a clear way. Um there are many math tasks that um um AI may not be good at yet, but at least at least for some of what we do um there's a lot of potential. &gt;&gt; Mhm.

Yeah, I I can definitely see that. And one thing you mentioned was uh programs to verify the work of AI. Correct. And as programs like that emerge and develop, do you think there will be a point where we can have a program robust enough to where we can have AI continuously generate ideas and have them be verified to create something new rather than be limited to what we already have planned out.

&gt;&gt; Yeah. Um that's that that is the hope. Uh so currently um if you ask an AI to generate ideas it it um um it will generate all kinds of random things and maybe a small percentage of them are actually interesting um but um we can't verify an idea um yet um but um we may be able to borrow some some some tricks from the u the physical sciences. Um so you know if if a if a physicist or chemist comes up with a hypothesis they can run experiments and try to gather evidence for the hypothesis not exactly a proof or disprove but you there are ways to become more convinced or less convinced &gt;&gt; that hypothesis is true.

Um I do see mathematics acquiring much more of an experimental side to it than we have currently. So currently math is almost entirely theoretical. Um but with AI um AI could propose um hypotheses and then maybe it could also propose experiments to test these hypotheses. Um you you may propose that some formula is true for all natural numbers.

You test a few numerical ones. You you find other special cases. You check whether it's compatible with with some other facts in the literature. And um it's this this type of use case is still in its infancy.

Um again because we don't have um the ability to verify um yet whether these things work or not um progress is much uh more holding but um as our work you know as our expertise of using AI properly matures u I can I can see that happening but still maybe that's 10 years away. &gt;&gt; Yeah. Uh honestly much better than I was thinking. 10 years sounds far but honestly in terms of research that's not too bad.

&gt;&gt; The the pace has been faster than I expected. I mean there are people who were I mean had really really skyhigh expectations. They thought by now um mathematicians be obsolete or science be obsolete. Um but it is um you know already we can you know AIs can can can already prove um um um theorems that that um that hadn't been proven before usually by by standard techniques.

Um and it can discern some patterns that that we didn't see before. It is still very unreliable. Um uh but uh the potential is there but we we need to research how to use it properly and how not to. &gt;&gt; Yeah.

And I think something Yeah. excels in is really structured repetition. Something it has &gt;&gt; uh very strict uh strict instructions to do and something it can repeat. And I mean the the point of it is to save us time so we can work on something that's more &gt;&gt; difficult for it something that's more creative.

&gt;&gt; Right. Yeah. they are different from humans and um it is maybe it's a a slight shame that that's somehow the current marketing of AI is is I mean even the name artificial intelligence sounds like you know it is an um a replacement for a human being but um humans do not like to do these very repetitive tasks &gt;&gt; you know you know like in math you maybe they would solve the first or second if you give them a set of a thousand problems you know maybe they'll do the first one one or two &gt;&gt; but then it that's um it's great to then just hand off to the AI that you do the other 998. Um and so um yeah, this this is I think um again maybe in 10 years this will change but but but in the near term the the division of labor that's most natural is is that you know um the human starts a mathematical project say here are the first few steps.

Here's what I think should happen. Um and then the AI takes that that sketch and fleshes it out, does all the grunt work. Um and uh it could it could massively accelerate um existing workflows. &gt;&gt; Yeah, I mean it's uh at the end of the day it's a tool, right?

And it's there to help us simplify a lot of processes. &gt;&gt; But I think another thing about AI is that what do you think we could do about when it comes up with seemingly random explanations, right? Because what a lot of AI does is it comes up with plausible answers or something that seems like it could be right but realistically a lot of it is nonsense. &gt;&gt; Right.

&gt;&gt; How do you think we can improve on that? &gt;&gt; Right. So um [clears throat] right so in mathematics um the um um the best thing we have we have found so far to to deal with that is formal formal verification. So we um the AI can first come up with a natural language argument which could be correct, could not be correct, but then we will ask either the same AI or different AI to convert that into a formal language.

Every single claim that um has to be converted into this precise language which will be um verified by a very strict compiler which is not an AI. It is a traditional reliable um piece of software. Um I mean it is it is designed specifically to be extremely extremely reliable. um we have never found a major major bug in um in in the compilers of of the major premises and languages.

Um and so um um so if it passes that test then if it doesn't pass that test we we we we ask the AI to try again. If it does pass the test then then we have this big long AI generated &gt;&gt; um formal proof which may not be so easily readable. Um but actually you can then go in reverse you can ask another AI to explain it. Um but also the nice thing about um these formal proofs is is that um every single step in the proof is very precise.

Um and so um you you can just manually break up this big theorem into into pieces &gt;&gt; and each piece you can you can study separately. Um &gt;&gt; so um once once you have the formal proof you know even if it's thousands of lines um it um you can actually analyze it you know so either with a combination of humans or AI. Um so it's um yeah we've had many examples already where an AI generated a proof that we first didn't understand but we kind of decompiled the uh um the proof that it it generated um and and someone found a human explanation of what was going on. &gt;&gt; Um so far every time an AI has sort of wowed us oh that proof came out of nowhere um we have found after a few days of study that actually there was a paper somewhere in the literature that did something similar.

Um so where where has an advantage one of the advantages AI has over humans um is is that it can absorb the entire literature um you know it doesn't directly memorize everything it doesn't there's not enough memory or weights in in in the AI to do that but it has somehow absorbed the essence of a lot of tricks um so a human mathematician may know &gt;&gt; you know be very good at you know maybe four or five tricks to solve a certain problem but but the AI may know like a dozen tricks it may not apply them um properly all the time. Sometimes it will fail, but um but it has it has breadth um and that's that is is very powerful at least as long as you're only doing things that were already in the literature. Um &gt;&gt; what we haven't seen yet um is an AI like come up with an idea which has no precedent in um right &gt;&gt; in in the prior literature. But then again, most human mathematicians struggle to do that too.

Yeah, it's a it's definitely a difficult thing, especially when a lot of [clears throat] AI is referencing existing information. &gt;&gt; And I mean that brings me to my next question, right? Is what would you consider as a major milestone for AI? Would it be something to do with how it thinks, something to do with how it understands what we give it?

Is it to do with application? &gt;&gt; Right. Uh so there are many things uh still lacking that um we would we would love to see. So yeah so so one is is &gt;&gt; um yeah creativity that cannot be traced back to to prior literature.

Um another is um some kind of um like like really continuous learning tuned on a specific um um uh body of knowledge you know. So um the current AI the capability has been compared to yeah so I myself had compared um current AI capability math to that of a math graduate student. Um you know they they they know a lot and they um um they know the set of techniques they try them sometimes they work some sometimes they succeed sometimes they fail. Um but one thing about um human graduate students is that if they try something and they fail, we can talk about it and say this is where you went wrong.

Um and they learn not to make that mistake again and you you and then so next week when you have this um you you meet the student again, they would they will avoid that mistake. &gt;&gt; But uh an AI you start a fresh session of your AI forgotten everything number four. you can keep the previous conversations in context and it it it sort of briefly remembers not to do something but um it's it's it's not reliable. Um &gt;&gt; and in fact sometimes uh um it um there's there's a well-known quirk of AI that if you if you tell an AI not to do something you'll sometimes do it um they'll still do it.

&gt;&gt; Yeah. They'll still do it more often even. &gt;&gt; Um so um yeah and the AI that you use is just this general purpose AI that's trained on everything. um you can't yet kind of distill an AI just to do mathematics, &gt;&gt; right?

&gt;&gt; Um you know um the same way that you know graduate students can specialize in one area of study and and and um yeah so we haven't really gained the ability to specialize in AI. You can fine-tune a little bit but it's it's not um anywhere near uh the capabilities that we want. Um and um but I think the thing that I I most want to see is is a really good robust way to integrate AI into our workflows. Um so you know currently we we're juryrigging all kinds of ways to use AI you know so you know we we write our papers and then suddenly we're stuck and so we go to a browser and open up a chatbot or something and we do an AI.

Um some of you have tried giving the you know making an AI an agent giving it control of your of of your computer which is a bad idea actually but um for many reasons but um &gt;&gt; um it it it isn't um u like it isn't yet fully like a co-author you know like you know like when you when you're working with a human collaborator you know you can talk at a blackboard and you can you can write equations know you can chat with AI is a little bit similar but it it doesn't quite have the uh same integrated feel that you know We we we've we know we have polished over centuries how we work with other humans. Uh and we haven't quite figured out the best way to work with with with AI yet. &gt;&gt; If you had to say what do you think is really missing in that workflow progress? &gt;&gt; Um I'm I'm not that's a good question actually.

Um it's probably something intangible. Uh it it is a little bit like how during co we we all switched to to remote meetings and &gt;&gt; um and you know you could say that it um these remote meetings work just fine because you know I mean um if you just want to talk why why why does it make a difference whether we are we are on a on a zoom screen or whether we're in person &gt;&gt; um but there's there's something intangible about um um talking in person like we are now like why are we talking together and that was a good question and not by Zoom you There's eye contact, there's there's there's um um you know, body language. Um and um so when you talk of a human, you know, the the actual words that you're saying to each other or the equations you're writing on the board, they're just one part of the conversation. There's &gt;&gt; there's other things going on um which are somehow not captured uh when you interact with with an with an AI.

&gt;&gt; That's fair. Yeah. I think another part of it is just mutual cooperation with other people. It feels more interactive than it does with an AI.

But &gt;&gt; yeah. &gt;&gt; Yeah. Yeah. No, the the temptation for AI companies is to present kind of a like a oneshot um &gt;&gt; uh finished product, you know.

So the type of products that they want to to present are things like where you push a button and the AI produces the entire solution. &gt;&gt; Um but you yourself are not involved in the process of creating the solution. Um so uh if you then have to explain the solution to somebody else, you can't explain it. It's just this is just this this thing AI gave or you want to modify it, you have no choice but just go back to the AI and says please can you can can you change it and every time it changes it becomes slightly worse.

Um so um yeah as you say um we um ideally you want a more interactive experience where you know u you do a step and then an AI takes the next step and then maybe uh you offer some feedback and there's a course correction and as long as you interact um you get an understanding of how the proof developed um and so when a human writes a proof uh solves a problem human can explain the thought process uh what what what kinds of ideas they were trying um what inspirational literature there was. But when an AI generates these uh these these proof artifacts, um sometimes it doesn't come with any record of where this proof came from. It's just a solution. Um and sometimes we realize that that's only part of what we wanted.

We didn't just want the answer. We actually wanted the process as well. Um so um but if once we can find ways to integrate AI and maybe the trick is is you know maybe AI is is is like um it's like salt you know like you know a little bit of salt makes makes makes makes makes food taste better but you you don't just dump as much salt as possible onto your food you know this you use it when as when appropriate and you don't use it when it's not. Yeah, that sounds great to me.

And I think even just research in general is not always about getting to the solution right away. It's always seemingly a very long process where you need to iterate on what you already have and sometimes you might not even get to the solution, &gt;&gt; right? Yeah. So, um, humans are actually, um, pretty bad at specifying goals correctly.

Um so um thing about AI is that they're a little bit too good at fulfilling goals. Um they're kind of like a genie that grants your wish very very literally. &gt;&gt; So you know you say you know I I I want to to um to optimize this this metric or you know I want to solve this problem &gt;&gt; and so it will it will spend lots of compute and and and effort to do exactly what you ask for. Um so you know often you you will find um yeah so like if I ask to to formalize a proof in in some formal proof assistant language and just do whatever it takes to to to make to to get a proof you'll find that it cheats like it will create axioms it will change definitions um it it will do all kinds of of things to to satisfy to the letter the thing that you required &gt;&gt; so we are learning that when we give tasks to AI um especially tasks that require like really precise um uh specifications you know, you have to describe everything.

Um, you know, you have to make sure there's no loopholes and you have to think clearly about what you really really wanted. Um, um, you know, so it it's it's it um yeah, so in the case of proof set, it's not always just the solution. We want understanding like uh we want like for example, how it connects with the with the rest of the literature. What other problems can we now solve?

Um, yeah, how can we explain this result to to to uh to others? Um yeah, so we we um in the past we didn't have to think so much about precise goals because when you ask a human to do something they will usually do not just exactly what what you asked them to but &gt;&gt; all the other things that that implicitly you also wanted them to do as well. Um you know like if if you know if you ask someone for for some tea you know they will not just pour some tea on you right they'll give you a cup and a plate and you know if you don't explicitly ask for these other things they they understand why you know all this extra context &gt;&gt; um so AI sometimes understands context but sometimes it doesn't um so um yeah we have to get better at at at um specifying our goals to um to get the best use AI. &gt;&gt; I think that's a very interesting perspective too is that AI is very focused on answering the question rather than making sure it's gotten what's everything right.

&gt;&gt; Yeah. &gt;&gt; And maybe I don't know for sure but maybe that is the problem behind what's currently hindering it. &gt;&gt; Yeah. Well, I mean that that's the whole machine learning philosophy.

I mean it didn't used to be like that. I mean, so so AI traditionally um was was not based on goals so much, but but but um early AI which was trying to to build reasoning systems that that mimicked human thought &gt;&gt; and they really struggled um like it was they could only do very basic tasks and um and then at some point people um try the opposite approach where you just specify a goal and you you try whatever it takes without it doesn't matter how stupid or or how illogical but you you just try to max to optimize whatever metric measures your distance goal. And uh people found that this just well it initially didn't work very well but if you add more and more compute and data and scaling it it just gets better and better and suddenly it um it it you pass a threshold it becomes actually quite good. Um um but uh it only but it it can sometimes it's too good.

It it it just it exactly optimizes your metric. You know, there's lots of stories of machine learning of you ask an AI to to to to beat a computer game and it will always find the exploits, you know, some way to to uh to exploit a bug in in in in in the code or, you know, not the spirit of what it meant. But, you know, but it does fulfill exactly what you asked it for. [clears throat] &gt;&gt; Mhm.

&gt;&gt; Okay. Yeah. And I think for my last bit of question is just what do you think people tend to mistake about using AI in science? Um yeah so most to for most people um AI modern AI is is the chat bots you know so you talk to them and and they they can say oh that's an excellent observation you do this &gt;&gt; um and and they they will they would tell things that makes you feel good or whatever.

Um and so some scientists do use the chat bots to to help to help think um but um um the most productive uses of um AI for science are actually rather different. Uh yeah so often coupled with with verification you just or like I often use it just to do numeric plot this compute this check this argument. Um yeah it's it the way scientists use AI is a little bit different from um the way the public uses AI. We don't generate lots of cute images for example is is not so useful &gt;&gt; right &gt;&gt; um yeah so unfortunately AI is lumped together into this single technology it's not really one technology it's it's it's it's hundreds of related technologies um and yeah so unfortunately it's it's uh the ones that have the most prominence are actually not the ones that we use the most in science so &gt;&gt; um maybe it's we should just have better naming like not call everything AI &gt;&gt; maybe yeah I think that would be that would be good.

I mean out there you already have sort of generative you have the LMS and then you have algorithms etc. But I think generally speaking for the public they are &gt;&gt; very hard focused on just the AI part of AI rather than what the differences are or what it's used for how it even functions. I think that's the most important part is how it functions, right? Because that fundamentally changes what it's doing and how accurate it is, which in this case &gt;&gt; I think is a very big thing.

&gt;&gt; Yeah. I mean, neuronets, I mean, that's a 20-y old technology. They're not as sexy as these modern LLMs, but but actually scientists have used them for years and and they're great. Um, and you know, there's no text interface.

You know, you just, you know, um ways to to to find patterns in data. Um and and it's a &gt;&gt; yeah so I mean they do they do great data science with neuron nets. Um but it's it's it's it's a very boring mundane you know it's it's just number crunching it. It doesn't um it's it's it's not like you it doesn't feel like talking to to um you know data or or some some some sci-fi robot or anything.

&gt;&gt; Yeah. &gt;&gt; Okay. I think that wraps it up. Thank you very much for coming once again.

Second interview. Very nice. &gt;&gt; Was a pleasure. Yeah.

&gt;&gt; Okay. Great. Cool.