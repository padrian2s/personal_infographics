Good morning everyone. My name is Techco. I'm the director of IPAM and I'm also professor of mathematics here. It's a great great pleasure to welcome all of you here to IPAM for this event that we're doing jointly with the S foundation. Um just a few words about uh us and what what this event is about. So, IPAM is one of several NSF funded math institutes in the United States. Uh, IPAM has a mission to make connections through mathematics. So, we run a variety of programs uh from uh a day long to

several months long. Focus on all kinds of areas that involve mathematics in one way or another. This could be programs in mathematics itself or programs that connect mathematics to other things. Um, so, uh, of course, it's all about AI nowadays. Um and of course AI is a fantastic thing that is going to have a huge effect on just about everything we do. Uh how we do science, how we do higher education. And so, um, we, um, Chuck, uh, who, uh, um, uh, got connected to us, uh, about about a year

a about half a year ago, this summer had this vision to create, uh, a forum for us to be able to make connections between, uh, science, between industry, uh, between and kind of have mathematics as the foundation of all of this. And so came this idea of having a foundation, the S foundation. And I think Chuck will say a few words about that. Uh which is uh a charitable uh organization that is trying to enable progress in in using AI for everything. So of course IPAM is a very natural place to do this. We've

been a player in AI space for many many years. In fact, I was looking back and uh in 2011, so what 15 years ago, we had a program that started doing machine learning in uh physics of materials and material science. And then we had a summer school that I think Stan uh co-organized with people like Yan Lun and and and so forth uh who uh uh you know really started uh the the or ended the AI winter and since then we've had many many programs of various kinds but this event is unique because we really would like to provide

space for people to make connections between ideas that lie in science ideas that lie in AI ideas that lie in industry and get a conversation going. So, um I'm also very grateful to um uh Miguel uh who uh is our dean of physical sciences and um UCLA is getting very very entrepreneurial. Uh we are uh going to plan a research park. Um and so part of of this and I think the physical sciences is one of the more entrepreneurial divisions at UCLA and part of it is is really to enable our faculty to give us uh a possibility of

exploring all kinds of uh ideas uh in commercialization of anything uh be it scientific ideas but also you know ideas from higher education which of course by necessity is undergoing a huge change and that explains kind of the three panels that we're going to have a panel on AI and mathematics, a panel on AI uh uh for industry and uh AI in higher ed. Um and then um I just want to uh give lots of thanks first and for foremost to our friends at Sarah Foundation, Chuck uh and then the rest of the organizers

of this event uh Terry uh Miguel u also a huge thanks to all the staff uh that have helped us put together the S foundation but also IPAN staff uh that have have been really amazing. Um for those of us joining uh uh the live stream uh welcome. Um we uh if you are in the UCLA uh Zoom there will potentially be possibility for you to ask questions. You should just raise your hand and then somebody will unmute you uh during the panels or during the Q&A. Um I think that's all in terms of the

practical things. Oh just to remind people we will be catering lunch. So um after the I guess first panel we will have a lunch break. So you can just stick around and enjoy and enjoy us. I think that's all the things I wanted to say. Let me just hand it over to Chuck who will say a few words about the S foundation. Thanks. >> Well, thank you very much and welcome everyone. Uh really happy that everyone is actually here joining us for this exciting uh full day event. I I want to acknowledge uh you know uh just also my

very po very much uh important host IPAM and as well as a so thank you so much for the partnership here uh we are very excited because we actually have speakers participants guests coming all over the country as a matter of fact all over the world as well as uh you know certainly thank you for bone capital for being a sponsor for munch uh you know I really as I said emphasize G me me me me me me me me me me me me me me me me me me me me me mentioned about how important it is uh in this critical time

working together academia industry uh you know the entrepreneurial community as well as you know founders and don donors and philanthropists working together and you know on this particular effort uh I you know I I've also I think one word to describe myself those who know me I've actually seen my life lifetime journey of building bridges uh and So I'm really excited that we're building bridges between industry and academia, building bridges between researchers and entrepreneurs, building bridges in our

post culture and global community. So uh certainly why it's here now uh you know of course it comes uh uh a very critical time uh as of course everybody as you know uh already Dimma mentioned about the rapid rise of AI and how that's shaping science shaping economies and shaping our society uh and so we really need a trusted scientifically grounded uh AI uh has never been more important than now and our mission uh really has been you know two core ideas right one is AI for science and science for AI and

to go you know as I said before it's bring researchers industry entrepreneurs uh funding private funding together to build an ecosystem that benefits all of humanity so in closing this is just the beginning right uh you know it's uh our this is our first step a much uh longer larger uh effort and so thank you thank you thank you and thank you for those who on on you know being on the uh online because this is actually broadcasted uh through our partners uh uh partners globally uh to actually to millions of

viewers so so you guys are the privileged uh few that's joining us in person here so I want to say thank you so much and thank you for uh you know having all of you again uh joining us and and um excited for the program. All right, Muel Dina turn back to you. >> Thank you so much. So uh thank you for the kind words and again thank you all for coming. So um I guess we should just it's a little early but I guess it is what it is. Um so Terry, you might be able to have a few more minutes for your

talk. It's a great great pleasure to be introducing uh our wonderful colleague ter who will be talking about machine assisted machine assistance in the future of research mathematics. >> Thank you so much. >> Thank you. >> So welcome. I'm very excited about this this event and uh all the new connections we can make just I think IPAM is all about building connections and uh this this is a a great venue to discuss a really important topic. So um yeah so I'll be talking about uh how

math is changing. I think uh this is it um you know we've seen it sort of uh the hype build up over the last few years of how uh you know AI and other tools are becoming more and more capable in math and and other tasks. But this is this is the year where I think it's really beginning to happen. Um, and you know, oops. And you know, to be honest, math is kind of overdue for for some reform because um, in many ways, um, we we are we are an extremely uh conservative um, not in the political sense, but but in in in in

the sense of practice. Um, I just give you two examples here. So, so um so here is a memoir from almost exactly 200 years ago 201 um introducing uh well most of of foundational complex analysis um kashi integral formula for example um and the book is is written in French and not in latte but um other than that it is almost identical to a textbook that you would see today. I mean the the way we teach mathematics has chang has has has changed only in sort of uh secondary ways but um you know I mean um yeah a

graduate student studying complex sciences would basically recognize everything in in that book. Um also we're still very attached on blackboards. You can see we're almost the only uh discipline left that that's that still use our blackboard and it's it's it's it's to the point where you know uh photographers and uh think that this is a it's an art form. Actually there's there's a little coffee table book by uh Jessica Win actually who I I I know actually um who uh um just who

actually you know um which is a very nice book just photographing their blackboards as a uh as as just an unusual art form that you don't see anywhere else. So um yeah so we are kind of unusual um for example uh we don't collaborate very much at least not not until very recently um so even among the other physical scientists um so so this is a plot which is already 10 years old um but just plotting the number of of co-authors in a paper uh with you know between say math chemistry and physics and you know math has been

stuck at like one or two collaborators for uh for decades you know and and the other scientists have begun to realize that actually um you know that you know the modern research tasks really require broad collaboration very diverse sets of people and and we haven't really um done that yet. Uh so we're kind of uh missing out on a kind of the scaling up or industrialization of of of science. Um now there's reasons for that. It's not just because we are antisocial. Um there there is you know so there is a

high barrier to entry um like but uh a mathematics problem you you often need a math PhD to even understand what the question is um and uh our standard of proof is extremely high um but we we we are interested in when we want to prove something we want every step to be absolutely correct so if you're collaborating with 10 people and one of them is unreliable um and and and it's producing untrustable untrusted uh arguments uh either everybody has to verify everyone else's arguments which

is very hideous or and a lot of our workflows don't scale. Um, so blackboards are lovely when you have two or three people. I mean, it's it's it's an amazing experience actually to to just solve a problem at a blackboard with someone who you're really mentally tuned to. But when you have 20 50 people uh working on the problem and they're all in different countries and so forth. Yeah. Uh we you know we you can't really solve a problem over Zoom for instance, it doesn't really work. Um so um yeah

there are reasons why we we sort of haven't changed with the times as much as other disciplines. Uh but I think now uh with all the technology this is going to change. Um so we we are finally in the last year or two beginning to create large scale projects. Um so the analogy I like to give is that in in the experimental sciences uh there's a distinction between case studies where you you take one particular uh object of study and and you you make a very intensive detailed um analysis of that

one object. Um and that's kind of the standard thing you do in mathematics. You take one mathematical problem or one mathematical concept and you you study it very carefully. Um but then there's population surveys where where you you you take a population of a thousand uh uh um members of a species or whatever and and and you uh you do and you do data analysis, you do statistics. Uh you know what percentage of your population does this, what percentage of the population does that. Um and we don't do that in

math. Um because we haven't had tools that can sort of systematically study large uh populations of problems until now. Um we are finally beginning to do broad participation. Um so in the other sciences that sometimes there is citizen science. You can you can have amateurs collect butterflies or identify comets or or take water samples or um and even if the data if the um quality of the data is is is is is not so up to 100% scientific standards there are ways to to to still use that uh that somewhat

noisy data. Um and until recently we couldn't do that with math. I mean a outside of a few isolated projects like finding large primes a few things where you could get amateurs um but now um we can we can do that too. So that um we are beginning to have projects where many of the contributors are not professional mathematicians but um um graduate students, high school students um you know um people from computer science or or or from the tech industry with some spare time. Um so uh we are um

yeah we are we are um finding projects where where lots and lots of people can contribute in in interesting ways and of course AI so uh AI is is advancing really rapidly um um and can really help these projects in real time now and in uh in ways that sort of save more time than they waste um and that we've sort of passed this this crossover point um and then there's a secret ingredient that makes all this work. Uh so um uh the reason why scaling and AI and broad participation actually is a net win is

because we have also have formal verification. Uh we have there's a lot of advances in actually automatically checking whether a certain argument is correct or not. And so even if a lot of the contributions coming from AI or from the general public um or from a very large scale project are um unreliable uh we have ways to filter out the the untrustworthy inputs and keep the the good ones and that has made a huge difference. So, um I've given versions of this talk for several years now. Um and um I've

usually sort of pinpointed individual examples of um um of places where AI or neural networks or whatever have have made some um some progress. But uh as I said, we're now entering the era of scale. So I will talk actually just about one population study if you wish. I call it the case study here. But um which is and it's one which has kind of made uh is is been been sort of buzzing in social media now which is which is um the Erdish problems um which are sort of the first large data set of problems for

which we can actually apply all these tools and and get some idea of of which ones are working and and and what the strengths and weaknesses are. Um so the the Erdish problems are a collection of about a thousand odd problems and there's a website started about three years ago by Thomas Bloom to systematically um um cover these. So, so Erdish was a mathematician active in the 20th century. Um, very very prolific. He authored over 1,500 papers in mathematics. I think that's still the the record. Um, and um, yeah, and he he

he was um, he collaborated with everybody. I mean, he didn't collaborate with me. Okay. But but uh, when I was 10. That's a picture of myself with uh, with poet. Um, and as so he loved giving up problems. I still when I met him, he just basically gave me a problem and and we worked on it. We didn't solve it. Um it it did get solved later actually. Um but he was very very um um um fond of giving up problems to encourage the community to to get interested in the type of mathematics he

was promoting. Um and so he was he was famous for u not just his research but for for posing problems constantly. Um and um he even put cash prizes to to some of these problems. Um um so some actually we've you know I mean most are like $50 $20 and nothing significant. Um but there are a few that that that are really quite uh quite influential. Okay. So so so this is one of the earish problems. Um it it doesn't matter what what it is. Uh but it's it's um for the purpose of this talk but it it is uh it

has been one of the most influential questions. How big does a set need to be before you can show that it has and uh this he attached one of the biggest prizes $5,000 to it. um and it's still open but uh there are many many I I've worked on aspects of this problem you know there there are many partial results towards this problem that have that themselves appeared in top journals it it is it is it is a really um really influential um question he he had a knack of asking really really good

questions that are not impossible um are not trivial but um um just at the border where where um he knew that any progress would be interesting um so Erdish call these problems acorns uh requiring deep and subtle new insights from which a mighty oak can develop. Okay. However, uh he posed a thousand odd problems. They were not all acorns. Um so um um yeah so there are some problems which turn out to be ridiculously easy in fact. Um so like like here's one another one he posed. Um there's a certain

equation n factorial x to the k plus or minus y to the k. Are there any solutions to this? It's like a fifth class theorem type type problem. So he he asked this um and it turned out um he he um he posted in uh well yeah um yeah it turned out after a couple decades that you just take a computer to search and this the answer is no there's there's a simple example you can actually just numerically show this this answer is false um so um but was knew this okay so he call these forms marshmallows serving as a tasty tidbit

for a few moments of fleeting enjoyment so um it's a very diverse set of problems um these problems And I I should insert some disclaimers because um over you know in social media sub um recently the these AI companies say we just solved you know fiveish problems you know oh no we solve six okay um and uh the implication is that this is what mathematicians do all the time is is that we we are just trying to solve these problems. Um so yeah I I should just preface this is is that um the problems I mean problem solving is

only one aspect of mathematical research. we are also interested in understanding concepts and and communicating and simplifying things. um you know I mean and the reason we solve the problems is not so much because the problem itself has all these applications um but it's because the process of finding the solution often often discovers new so so many of the problems there are new techniques um you know so the the this problem of of um of finding arithmetic progressions you know it um it led to the whole field of

attiturics for instance um so there are it's it's not just getting the solution um but but sort of all all the things that come with that usually when when when you work towards a solution. Um but nevertheless, you know, it there's a thousand problems and some are solved, some are unsolved. You know, to a computer scientist, it looks really really much like it looks really like a benchmark. It is not a benchmark, but it is uh it's become a very tempting target because it's it's you know, you can

actually measure, you know, here's your here's your new AI tool, how many problems going to solve? Um so um I think it it is it is a nice data set for the state to to sort of take a snapshot of where these tools are at this moment in time. Um and so and you can start doing comparative tests of of of what types of of of ways of using AI are more effective than others. Um which you it's harder to see if you're just studying if you just if all you're given is that one or two problems that have been solved by

AI. Um but you know we have a thousand you can you can start doing things like data analysis. Um yeah so there has been a lot of hype uh so I should say right away okay so even though there are major important problems in the set of uh in the early problem set currently AI has not really made progress on the most uh high-profile problems uh the ones that that mathematicians most want to solve. Um to date the problems that it has solved are the ones that are attention bottlenecked the ones for which um it

has posed once or twice in a paper but there's been almost no follow-up literature. No one uh has really looked at them. Um but AI can scale and so we are sort of clearing out um um uh getting making progress on a lot of problems for which we didn't really have enough um human attention on. Um and but but even with all the hype they have they there there has been a really really visible in uh increase in um in capability. I mean it it is it is not it is not pure hype by any means. Um and to

me what what what these advances show is that there is a complimentary way to do mathematics. So humans traditionally we work in small groups on hard problems for months and we will keep doing that. Um, but we can also now set AI to to scale to sweep a thousand problems and and pick up all the uh do all the low hanging fruit if you wish. Figure out like figure out all the ways to come to um to match you. They have 20 different techniques, apply them all to 10,000 problems and see which ones can be

solved by these methods. This is the cap is present today. Um yeah and you know as I said we can do statistics. Okay. So like I can ask how are we doing props? I can give you graphs. Um so yeah we we started tracking this systematically just last September. Um so uh what all these graphs okay so um um this is the number of unsolved problems. Okay so right now there are of the thousand odd problems there 699 unsolved. Uh the reason there's a big spike here is that at one point um Thomas discovered a big trove

of newish problems like like 50 or so that he added. Okay. So um and how many how many are are solved? About 480. Um and it's sort of it's been increasing steadily for many reasons over over time. um AI started making big progress around here. Well, actually there there was a spike here also when when lit literature to search came out. Okay. So um um AI research tools had discovered a whole bunch of solutions that were in the literature but but uh we hadn't recorded them. So there's there was an

early spike uh and then there's been this acceleration although currently there's been a plateau um last few weeks there hasn't been much activity I think because there's another benchmark came out and attracting a lot of attention but that's my theory. Um and uh some other uh yeah so um and also we've been making progress formalizing a lot of the solutions. So not only are the solutions many problems solved but we've actually started formalizing them in this lang language called lean um and uh yeah so

um a lot of solutions are now also formalized I won't talk about the the other other curves um yeah so we um we're going to make progress um some of the progress is kind of mundane well it was amazing six months ago and now we think it was mundane it's it's it's like it's like saying web search you know I I I remember when when um out of vista and then Google came out in the 2000s and my jaw dropped just how how amazing it was that I could access the entire internet you know and we just take it for grant

granted nowadays and it's beginning to be like that that too yeah so yeah so six months ago uh these deep re research tools came out and you can get an AI to search all kinds of of literature and and find obscure matches to your problem and say oh yeah there's there there's a paper from 1970 which has a in a different language often literally um but in a different field but it solves the problem with a tiny bit of of modification so we basically have semantic search now uh which we've been

wanting for years. Um they still occasionally hallucinate bad references but uh at least with literature search you can go and check the source material. So um and yeah 20 30 odd problems were was solved this way. Um yeah everyone I mean it's extremely easy now to use AI to to generate code and numerical data. you can do all much more numerical experiment um generation and we can formalize so much faster now that um the the translation of an informal proof to a formal proof to check was really tedious. it took weeks. Um now

now people can do it in hours. Um like it's um well not for every single paper but the but any types and this has been important for being able to work with AI because um if if if someone says hey I've solved this problem and here's an AI generated proof of like five six pages of of of AI generated uh text. It's often got rubbish in it. Um and no one has the time to look through all these things. But yeah, but if but we can automatically convert them into formal proofs. Sometimes it works,

sometimes it doesn't. Uh and so we can actually um uh handle a big influx of AI generous solutions. Um yeah. So um yeah. Okay. Um this is a typical deep research. Yes. So so here was an Erish problem which which yeah um you just asked was this problem being solved and yes it was solved by this case by Erdish himself 1981. Uh yeah. Yeah. So, at least 20 problems have been solved this way. Um, here's a recent paper I wrote on another problem. This one I didn't use much I I used AI to convince myself

the result was true. I use AI to draw pictures. Okay. I mean, they can draw professional grade plots and it just, you know, it's much better than much faster than messing around myself with Python or whatever. Um, so yeah, I mean just for for secondary things like this, AI is already basically excellent. Um, and this is what a formal proof looks like. Um yeah so uh here was a a proof that was first published like 10 years ago one of the earnest problems and uh there's a talk at Aristotle that

that converted it into lean. Lean looks kind of a mix between math and Python. Um but yeah it it uh um yeah so this is what a proof looks like. Uh you'll see there's always squiggly lines. The the former who sometimes has some some oddities like Aristotle likes to use um deprecated methods for example that uh still work for now um but um uh but they're being phased out um and yeah. Okay, it it the proofs when you um to someone who's expert in this language, it they look a little bit verbose and um

yeah, not quite polished, but this is something which I think will uh will be improved upon. But maybe it's not so important because um in many cases, you don't really care exactly how elegant the proof is. As long as as long as it compiles, you're happy. Um yeah, so um we're using all these tools. Another thing that that um has been um the reason why we're making so much progress also is is that we have a community now. So Thomas has actually worked really hard to um uh to build a

community. There's this discussion forum and community rules. Um and um importantly um we're we're neither sort of overly pro AI or anti-A. I mean some others different forums have all kinds of of uh of attitudes towards AI. So um I think what has made the problems particularly immunable is is that we welcome people to contribute AI generated solutions as long as but there are rules you have to disclose them. You can't just uh have a long string of text and and and pretend that it was a human

that came up with it when obviously it wasn't. Um and you you have to summarize. You have to be responsible for the content. Um and you can't just spam the doc. Yeah. If you have a really long thing you want to say you put in in a link. Uh so there's some just some reasonable reasonable rules. Um and and it's actually managed to work. Um you know so in in other in other forums uh there's a there's a real concerns about being flooded by AI generated you know slop I guess is the is the modern term.

Um and but and we've had you know we had to moderate and delete some some comments but actually it's by and large we've had constructive discussions between both people who are doing math traditionally and through AI. Okay. So um just very quickly uh I'll just give some actual examples of how humans and so uh humans have interacted on the site. Um here is an English problem 367. Uh it is still unsolved technically um uh because it it asked two questions about a certain number theoretic object. It doesn't matter what

the the uh the quantity is. It asks for two inequalities. Um and AI was able to prove one of them. Uh the other one is still open. Um well not not AI precisely humans and AI. So uh what happened was that um uh a human on the phone uh uh water uh played with it and he said okay I got a construction which he did some numeric I think it works but uh there was this one identity that he had to prove. Um so um he he plugged this he plugged in a certain construction and as long as a certain congruence condition

held he could he could he could solve the problem and he said I'm sure someone is able to verify that that this this holds he could he could check it um the first few uh um cases numerically um so um I was I logged on the site um so instead of working out pen and paper I just gave it to Gemini um and uh yeah okay and Gemini just proved the uh um the missing step um Yeah, this was about three or three months ago or so. Um, using farther way fancier technology than was needed. I used five evaluations

and some algebraic number theory. Um, but I I okay I could read the proof. I translated into something which was sort of simplified. Um, so then I I explained it on the forum and then a third person um Alexi took that proof and just fed it into um one of these AI order formalizers, Aristotle in this case and converted into a lean proof. So checked out we we yeah so we have a completely confirmed proof of of that of that result. So that's sort of a typical interaction. Um another example and this final example I

think these books um is uh yeah so so there's another problem which actually we did fully solve 126 um so it's an optimization problem. Okay. So there there's there's a there's a mathematical uh description, but actually um I asked Nano Banana to uh to give a a condensed explanation of it. So um you can think of it as a coin game. So um two players, Alice and Bob. So Alice has a stack of coins and she will split them into n piles. So N is given like say 10. Okay, you want to split your your pile of

coins into 10 piles. Some are tall, some are short. Um so you have uh 10 piles and then Bob will select some of the piles to keep for himself. Um but the rule is that Bob can only select an increasing sequence of of piles or a decreasing sequence. It cannot select an alternating sequence. So Bob will might select for example this guy, this guy and and this pile. But it can't select this pile, this pile, and this pile because that's that's neither increasing nor decreasing. And Bob will will select

the um um the the the competition powers that gives gives him the most coins. And Alice will try to arrange the coins so that she loses the least amount of coins. And the question is is how much um uh what should artists charge Bob to pay to pay this game? What is the fair price of this game? Um so as a fraction of the total number of coins. So so that's a quantity called called C of N. And basically the question is what is C of N? That that is the question that that Erdish asked. Um yeah. So uh the

way this worked is that uh one of the participants on on on the on the forum um uh just started working this out with small n using some linear programming and worked out what the the ratio was for for small n and made a conjecture that that if you had a square number of piles k squ then the the optimal cost is is one over k. So if if you have 16 piles um Bob can basically take one quarter of Alice's money. Um it turned out actually that this was not a new conjecture that actually um yeah later

on we actually ran a deep research tool. This exact conjecture was made back in 1980 but we didn't know about it. Um and then um well um and then nothing happened for two months. Um no one tried to no one was able to solve this conjecture except at some point B decided to just put this conjecture into Aristotle and see if he could just solve it. It's just a finer proof um and formalize it in lean. Um and it did. Um so I think he tried it for like hundreds of problems and and and the success of

it was like one one or two% but this one he did and uh the proof was quite interesting like it this coin problem he managed to convert into a problem about packing little squares into a big square. Uh there's a there's a simple translation which I won't mention here but it it it it caught us by surprise that the the the AI could do this. Um we did later find that there was precedent for this trick of encoding this this type of monitor and sequence problem into a packing problem uh by a paper

from 1959. Um and also we had we also later found that this particular problem that it solved was already solved by a different method in 2016. So this by itself was not a novel um was not a um proof of open problem but it was an interesting method and and and rather creative um but it only solved the square case. it only if the number of of piles was a squared 1 4 96 it worked but what about the other um ones okay so with numeric you could get up to like like n= 8 or 9 but that but um with linear programming

but at at some point uh the linear program became exponentially big and you couldn't do it uh so I use a different AI tool called alpha evolve to to work out extraises for for um or up to 16 actually so um and so uh I just ran this tool and it gave me here are sort of the optimal or at least anoptimal or or probably optimal um configurations of coins. Um and there are various patterns that you could see and and those um and it it gave um um values of of of the C of N. Uh and based on that I could make

a conjecture as to what what it was. Um I first made a rather complicated conjecture and then and then Bars simplified it to to a much simpler conjecture. Um and then um uh a a further co-author Lawrence Wu who I think works at uh um uh um was it open air? Um yeah so uh he he noticed that that this this conjecture was very similar to u well either he or he plus a I'm not quite sure exactly but um um yeah was actually um it was almost exactly the same um function appeared at at a in a in a different problem which

actually was a separate problem about square packing um and that problem had just been solved. So there's a question about square packing that was just solved like two years ago um using actually and uh with a with a function which almost in fact turned out identical to the one that we had just conjectured and so just by putting that together uh with with everything we've done we we we solved this problem 1024 and it's now also formalized in lean um so it's it's it's a fascinating

interplay between um humans and AI so uh just to wrap up um yeah so AI it's already enabling all kinds of new ways to do math at at at scales we haven't seen before, at speeds we haven't we haven't seen before. Um and um and really broad, you know, most of these people I've met online, a few of them, but but but not most of them in person. Um but I think what's really important like um once you collect a systematic set of things to do uh problems or tasks, lots of good things start

happening. Um I mean in computer science, I think we've known this that once you get a good data set, you can do all kinds of things. Um but mathematicians we haven't put enough value on data sets. Um uh but this is I think u it's the foundation once once you have a a a good set of of things to do. Uh there's just so many tools out there and so many people who may not be professional mathematicians who are just willing to experiment that you can start getting all kinds of unexpected

progress. Um and yeah in particular I think I think uh because of this they really lower the barrier to to uh to to um yeah so you know there there are problems that were basically solved by high school students um with ARM driven AI that's great um and but you know and we've been able to check it because it's it's in lean yeah um yeah so uh the other thing is it's really really important that we have this verification okay with um everyone has seen what happens if if you allow unverified AI to

take over um side or something. Um, yeah, and I I really think, you know, so AI by themselves are already great. Um, but I I think there's so much potential in in in human AI collaboration. Um, yeah, particularly for sort of longtail um applications. So, so far working on the hardest problems. Um, it's it's really not clear how to apply any of this to to individual really hard problems. But if you have a thousand medium difficulty problems, uh, then AI is great. So, I think I'll stop there. Thank you.

>> Well, thank you so much. Um, we have time for a few questions, so be sure. >> Um, this last conclusion that it's highly situational. >> We're at a point in time now. >> Do you think that is what it looks like five or 10 years from now? >> Um, >> all right. Yeah. So the question is in five years time will AI use cases still be highly situational? Um I think uh technically yes but I think we would have figured out how to uh um how to use it. So uh maybe an analogy is with

Wikipedia. Okay. So um bear with me. Okay. So um yeah so when Wikipedia first came out um you know there was this brief period of time when as as a as a lecturer you would see that students would just dump Wikipedia pages into their homework and um you know um and clearly not understanding what's going on. Um and so like some the initial reaction is oh we should ban use of Wikipedia or whatever. Okay but we eventually realized okay so basically what what happened is that Wikipedia is a situational tool. Um so you know

you don't use it to get the final answer to anything but it's a good starting point. it gives you other references and you should still use your own judgment. Um and so you know now no one no one forbids people from using Wikipedia because we have understood how to use it properly and how not to use it. Um and so technically Wikipedia is still a situational tool but it it's no longer an issue, right? Um so I think AI will will will go the same way. I mean so there are obvious sort of really bad

ways to use AI that we're seeing right now. Um and we still we need to educate ourselves as a community how to do that. I think in five years uh we will um just have a a good cultural understanding of what AI can and can't do. Um and so the uses of AI will I mean uh we won't have this issue of of having to distinguish between good and bad AI as much. >> Other questions? >> Yes. >> Yeah. Uh so let me ask this this one. So these are problems. >> Yes. >> They're well known. But as you said

there's some hard problems. >> Yes. by the green. >> Yeah. >> So let's say you have not proved it. >> Would AI be able to prove it? It's not >> not yet. Yeah. So that that yeah that green theorem which I proved. Yeah. That that is one of the problems. I forget the number. Um yeah. Um yeah. So to date Yeah. So there have been scans. So people have just gone through each one of of the 10,00 problems and fed them to an AI and they have like a 1% success rate, 2% success rate. Uh which is

already amazingly impressive. Um but uh to date with the current level technology the one or 2% that they do solve um they are the ones that have not been studied very intensively or and and the solutions are relatively short and standard um uh now the ones that have been solved by some difficult method if the methods in the literature sometimes they they can recover it. Um yeah, so so far we have not had um um a really striking um uh use of of these tools to to to solve a problem using a technique that we that

no one has seen before. Um but that that's where we are right now. >> What about formulating conjectures? >> Yeah. So um that's a good question. Yeah. So so this site doesn't we're not um they don't accept new new conjectures unless they came from. Um it it is potentially a good use case. Um I mean one thing I think is it's much harder to score. So so a a problem you can solve or not solve. Okay. And that that's a scoring function. And AI is pretty good at optimizing scoring

functions. But a conjecture could be useful or not useful. I mean I mean you can generate random conjectures but but generally useful conjecture we don't have a good scoring function for that. Um so um I think um in the near term what will happen I mean I think what these tools can do is is that humans can can form conjectures and AIs can critique them maybe try to disprove them prove them using using um standard examples and and you can give give you some feedback some on a conjecture but not yet autonomously producing good

conjectures but that would be a great development. One last question. >> You mentioned how AI is helping medium hard problems in math. >> Uh how about the connections of math to say physics or biology? It's so far, you know, quite difficult to establish collaborations. If there's faculty in the same institution that happen to have that overlap, they collaborate. >> Um it would be wonderful if mathematicians could get involved in this kind of applied math. >> Yeah. Oh, we are having some IPA events.

Uh, yeah, with the next month there's we we're bringing together physicists and mathematicians to basically try exactly that. >> Um, yeah, so AI should be helpful. I mean certainly um explaining basic concepts, you know, I'm working with a physicist and I I don't understand what a quantum field theory is and explain to me like like I'm a mathematician, you know, it it um this this does help. Um um I mean um one thing though is is that I mean as I said AI has been particularly

useful in mathematics because we have this ability to verify everything that we say and and so this filters out a lot of the rubbish. Um the moment you actually move to the to other sciences um you still have some verification but but it is not as watertight. Um but um so it should still be possible and we're going to run we're going to run various various attempts. Um yeah but that is yeah so among the the concept of broader part broader participation mathematics would be also include the other sciences

and also to get mathematicians to to work on on on projects in in physics or chemistry or or biology. Yeah. >> All right. Well, thank you so much for now. We resume at 10 with very very I know Thank you Crazy. Heat. Heat. I know you Heat. Heat. Heat. Heat. Suspension America. I'll be going there next time. Oh yeah. Okay. Brother. Are you section? They should be good. They come check Please develop longerlasting over a longer period of time as opposed to just being like, "Oh, when I was at

it was great, right?" And I leave and you met some folks there, but they're not necessarily the folks like anyway. So that's >> interesting Wednesday. people,000 people $100,000 that it's it's the becomes you're doing this thing and who knows it's going to turn out. But I mean that's that's what ends up making it way back. The reality is just we've got to find a way to sign us for Yeah. The engagement level need Although you could in some cases, right?

has been instrumental. So now I really want to get this broad. >> How long This is the world that we live in. >> Very well. We didn't have any questions. >> No, I was when I started this lesson. Thanks. And I got injured as chair. really what we see and there's been others like that actually higher up value to a broader coalition. So that somebody needs to get another company that's fine. People still think this is great. is something that science just train is something really capturon

that Hey, >> morning. >> Okay. >> Yeah. >> Remember I remember Oh yeah. >> We have a very good design and it has a very nice role in the future of particle physics but it's not funded. It's >> well the trouble is it's a >> it's a structural problem in Japan. Japan has been chosen as the place to do it. Japanese fund particle physics through which is a rather small part of the industry in the government. >> Yeah. But anyway, the the project is

considered to be too big that uh ministry and so the model well so they could put more money in that ministry but that's not the model. The model instead is that other ministries should China. They'll probably build their equivalent, but it won't do it on their own. Okay. I don't have a birthday. Another It's a general relativistic calculation of the collision of two. >> Oh, that's >> all right. So, uh, great great pleasure to introduce Kerry Barish, another speaker

that requires no introduction. Uh, so, uh, please. >> Okay. Uh, I wasn't quite sure what I should talk about today, but I'm going to weave in and out the big research project that I do that people know about and where uh AI is making its mark in what we do. But I'd like to along the way reflect a little bit on AI and physics and the fact that maybe in some ways physics is a place where it hasn't made the kind of impact that you might think it would. If we look back at the last century and look at the advancement

of technology, so much of it has started with physics of the most fundamental kind. uh the invention of the laser started with a concept of Einstein's the MRI machine started out with another concept from nuclear physics that then one both of those won Nobel prizes and later people learned that it had applications AI has made a much more a much slower entry into physics we use it all over the place but I don't think in really the ways that is pushing the science forward and I'll explain why I think

that's true and what the problem is uh not a problem what the limitation is. We started physics as a real subject in the days of Newton and Newton taught us uh the scientific method as a way to determine whether what we do in our laboratories or in our heads and develop is true or not true by testing it against this set of criteria. And about in the 20th century that got replaced. We still use a scientific method, but it's no longer Newton's steps. Instead, the predominant tool that we use to determine whether

something sc that we do scientifically is true, whether it's a breakthrough in science or whether it's what we're going to build for a scientific device and trying to determine it quantitatively is statistics. and it's statistical significance that we use to measure whether something's a a true event. And the real limitation for us in applying AI traditionally or machine learning to uh to physics has been the fact that there's basically it's basically allergic to each other.

the uh statistical methods are the fact that you we use neural networks and for example is a black box that comes out we can't tell what the statistical significance is. So if you look at the discovery of the Higs Bzon I know all the what background work it's done and we look at all the internal notes and know how much uh modern techniques like this were used in determining whether it was right or not. But in presenting it it to our colleagues, if you look at the discovery of the Higs Bzon, traditional

statistical techniques are used to show that it's five sigma. And so the problem is that I remember the day that uh Max Delbrook came to Caltech and he was brought by Murf Goldberger, our president at that time who had come earlier from Princeton and brought him to the physics department and we tried to I tried as a young faculty member to work with him to tell particle identification whether you see a pion or a kon or an electron. or a photon in a detector which again uh by uh neural networks or

nested neural networks whatever you use doesn't give you any probability so that basically we've always done it by statistical techniques and so it's been the limitation and still is today and that's why I bring it up in what role AI plays in physics now it's starting to play a big role in an everyday way, which I'll point out kind of in our experiment, but it's not as fundamental as it might be because of the fact that it's not related to statistical techniques in today's

versions. And so that's the limitation with or the bottom line of what I'll do. So this is the discovery of gravitational waves. the picture from the uh physical review letter that we wrote now 20 years ago and uh 10 years ago, I'm sorry. And what it is is the merger of two black holes. The scale from left to right is 210 of a second. And the scale and the vertical one is the one that should be impressive. It's a number with a lot of zeros, 10 the minus 21. And so we were able to make an

instrument that could make a measurement to some small part of an effect that was at the level of one part in 10 the 21. And that was the instrument. Without going through it in much detail, the reason there's two graphs is it in order for confidence and for other reasons. We built two different detectors. Part of the reason is to use two or then three to point to where something is in the sky. And the scale from left to right is the merger. As they get closer and closer together, it's a bigger and bigger

signal and then they merge together. So uh the traditional technique that we use to find this is what we call template banks. We go and calculate using Einstein's equations every configuration that's kinematically possible between two black holes or black hole and neutron star. And we make roughly 250,000 templates that cover the parameter space that our instrument is able to cover. And then we compare the calculated template with the data 250,000 times on every piece of data. And that's basically where

the events are discovered. Uh in AI, we now use AI but in what I'm calling a secondary way. We use convolutional neural networks uh trained on a simulated waveforms and it enables us to do this more quickly. So that's not to me the revolutionary step forward. But by more quickly does enable us in terms of gravitational waves to make a quicker decision to tell astronomers whether we've seen something where they might turn their instruments and look at what we're seeing. So speed turns out to be important. Speed is

something that we can get help from. And that's one aspect where we now are using uh uh these techniques and this real time ID quickly then uh low latency enables us to do to begin what people like to call multime messenger astronomy that is that we see the same phenomenon in space and look at it in uh uh electromagnetic interaction. waves of all kinds, possibly nutrinos and gravitational waves. So that's the goal and that's why we do it quickly. This is LIGO itself. It's a very large

instrument even though it's so precise. The arms are four kilometers long and there's two of them. One in Hanford, Washington and one in Livingston, Louisiana. And there's a third uh partner which is in near Pisa in Italy and with a little different technical design but that doesn't matter for today. Uh we proposed this in the early 1990s to the National Science Foundation. They agreed to do it. The politicians when they agreed to fund it took our proposal to use a site near the Owens Valley in not so far from

Caltech and one in southern Maine and they rotated for political reasons but they funded it. So the job then is to actually compare and measure an effect that's one part in 10 the 21 which translates in terms of kilometer size uh device to one part a few parts in 10 the minus 18 meters. And to do that just to summarize what the biggest challenges are is that we have to do interpherometry. Something that people here probably have seen many of you in a laboratory in undergraduate school somewhere. We have to do it where

you compare the two arms light going down and coming back to one part in uh 10 the 12th of the wavelength of the light. And that's seven or eight orders of magnitude better than people had ever done with an intererometer. So there's many many tricks I'm not going to talk about. Uh the second thing that we have to do is even though LIGO is on the earth's surface, the main problem is the earth. The earth shakes, it's not that solid. And we have to basically float it or isolate it from the earth. Again,

getting rid of the earth's vibrations to one part in 10 to the 12th. And those were the two major if I summarize it the two major problems that took us so many years to solve or get good enough that we could make the detection. So uh we made the first detection. If you just uh look it it was a merger of two black holes which you can see in the table on the left. One 36 times the mass of our sun. Another one, 29 times the mass of our sun. That adds up to 65. And you'll notice that the final mass that we also

measure is 62, which means roughly three solar masses of energy went off in the form of gravitational waves. And uh we were to detect it later. The the um distance away in light years was 1.2 two billion light years away. And if we translate to what that meant on the earth's surface, uh we were just evolving from single cell to multi-level cell life on Earth. And so by the time the signal got to us, we became us and were able to detect it. So progress now and this is where we start to there's no uh AI or machine

learning and what I just showed you. So, but we've been step by step putting in the modern tools which help us. The most maybe the most important one is to make this decision quickly of where something came from to enable us to do what we call multime messenger astronomy. And that is that we measure in three different places on the earth and try to decide quickly and reliably that we see uh uh gravitational wave signal and alert the astronomical astronomical community. Again in the end we use statistical techniques

because we want enough reliability so that the astronomers don't lose faith in us when we say oops we were wrong when they turn their instruments. But we use uh uh modern AI and machine learning techniques to actually do the calculations themselves. >> Question. How quickly do they need to turn to see if they'll miss the >> we we try to I think I may have it on the next slide. If I don't I'll say it's we decide in a few minutes. It takes maybe an hour to turn things.

the signals depending on the frequency can go weeks. So it depends what it is. Uh but we want to decide in a few seconds but then we have to have an ability to say oops we were wrong and not do it very often maybe a half hour later so that they haven't done much more than mobilize but haven't invested a lot in turning their telescopes in some direction. This is another uh this is the first and maybe most important event that we've seen in multime messenger astronomy that is the collision of two neutron stars

and it's shown over on the left here. So you see on the left three plots or four plots the bottom one is a gravitational waves. It's a time frequency plot. And you see the little line that goes on that plot here is the gravitational wave signal as seen in LIGO. And it was very clean in LIGO. I'm not going to go through those details. If we project it up in time, these are satellites that were looking at high energy gamma rays. So if you look at the top one or the second one, within about one and a half

or two seconds, they saw a signal as well. And that was what gave us the confidence to alert the astronomical community. A side remark is that we expect that when gravitational waves are emitted, which has to do with a gravitational interaction, that's going to be slightly before any nuclear physics, it would emit photons. That's after it's merged and nuclear physics comes out. So within a couple seconds is kind of reasonable. But we know from analyzing this event that it came from an OB a galaxy that's 150 million lighty

years away. 150 million light years is 1.5 10 the 15 seconds. So within something like one part in 10 the 15 we show just in this little plot here that light and gravitational waves travel at the same speed. So, we alerted the whole community. They could tell what galaxy it was in. I'm going to run out of time, so I'm going to go a little faster on this. And then it was looked at in all the frequencies to answer the question in the front row out to days when you see the radio waves. And that whole thing

was analyzed then, which is the power of multi- messenger astronomy uh to understand what happens when two neutron stars collide. And it fits a model that's in the literature called a kilanova. Everybody's heard of a supernova. It's when a star collapses by its own, burns up its fuel and collapses. This is a kilanova. Uh and a kilanova has an interesting effect. So the kilanova is what we saw. Once we saw that you can calculate actually what happens in the kilanova itself and it solves a problem which is the way

science works that has nothing to do with physics a geology problem that I remember from the time I was a graduate student which is that the universe is made out of hydrogen and helium dominantly uh otherwise there's stars and the stars have a few he heavier elements and they burn by the fusion process. So we make heavier elements by the fusion process in stars, but the fusion process only works up to iron. So we can't explain by that simple argument where our favorite metals got into the earth like gold and

platinum that we love so much. And so uh that argument which is what I learned as a student of where heavy elements came from is probably wrong. And the right argument is that earlier times neutron stars collided and made uh these heavy elements which is an illustration of the fact that sometimes the science you get can move a long ways from what you're doing if you keep your eyes open. So that's the fact in this one supernova model uh it made 100 earth masses of gold. So that's the

argument we now use to make the instrument even more sensitive modern techniques called squeeze light which is a quantum effect which I'm not going to talk about and the sensitivity gets uh better and better to do that deep in the modeling of how we do something like squeeze light we use uh AI techniques with that even though it was a big uh success to be able to see gravitational waves. The plot on the left shows how much we've been able to improve since then by doing more modern techniques of

interpherometry. So the slopes this is the number of events versus time. We now have something approaching 300 and uh uh the slope change is and was so listed there as 01023. We basically take observing run one, observing run two, observing run three. In between we improve things and have made it a better instrument and the slope gets higher. A comparison. So one is that we get more events. The second is that they're much cleaner. I've picked here a recent event that's last less than a year old on the bottom which

has more or less the same uh parameters are close to the first event that we ever saw. But you see the first event has a lot of noise going around on it and this one very little noise. that enables us to have much cleaner events and in this case we were able to test a fundamental uh theorem that we weren't able to by hawking that we weren't able to in the uh earlier uh data. So now we have hundreds of events and we're able to compare with various astronomical models and that'll only get better and

better and we have events that uh we're still working on. In the upper left is the tests we're able to do on general relativity. And so far we've seen no violations of general relativity and are able to set a limit on whether there's a thing called a graviton that might go along with uh it at a very small level 10 the minus 23. Uh on the bottom left is the fact that as you might expect in a few hundred events we have some that we can't really explain. I'll tell you what that is and that is they may be

measurement errors. They may be real. At this point we just uh take it as an observation. We know that there's objects fundamental objects in the sky called neutron stars that are 1.4 four times the mass of the Earth and it has a fairly small signal. Heavier than that, the only object that exists that we know about are black holes. And the black hole can only be a black hole if it's heavier than some limit, which people have calculated. It's typically about six solar masses. So between 1.4 solar masses and six

solar masses, there shouldn't be anything. But we have several events. So we're not sure yet whether that means anything, but that's what we have. Uh now in terms of AI and machine learning, we're using it extensively to help figure out how to make a better detector. This is incremental. As I say, we we're we're using it for the optical design. We're using it for uh uh s the making the signals signal processing optimized and it's a central uh tool in kind of all the engineering designs as well. Uh

we have a concept now for next generation detector. uh in the present environment it's it's being not being proposed to be funded because uh funding agencies are kind of crippled in the present situation. One last thing which is for me maybe the heart of the problem um is that we would like ever since I was a student to somehow figure out how the universe began and how it evolved at early times. We don't have good tools to do that. The best tool that we have is what's called the

cosmic microwave background. And there we look at the shape of the cosmic microwave background and we get kind of a photograph if you want of what the universe was like 380,000 years after the big bang. Earlier than that we had what happened at the very beginning as a puzzle. The fact that it seemed to have grown very very quickly something people have heard the word inflation maybe uh and we can't probe that. There's two possible ways we could uh do that then. uh one is with nutrinos. There are many

many nutrinos that were made in the very early stages of the big bang. But the problem is that those nutrinos have thermalized and they're so low in energy that at present we don't have a viable technique to detect them. Maybe someday but not now. The best possible way to look at the earliest stage is gravitational waves which would go back to the very earliest time in the uh creation of the universe. Uh and we don't yet know how to do that. It means detecting gravitational waves that are

much lower frequency than the ones that we've detected. So instead, the way we presently have our best picture of the early universe is by combining all the things that you kind of hear about, and that's in this plot here. If you look at the left hand side where it says Hadron collision, that's the part of a of a density versus temperature plot characterizing the early universe. That's covered by the Large Hadron Collider at CERN. The next one which says heavy ion collisions is what's

being done at Brook Haven where they collide heavy ions to do uh nuclear physics but basically cover this part of the plot. And then if you move down to the further right hand side it's the part that's covered by studying neutron star collisions in gravitational waves. So in an indirect way we're developing a pretty good picture of what the early universe might be. But directly that remains uh for the future uh and that's all I have to thank >> I got a question well great presentation

uh uh you know really uh interesting sharing no actually uh Einstein actually predicted gravitational waves in the seminar paper in general in 1915 and it's taken you 100 years literally right 100 year 2015 that's when you actually detected it so I guess my question to you is when you finally did uh what surprised you the most about what they do about >> um so the the question is after 100 years you have all kinds of ideas what maybe you'll see if you see gravitational waves we

We haven't learned and I can't really answer your question very well because we're just scratching the surface. We're able to see uh not a big surprise. We're able to see the collision of two objects so far and the merger of them. That's neutron stars, something we knew anyway, and black holes. But we don't know where these black holes came from. So there's two kinds of black the biggest question we have now is what is the origin of black holes? We have black holes that are huge

that are at the center of galaxies but the black these black holes are lighter than that. They're some 100 times the mass of our sun or something. And where did they come from? Were they primordial made when the universe began? Were they made by some dynamical mechanism and got so heavy early in the universe? or were they made from the collapse of stars? The most popular view is they came from heavy stars burning up all their fuel and collapsing and making a black hole. The problem is that we see some that are

too heavy to explain that way. So it's hard because if stars get very big, they're unstable. And so stars heavier than about 50 times the mass of our sun are about the limit. But we see events already quite a few that are closer to a hundred times the mass of our sun. So that's creating a problem. The second place that I mentioned already is creating an uh not problem maybe interesting problem but a problem. The second place is the fact that that we see events that tanalyzing events that

don't aren't either neutron stars or black holes but somewhere in between. We don't understand those yet. So we've got a lot to do. Any questions? St. >> You mentioned den noising briefly. >> I mentioned what? >> Noise. >> Yeah. >> Okay. I love noise. And uh somebody told me that the first black hole was uh recovered using god help us my algorithm. So uh how does regular mathematics play a role in what you do like advanced signal processing things like

that? Yeah. uh uh we well first advanced mathematics if it includes solving Einstein's equations especially in the strong field limit answer certainly yes >> not so advanced algorithms to do the noise and things like that >> we do yeah uh the to understand the noise um the non-gaussian features of the noise we use advanced modeling to that to to do that total variation. >> Yeah. >> Question. >> So, so coming from another physicist, I'm curious throughout throughout your

talk and I would agree with you. You said that there have been no real AI advances in physics. So, what do you think is the barrier and what do you think AI needs to do to to to surmount that barrier? Well, ideally we have to find the connection somehow with the great power we have not just in what we do but otherwise with statistics and to me the fact that those are two completely separate topics at the present time. How do you kind of get them close enough to talk to each other that we can use some technique that uh

gives us some level of confidence that isn't just totally a black box like the neural net nested neural nets. So that's the challenge I think. >> Question there >> I have more a general question. Is is there any u foundation for us to believe that uh we could one day modulate gravitational waves >> that we could what >> modulate gravitational waves? >> Modulate them. >> Yeah. >> Uh I don't know. I mean you made this important point about discoveries in physics relying on

old-fashioned statistics because we can quantify uncertainty precisely very well. I mean this is a kind of frontier area and there's certainly not a consensus but in areas of physics where there's comp very complex phenomena in which the data itself is very complex like think about ocean turbulence shocks and galaxies even large scale structure maps of the universe. There's another way to do it which is you generate forward model simulations and you generate many realizations of the noise and the uncertain physics and

by comparing those with measurements you can get not as good but you can get a pretty good uncertainty estimate. So that's a area fascinating to me. And what's interesting sociologically is I pulled cosmologists at a recent conference. Just over half said if a result came out of this process, I wouldn't believe it no matter what. >> But I think we are at that transition point. It was only just over half and needless to say there was a >> it's not epsilon, it's 50%. Sir,

>> right? uh back. >> Hi Jerry, good to see you again. It's great talk and actually I have a question regarding one of those slides where you mentioning about the parameter estimation. It takes hours and then and weeks or even months to estimate and gravitational candidates. So my question is um do you think what would be the bottleneck in this case in terms of communicational capabilities? In other words, do you think the scalar data center now that people talk about will help to speed it

up in this area. Uh the one the second point of question will be can we move this capability computation to the orbit in space like space that helps to reduce latency distribution so that we provide actually initial detection data that will be acquired through the telescope and make the immed >> I missed your first sentence about space say what you said about it move the instrument strument to space. >> Uh not instrument but the data center. >> Oh the data center, >> right?

>> Yeah. I don't know. We are moving we are moving the instruments to space. That's why I asked you the the there's a big uh project which is funded uh in Europe to put an uh gravitational wave detector detectors in space in about 2035. and it's one of the so-called cornerstone missions in Europe. Uh NASA has a tiny role in it and uh that is very complimentary to what we do and moves toward where I think the ultimate goal is the very low frequency when you can look at the early

universe and it looks at much lower frequency than LIGO. LIGO looks at the audio band which is where the earth is quiet enough for us to but we have nothing to do with audio but the reason we can communicate with each other is where the earth is quiet is the audio band. So uh we work in the same region that evolution picked for our ears to communicate with us. But in space you can go to much lower frequency and there's much more uh phenomenon that will give gravitational waves there. All right, that's one question.

>> I um I was under the impression that foundation of the LLM is >> that what >> the foundation of the LLM is statistics and probability and prediction from the sciences. So where's the gap between what they're doing and the statistics you're talking about that will advance physics? Well, in our case, we have to get to the level where we give some traditionally where we give some probability that something's right or wrong. And that's where statistics usually comes in. So if we want to tell

something mundane like whether it was a pime mess or a k mezzan that went through a detector, we give some statistical probability that it was a k a statistical probability that it was a pi. If it's large enough difference, then we decide we know or not and or make a better instrument. And so we use it in that way. Traditionally, as I say, that's become in my mind the main barrier for using say nested neural nets to tell the difference between a pi and a k even though it's probably better.

We don't have the confidence that we rely on. So we have to readapt either not to use statistics and to find some other way. But I think what keeps us from moving as much forward as we kind of traditionally have in something like physics or chemistry compared to other things where we're ahead of the technology not behind it. Uh we need to find some way to get around this stat reliance on statistics. >> All right. minutes. >> Of course. language to extract this information which we were not able to unstructured

data from audio. in the future. So what we do is we did a lot of simulations. We use all the variable we have to try to a new system in the future and then we expand to different possibilities in the future. Yeah. And then try to get something back. This is this guy isn't really stable because it's mortgage and we want to make sure they can pay back 1 million or $2 million. You know, if we get a lot of interest, but just one bad amount to wipe off all the problem. That's right. That's right.

Exactly. So in fact one second but how about those not only just my lot of scientists just they try to find out Not only the probability all the correlation it doesn't matter and they try to very simulation gravitational about physics and astronomy. >> Yes. >> But I think supposed to be the same guy. Then I began to appreciate this. the only It's live stream and then the recordings get posted later. So I was a little bit surprised how some of the And also I see the way >> it's, you know, it's very specific.

So I work with big exciting It's already matters too much. exciting things going on. >> Yeah, we'll put you at the end to try to socially distance. Okay. All right. You have a quick >> and then you know exactly All right. Hopefully it'll be interesting. People will talk to So sorry. >> I didn't have your phone number. Yeah, two separate organiz realiz was a bad decision. >> Yeah. I was trying to think very his big point was that there's not enough traditional like

It's not Andrea. >> Yeah, >> we we we deliberately put you on the opposite ends of the table. There's a ball. >> Uh, no. This is >> I think it sounds like they're setting. >> I believe they all be one giant. Yeah, you're the final. >> They're in here. This is one giant slide deck. >> Okay. Okay. So, maybe we can stop the panel. >> So, welcome to the first panel on um on AI and mathematics. So, um I'm going to be moderating this this event. And so,

we have uh four speakers here. um who will be um all doing using AI in different ways to do mathematics. Um so we have Hayden Schaefer from UCLA um Dam Davis from Pennsylvania uh Diana Neido also from UCLA and Andre Bosi from UCLA. So we will begin with some short presentations by each of the speakers on what they've been doing in the space between AI and math. So we'll start with Hayden please. Hi. Um, I'm Haven Schaefer and my research group and I work on a variety of different problems

related to AI for science, AI for PE. I'm going to try to cover a lot of stuff in a few minutes. So, the first director we work on is AI and PE trying to come up with multitask general purpose solvers to uh be able to predict complex nonlinear dynamics just based on raw data. So the idea is uh we train very large uh transformerbased networks that can read in a short amount of uh spatial temporal snapshots. So think about a video that's just a few frames and then try to predict what the next frames will

be based on what we observe. So just on his context the uh goal is to make really general purpose uh the goal. Okay, I'm going to restart again. Now, uh the goal is to do general purpose uh numerical solvers where we don't tell the AI model what we're trying to solve. We let it make uh an inference based on the historical context. Um the hope is that these will be reusable. So, we just have to train a large scale network once and then apply it to a new task uh for downstream applications. So, as a nice example, we

have um 10 temporal snapshots of a fluid system. Oh yeah, we train the model using a bunch of different fluid systems. So different physical parameters, different geometry, different initial conditions. We give the AI model after training it a new sample of just 10 snapshots and ask it to perform a generative task, predict the next 10, but we don't tell it what the parameters are or what system we're looking at. So it has to make an assessment based on what it's seen in its training set. The top row is the

actual solution after time step one three or one is it three or five? Yeah, five and nine. So we uh uh ask it to generate this from the endpoint of the input. The middle row is a um popular operator based network that can do this prediction but is very good for single task but is uh has difficulty when you don't prescribe what you're actually trying to solve. And the last row is our prediction and you can see at least visually it's very close. And in terms of the error metrics, it's only 5% uh

error for this particular task. Uh the AI model does not see this problem in its training set. It has to now infer it based on its history. In another direction, we work on AI for science. Okay, this is a huge topic. I'm only going to cover one aspect of what we uh look at. Uh one of the interesting problems I've been studying now for over a decade is can we uncover physical laws from data? So can I provide scientists with an AI tool that while you just give us raw data, I can tell you what the

governing equation or the mathematical model is that uh actually the the data obeys. This is a very challenging task but we have a lot of applications in this and we have a lot of methods that do this. What's really interesting um and what we have been leveraging recently with the uh novel AI methods that are coming out is how to uh ask for more interpretable and explainable scientific intelligence out of the data. So not just what the mathematical equation is but can we talk to it can we communicate information that is hard to

write down as an equation like a chaotic regime or the data is likely to get to steady state rather than just writing down a model for it. So this is the goal here is to provide scientists with a better feedback loop of how to understand the data and how to interpret it in a um natural language and a mathematical sense. Okay. Um in another direction I'm just going to list all the projects that we're working on all the exciting ones. So in another direction we have uh AI for mathematical modeling. So in a lot

of cases we actually have a mathematical equation or a physical law that uh the data governs. So um but one of the issues is that computing or or predicting using that model could be very costly and we often don't have enough data to actually prescribe and to simulate uh the forward model. So maybe I'm missing boundary conditions or maybe I don't have enough parameters to resolve the potential field for the system. So um here we're using ML to mitigate some of the inaccuracies in our

data and also the lack of information for the model to simulate um moving forward. So, I just want to show two examples. It's a little hard to see with the light, but can you see the first? Nope. >> There we go. >> The uh video at the top left corner is actually a video of fish in a contain in a contained space. It's the raw images. It's a little easier to see in the particle the predicted particles. What we want to be able to do is take a mathematical model for it fit what the

potential is. how do the fish interact based on um an ML architecture and then predict the ground truth or predict the density um just based on on this kind of a simulation or fusion. So we're aligning mathematical models using ML tools and you can see the the ground truth density and the predicted density based on the model. um for um another application we have uh gas or air in a closed uh space or in a room. I I don't have enough information to actually do the simulation. I don't have the

boundary conditions completely and I don't have the parameters for the system. Instead, we run the neighbor equation and use ML to augment the obser observations that we have into the system. So, it's more of an alignment problem. As the simulation is moving, can I align it towards the observations I do have? And you can see this is um actually the velocity field and the temperature in the room and it it gets a strong fidelity to the to the ground truth. So this is really builtin data simulation using ML

and then okay so of course all these uh techniques and tools rely heavily on optimization. Um in order to train the hyperparameters for the large scale models, we have to optimize um and in order to you know learn what the dynamics are, we're optimizing against many uh highdimensional um data and highdimensional parameter spaces. So optimization is very important. We work on two different thrusts in optimization. The first column is the optimization geared towards physical modeling. So instead of just using

blackbox uh optimization routines, we want to respect as we're doing the training what the physical systems are. we might have imbalances between the data sets or we may need to impose after we've trained a model that physical quantities are conserved or energies are conserved. So how we do that is through metalarning strategies or fine-tuning strategies where we've optimized uh physical properties after we've trained the model completely. And then of course uh okay so in a completely different

direction we also work on optimizing large language models. LLMs are very popular. I know we'll hear more about them during the second half of of the the panels today. Um and an important task is to make them more efficient. So um recently there's been a push for these uh 2D or matrix aware optimization routines like MUN that do a really good job at um yeah at optimizing the parameters in a faster manner because it's uh aware of the matrix structure that appears in the parameters for the

um attention layers. what we're doing is um mitigating issues of instabilities that can occur with this type of optimization from time stepping or from aggressive learning rates. So we add adaptivity into the system and as a uh test we run a small uh experiment and a medium experiment training uh nano GPT or GPT2 uh using our model and comparing it to the two state-of-the-art uh optimization routines which are atom W and the moon algorithm. In both cases we get an increased speed and a uh lower uh

steady state loss uh from our um system. I should say uh for fair comparison everything is uh trained over a sweep of the parameters. So we tried to find the best parameters for each of the systems to do a fair comparison. Okay. Those are all the pillars I'll talk about. I'll come up, I think. Yeah, >> we'll have to switch the mic. >> I don't get assistance, I guess. >> Is this on? Yeah, we're good. Okay. Okay, great. Uh, thanks for having me here. So, um, I think this Okay, good.

So, um, so I work more on like in my in my research usually on like math for AI sort of space. Um, but I have had like a strong interest in AI for math for like several years. So, I thought what I would try to do with this um, with this talk is to just give you a sense of like how I see AI progressing like within my own research and like some anecdotes from my own usage um, over the last couple years. So um oh and if you're interested in like some of the optimization stuff and you're around

tomorrow I'm giving a talk in the applied math colloquium here. So just advertisement so I'll talk about that then um okay so uh I kind of got interested in this space like at the beginning oh and I'm sorry I'm going to show a bunch of screenshots like but I got interested in this space of learning about AI for math back in 2023 when um sort of like programming languages uh for formalization like lean started becoming the promise of these tools. Um, and so I was trying to figure

out like whether we could use them in our research. And my goal was basically November 2023 and December was to try to formalize a proof of gradient descent convergence which is something that is like kind of foundation to my field which is optimization. Um, and so I got started and at the time GPD4 was the state-of-the-art model. Um but even formalizing very simple proofs that about one line of you know of an English proof takes you know 50 lines of of lean um at least in my usage. Actually Terry

sent me a threeline proof a few days later. So that was interesting uh to get that but um uh but even formalizing these simple hard and things like GPT4 could not formalize uh them. And so and basically what I what I did is I spent the rest of December formalizing all but one result that I needed to prove this sort of convergence of gradient descent and then I left the last part as like an even thought you know maybe something and so over the years since November I that that year I would go back and test

all the latest models and here's a snapshot from April 2025 where I tested 03 Gemini 2.5 Pro Claude Code etc. and and nobody was really able to solve this this problem. Um and so I put it aside for a while and I came back because like I started watching his talk there's been a lot of formalization tools that have been developed. So for example Barnel from whom you're here seems to be pretty um interesting. Um so uh so fast you know fast forward to February this year. Um I gave Aristotle a sketching proof

that was generated by GPT 5.2 to Pro and it was able to formalize the RO result in 15 minutes in 200 lines of lean code which are like easily readable uh for me in particular and it gave me a sense of like how rapidly that area has been been developing. I'll just give you a second uh uh anecdote. Um so uh back in January 2025 um a colleague of mine was working on a learning theory problem. She uh asked like several prominent experts in the field like uh you know how do do you know a solution to this? does it exist

somewhere? And it looked like something that should exist, but nobody really knew. So I decided to treat it as like an exercise in testing the ability of the LMS. So I read none of the surrounding literature and I tried to solve this problem pretty hard for like a couple months just by interacting with uh 03 at that time basically and several other LLMs. And so when I started 03 couldn't apply definitions correctly. It was just like uh having a trouble because the the objects that we're

looking at are very combinatorial in nature and kind of recursively defined. And so it's just difficult for it to to reason about them. Um and so I kind of worked at this for a while and then once I got to July uh I was a little bit demoralized with it. My feeling was essentially that like the LMS were destined for this particular problem just to be like uh you know trying to solve oops sorry non-trivial sorry let me give you that. The LMS were destined to sort of saying this is a trivial claim therefore it's true which

is sort of the errors that I was getting at the time. Um but I you know I saw that they were pretty good at search. they were able to find some uh examples and literature that was relevant for me to read, but they were bad at applying arguments from um from papers in the literature. And so uh the search aspect turned out to be the key thing and uh because a week later agent mode was released and uh it suggested a list of five papers, one of which contained the results. It was in the appendex. It was

on an unrelated topic. uh had many missing uh uh keywords that that it should have included and it wasn't really reproducible but I considered it solved because you know uh I knew the solution now at least and uh I I stopped kind of testing the models in this problem but I decided for this workshop that I would try it again so seven months later uh chatbt 5.2 2 proved the result, cited the literature and spent 66 minutes thinking about it before it did anything. Um, and it just became like much more reliable and that's sort

of my perception in my field of optimization of how how things have gone. Um, I'll point out though that I did try to use Claude Code or Claude Opus 4.6 today and uh Gemini 3 Pro to solve this problem and Claude code stopped thinking after 30 minutes and uh crashed twice. Gemini uh gave me something that was like only half correct. It kind of cited an older paper of 1994 that stated but didn't prove the result. And okay um so uh so um last example I wanted to give you um was about the auto evolve software

which is useful for like automated algorithm tuning. So I you know I researched optimization. And I also really like numerical optimization and like trying to solve problems quickly with code. And so um Google released this tool called auto evolve. And Terry Terry already mentioned it. Um and it was basically a tool for um among other things like optimizing constants in various uh theorems and proofs. So for example, here's a proof about uh or constant that appears in um an inequality involving like the

autoconvolution of a function. And so I picked this this inequality because it looked like uh not so daunting. And I thought, hey, I'm going to claim on Twitter that I'm going to do this live. And that was like a big mistake because it took over my life for 5 days. Uh trying to like actually solve this problem. Um and at at the end of the five days, I like tried every single thing I can think of essentially. Um I said I give up. This problem is hard. there's infinitely many methods that I

could have tried but didn't because I just don't have the time or motivation and I had every LLM but I just like did not want to think about this anymore. Um and uh it gave me a strong sense that like uh you know having like a lot of compute plus like a pretty good prior model that can sample you know solutions and sort of like evolve code is like extremely powerful and kind of like unpredictable uh in some sense and and so it gave me a sense that like you know a lot of the problems that we care about

can like at least median scale problems is like as Terry was mentioning out could probably fall to like you know a lot of compute let's say like a million GPUs like let's say that a lot of these companies are trying to develop and having a pretty good prior model which is an LLM that can search within the space of solutions pretty well. And so I think like in the next year I we're going to see like a lot of semi-autonomous results and so uh I'll point to Seb again uh who is building

the strongest CS theory department in the country at OpenAI. Um so he has you know a strong team a strong model and I suspect that like in the future we're going to see like a lot of semi-autonomous results in the in the near field uh future. um not necessarily autonomous but you know within the next year and I'll point out here that I'm very biased in this because the best performance that I've got from these models has been in optimization it's been in high dimensional probability and

I think this is like a function of maybe the team and the initial training data and uh so it's not necessarily the case for every field but that's sort of changing now so there's been some papers uh by Axiom math for example which is like an early stage startup where they um uh are now proving things on remon services some combinatorial uh identities. I don't know how difficult these are because I haven't spoken to any experts that work in this field and maybe they were just like you know

straightforward consequences but they're look much more sophisticated than the things that we were doing just a year ago. So like imagine a year ago that you were able to generate this type of stuff and actually have fully compiling lean code to generate it. Um, and then I'll also point out Google's doing the same. Uh, some Aeros problems and also um some some things in arithmetic geometry, but these are like maybe subtasks that you wouldn't normally publish a paper about, but if we're using AI, maybe we maybe uh

you know, we're publishing a paper about it. I can't tell. I would be highly interested to hear from some experts on that topic. And so, the last thing I'll just say is that this is like a very good access for fundraising in the near future for like a lot of companies, right? like you can demonstrate capabilities and you can make this number go up and it's like we all benefit from it in some sense that we get to you know get these much more powerful tools and so it's very exciting

and I and I continue I I suspect this sort of thing to to continue in the near-term future. Um I don't know about autonomous but semi-autonomous for sure in the next year. Okay then that's all I wanted to say. I'm going to keep mine very brief so we can get to the Q&A. Um, but I have a link at the end if you have more questions or want to chat about anything. Um, so, uh, yes, I work with a lot of amazing folks. Just wanted to throw their photos up here. Um this is my group in the lower left and a bunch

of other programs including RUS that have been run here at UCLA. Um I just kind of wanted to give a brief overview in text um of all of the areas that I work in. So I also work in optimization like a few folks have mentioned. Uh I work in particular in methods for large scale linear systems. Uh I do topic modeling for feature selection image segmentation. So a lot of imaging and signal processing uh prediction and many more machine learning tasks. Um I also work on the foundational side of ML which haven't been talked about as much

u previous two talks. Um so working on proving things about behaviors of uh of ML. So like banan overfitting groing debiasing these kinds of things. Um a lot of that is actually joined with GO Montifar who's also at UCLA and not able to be here today. Um as well as many of our students. Um I also work in fair machine learning. So um tracking bias on error propagation throughout these methods as well as developing mitigation strategies uh to make methods fair and obviously the word fair itself is um a

little bit hard to define. So working with people in philosophy and other areas to actually kind of make that more of a mathematical definition. Um so a lot of really interesting work there. And um I also work with several community nonprofits um which I think I mentioned on the next slide uh in the medical space um the limey disease.org is a nonprofit that is working to study Lyme disease with large data and centure which is a nonprofit of attorneys that work to free and send people from prison. So a lot of

the applications we use uh LLMs and machine learning uh to study as well and those tend to motivate science as well and so it's kind of this nice uh feedback loop uh that I really enjoy. How does one advance? Uh so I just threw some pictures. I was much less thorough than my previous speakers. Um this top picture is showcasing uh this idea of benign overfitting which I mentioned. So we're trying to actually prove and understand um when um a model will exhibit banana over fitting. And this is just a

visualization of fitting you know points to a curve. Um but this is a good way of of seeing what we mean by ban overfitting. And so in each of these three examples clearly the data has been overfit right the curves in all three examples pass through all the points. Um, but they're overfed in different ways, right? So like on the left, we kind of consider that benign because um, if you use that turquoise curve to make a prediction, you're not going to be like too far away from kind of this

dotted gray line. That's the truth. Um, versus this catastrophic overfitting on the right, which is like the extreme. I don't even know where these curves go, right? They're like in the basement underneath the ground somewhere. Um, so that would obviously lead to very poor prediction. And so we've actually just developed theory uh for you know low layer neural networks to describe when each of these happens. And the idea is that we hope that that motivates what happens in the more complex models.

Um on the bottom here we've got some examples of doing machine learning for feature extraction and um we've developed a kind of built this synthetic data which is a population consisting of different groups. I won't go into details of what those groups are. Um, but each of the groups experience very different levels of reconstruction and so this is sort of an unfair model where for example a minority group might have terrible prediction whereas majority group experiences really high

prediction. Um, and then we've mitigated that that lack of fairness using this method that you see on the right where sort of um they're all experiencing some some levels of accuracy. This is the type of fairness work that we do. Um, in terms of working with the nonprofits, um, as I mentioned, um, we'll look on the upper left here. This is a heat map, uh, looking at Lyme disease data. Um, so this is one of the fastest growing epidemics in the world. Um, and uh, it's a very poorly understood disease. Uh, it

kind of mimics long COVID and all these long illnesses that are post infection. And so studying the diagnosis and the treatment and uh patient response is something um that we're getting a lot of funding for now. And so this is just a way of uh looking at the data and we're using a lot of machine learning to make some conclusions about particularly studying some neurological manifestations of the disease. And in the innocent center, uh this is a fantastic organization that has freed numerous innocent people from prison and

they have to look through vast amounts of data, court case data, arrest data, forensic evidence, all this all these things uh just to make a decision whether to investigate a case or not. And it typically takes an attorney about nine months just to make that decision. And so you see you you see clearly that there's a nice uh use of of AI to help make that decision and kind of run alongside the human being in analyzing this and also using it to just ask questions about why a case was taken on

and not. So it's also understanding how the humans are making decisions. Um so I think I'll wrap up there for sake of time. Um, but if you have any interest in anything I just said, feel free to stand up. >> Okay. Then you have to >> Yeah, because I'm going to take my mask off far away from my friends who don't want me to be near them when I take my mask off. All right. So, um, I need to mic. Okay. This Flip on. >> Oh, flip on. Beautiful. Okay, I got you. All right. See where I can put this?

There we go. Okay. How's that? Good. >> All right. Thanks. Hi everybody. I'm Andrea Bertozi. I'm a member of the math department here at UCLA and I have a few slides to share. Um, try to be brief. Okay, I want to start with an example. So, I realize we're supposed to talk about math, but I really want to talk about applications. So, this is a problem that I've been working on with uh an Andrews group in chemistry here at UCLA and it's regarding um the selection of DNA ops. These are single

singlestranded DNA molecules fairly short and the problem here is really a design problem. How do you come up with a you know seemingly random sequence of nucleotides that together in the form of a of a small DNA molecule will fold up in some way and then bind to a target with high affinity and specificity. And so the way this is currently done at least using this method called uh systematic evolution of lians by exponential enrichment um which is called cells um for short is that it is literally looking for a needle in

haststack. So one creates a soup of uh random uh sequences like a billions of these things um and then over an iterative process of um you know sort of testing them against a target um seeing what sticks running PCR amplification on that information and then redoing the whole experiment over again about 20 times. one goes one down selects from about a billion random sequences to maybe 5,000 and that's still way too many to pick one. And so then one has to come up with a way to identify maybe a couple

candidates to test in the lab. And the way this is currently done is by looking at the total count of each sequence um at the end of the select process and looking at the high count molecules. So um what we've been doing is using AI um and and in particular more classical machine learning ideas to um to take that data and to be able to look at kind of sort through the secondary struct or the the secondary structures of the DNA. You can see pictures um on the lower right of different configurations

um and how they fold up. And what you find is that um oh I have to take this with me right my leash. Um, so for example, here's a high count aptterr from the cell expressis. Here's one that just shows up one time, but it's almost identical in structure, right? And so one might ask the question, is looking only at the high count molecules the right way to do this or do we really need to get into the weeds and start understanding a bit more about what comes out of this process? And without

giving away lots of secret information, I'll just say that yes, there is something to this question. Um that maybe we can find um molecules that we wouldn't have thought to identify by actually using some machine learning and AI to be able to understand much better the the space of this problem. Now, there's a lot of nice mathematics that goes into this. Um so it's not a blackbox AI. We're actually using a fair amount of sophisticated mathematics um including ideas from subgraph matching.

Um this similarity structure is designed using something called matskin paths which come from combinotaurics. So that's a combinatorial object that's um that basically gives us a onetoone correspondence between this the shape of the DNA and the matskin path and that allows us to use that as a feature vector for machine learning. um and and then one can actually use this for computational chemistry. So the the moral of the story here is that there's a lot more to using AI than just taking

blackbox um or you know sort of blackbox um uh language models and neural networks and just kind of plugging in things and seeing what comes out that you can really get into the weeds and see how to use some very nice ideas from mathematics and computer science to um to solve some really interesting problems. So this is just one example in computational chemistry. So I want to talk about another way we can take ideas from classical mathematics to develop models for machine learning. Um and this is work

that I've been doing for gosh going on about 15 years now. But the idea is to take some classical ideas from surface tension from fluid dynamics and minimal surface problems. Um these are classical problems in lowdimensional ukitian space. Um and there and all of these problems algorithmically have the lelassian as playing a major role in the mathematics. Typically when you want to compute these things numerically um in uk in lowdimensional uklitian space when you're working with a lelassian one

often likes to think about um very fast methods such as pseudospectral methods where the lelass operator diagonalizes because of the fact that the signs and the cosiness are igen functions of lelassian right and um that that allows us to use a very old idea the fast 4a transform to be able to go back and forth between the frequency space and the and the uh spatial ukinian space to be able to very quickly solve minimal surface problems. So it turns out that there's a very beautiful analogy between

these things and looking at highdimensional discrete data organized on a graph. Um so basically what you can do is take your data and you can put it on what's called a similarity graph where each piece of data is a node on the graph and then the edges between nodes describe how similar are the information on comparing between each of the nodes. So then what you can do is you can for example solve something like a graph min cut problem which is a classical problem in computer science but we can now look at this as sort of a

discrete analog of the minimal surface problem uklitian space and then it turns out that all these beautiful algorithms from uklitian space have many of them have analoges in the discrete problem so for example we don't have the fftft but we can try projecting onto ien subspaces of the graphion And in fact, because similarity graphs have so much redundancy built into them, because you're looking at comp, not only are you looking at the data, but you're looking at comparisons between the data in this

graph structure. Um, it turns out you don't need the full spectrum to be able to do um, you know, interesting calculations. You need things like low rank approximations or sparse approximations. That brings things like the Nestrom extension or really chubby methods. And then we often find that we only need a small percentage of of these spectral modes to be able to answer questions like the graph min cut problem. So um these methods are excellent for data reduction in train um data reduction in

training data for things like semi-supervised and unsupervised learning um that they're a nice replacement for supervised neural network methods um in the case where you just don't have a lot of training data. So I'm working with a team at Los Alamos National Lab right now where there's a lot of data there um where we just don't have training data. Um it requires um you know somebody to do some work to actually label the data. One example would be this this example in the lower

left hand slide. That's a problem in surface water detection and multisspectral images. Many of this this information that we want to glean in terms of the surface water um lives in parts of the world that are hard to get to like the poles right where you where it's difficult to go and make um make actual um physical on the ground measurements. Um and the other thing is that this these are very um these are mathematical ideas where you can prove a lot of theorems but they also partner very well

with modern neural network methods. One example that we've used recently in several papers is contrast of learning um SIM CLR for dimension reduction of the data. So the last slide I want to talk about is another problem um that is now showing up in many interesting problems including um what Damech spoke about. You mentioned the combinatorial complexity right um I'm also just starting to work on a DARPA program the A3ML program on anti-moneyaundering where we're interested in finding

patterns of activity which is a subgraph matching problem. So what we discover is when you're trying to when you have a very large um world space of information and you have some pattern and you're trying to find it in that space if you can find one instance of the pattern I claim that there's probably many many instances of that pattern and that finding just one instance is probably not going to answer the question you need to have answered. So um most people when they hear cominatorial complexity

if you just read the literature you'll see that the there's sort of a knee-jerk reaction that people have which is to just walk away from that problem. Um but why why do you have to walk away? Why not attack the combinatorial complexity problem headon? So this is something that I've been interested in and this is some pictures from a work from my group a couple years ago published in um it e transactions and network science and engineering. And so it turns out that you you can actually make very rigorous

definitions of uh structural similarity and subgraph matching. Um you can prove theorems about it. You can derive cominatorial formulas for how to count all the instances that result from making these these swaps. And that allows you to be able to count for example we have we have an example with over 10 to the 100 solutions in real computational time just by taking advantage of this the structural equivalence. Um I have an example. So now this example is very relevant for some of the talks today. This is not a

mathematical proof. Um this is just an example from something we worked on um with DARPA about five years ago. But um the lefth hand figure is a template um for um uh for a problem from the biosciences related to um the cytoin storm in a co 19 infection. And we were looking at a very large knowledge graph um from lots of papers in the medical literature related to that. And we were asked um you know can we find any instance of this template in this giant knowledge graph and my group was able to

show that there's I think it was something on the order of 10 the 18 um uh matches for this particular template but and you might think well how can you even begin to get your head around 10 the 18? Well, you can because you can actually write down a vin diagram that shows you exactly how you map um nodes in this template. P is stands for a protein um for example. Um and then you have different colors that correspond to the different nodes on the left um that give you different um groups in the ven

diagram on the right. Um and all of this can be very nicely paired with large language models. um it can be used um in the same kind of way I believe in in terms of looking for mathematical proofs. Um and that's something I hope to be working on in the near future. Um I'll just say that much. Um and uh yeah I I so basically I'm going to finish by saying that there's a lot of beautiful mathematical um ideas um you know constructs things that we can actually get our head around and prove theorems

about that are very important. um as pieces of solving these puzzles with AI and language models and all of the things people have talked about today. So, thank you very much. Too many of these things. Okay. So, we'll start with some panel questions. So, u I guess maybe I'll start. So, we um might be a broad question. Um so, for each of you, what are you most excited? >> Oh, yeah. >> Okay. I'll just question. How do that work? Okay. So, um yeah. So what excites you the most about um about AI for mathematics

and what what are your greatest concerns about all these new technologies? Um >> oh man start uh I think I'm most concerned about is this on by the way? >> It's good. Okay. So I'm most concerned probably about students uh getting demoralized at this point because you're get just getting started in a field and you know it looks like there's a massive supercomputer aimed at your research and uh you know maybe the the goal for them is to get it you know working with that

supercomputer and so I think like we don't have I don't think anybody has really good advice to give them at this point and I don't know what to advice to give students um so yeah >> yeah This is not on. >> It's on, but it's kind of >> It's on but it's quiet. Oh, okay. Good. Okay. So, I I mean I see your point, but you know, like as an as an analog to the combinatorial complexity, maybe the right answer is to tackle that head on, right? And and more importantly, when

you're working with students, I mean, you definitely don't want them to get scooped by open AI, right? So I think we have to think we have to use our own c creativity and their creativity to think what are the important questions we should be asking that they're not asking right and uh you know like go from there I guess um I I think there's more to be done than what they're doing. I could be wrong. >> I agree. I'm just saying it's hard for them to see it. >> It is hard for them to see it. Yep. Yep.

But maybe if I I may like just like an advice you can give to students is that the more of an expert you are, the more you can extract out of those models. Like you need to be really really good at what you do, at your craft, at knowing the literature, at understanding an argument. >> So they really should not be demoralized. In fact, it's kind of the most exciting time ever. >> They should use it to their advantage. In other words, >> I agree with that, too. And there are

some students like that. But you should see there's many students that actually kind of almost resist using AI tools. That's that's the the trade-off and they should they shouldn't do that, right? We should be teaching them in classes. So like in my class for example that I'm teaching, I'm teaching a very applied class on optimization in PyTorch. And so uh I teach them in the class like how to use like for example prompting skills, things like that or like um you know what are the best models, things like

that. I I bake it into the class. So >> any excitement? >> I think that the obvious excitement not just for math but for science in general is just you can do so much more now than you ever could before. I mean I mentioned like the work that I do with the innocent center and you know what attorneys again are spending months and months of time doing can do in five minutes. I mean not to say that this is going to replace the human being in this process for sure not. Um but just the amount of um you know potential that

this has to have impact. We're talking about like you know life and death things that can now be done like this. I think that's extremely exciting but also worrisome at the same time for obvious reasons. >> I think Damik had a good example with the the convergence proof. >> Right. So certainly I mean what I like I have a student who's trying to prove something in numerical analysis and there's a lot of like annoying calculations that had to be done and I mean he just went he just like conquered

this thing you know with a combination of chat GPT and and his own ideas you know and and waited through it I think much more quickly than um a student would have done 10 years ago. >> Yeah. Yeah. I think the biggest difference for me is that I can try all of the idea. I have a lot of ideas. Most of them are wrong and I can try all of them one after the other and just go away and try you know leave it for a while and then check. That's like super hard. >> So I have a question for for the

mathematicians here myself which is if you're interacting with an AI that's online and you start following a line of reasoning, it's going to be learning the thing that you know which is then going to introduce it to the rest of the world effectively. any comments about that? >> I I have one. >> Yeah. >> Um yeah, I I I guess to me and maybe it's easy to say that from being in OpenAI, but it we have to remember why we do what we do. I mean, it's nice, you know,

to prove more CRM than your neighbor, right? >> That you know, everybody loves that, but that's not really the goal of why we do science. We do science to make progress. And if if our ideas travel faster than before, >> it's a good thing. It's not a bad thing. Now I one thing that I have it >> is except if you're writing a dissertation, >> right? Yeah. So I mean I I'm not sure about that even even about that. But but I think what what we're seeing one thing

that I'm seeing is that there starts to be some some different groups that emerge where there are people who also do this for the competitive aspect. >> Oh sure. And and then for those people yes they want to keep you know whatever they are working on very secretive and you know nobody else should know about it and yeah maybe they should not use >> well but I mean could they use a small language model on a on a local machine >> you know so I don't know if we're there

yet with mathematics to do that I don't know if we're at that point >> but it's a question yeah >> I mean I love this point because like several years ago I learned from my own graduate students whose dissertation I was trying to protect fact that they were doing everything on a world public GitHub site like it was a new generation and they all you know it's just like >> nobody was going to scoop them because they were ahead and this was their main thing and >> and people may not know to look at that

student's work >> right but it accelerate the field so I love your point >> yeah okay I guess we're already kind of opening up so maybe are there any questions from the audience Yes. >> Um, one one analogy that could be drawn is to the trajectory that chess has taken over the last 20 years. Um, how do panel members feel about how close that analogy is to the situation in mathematics? >> Well, I didn't hear the first >> the analogy of chess. So, you know,

chess computers have been superhuman for decades, but people still play chess >> but in different ways. Now, >> I I'd like to tackle that one. Um so I mean chess is a very I mean chess is a very scripted game with very specific rules. Um for mathematics you're looking at a very large space of information that's already out there. So for example, knowledge graphs I think play a can can play an important role in in mathematics um in in interacting with an AI on math but I don't see as much how that would

work in chess just as an example right so I think I think the space is just very different the other thing is that as an applied mathematician I I like to work in a in a playground that's bigger than just math right I like to I I look at math as a language for the rest of the world and So this also gives us access to the rest of the world. we can think we can think beyond theorem proving and we can think okay how can we use mathematics to solve problems in chemistry in in physics right in other

in the social sciences right and and I think that the model that's going to be developed for mathemat is being developed for mathematics I think at some level although it won't be lean code necessarily it's going to be maybe a a broader structure that's less rigorous could also have have this interaction action with the rest of science and the rest of the world which is very exciting >> followup is Mark's point more that people still play chess because they want to play chess even though a

computer can be so I think that is also analogous right that even if say ai could you know in x years solve every problem that any of us mathematicians ever want to solve we would still want to be mathematicians we would still want to train students to critically think and so forth right so I think there will always be a need for that and so this fear that like AI is I'd replace the mathematician. I don't particularly subscribe to I think it will change, you know, what we do and what our focus is.

But I completely agree with that analogy in the sense that like, yeah, we still want human beings to think critically regardless of what the the end use is. I think that's a valid point. >> Maybe I could just add a comment to that. Um, so the the chess computers are very good at at doing what they're doing, but they are not good at telling us why. >> So why is a chess position good? >> Yeah. And that puzzle I think is what drives humans to still do the games. Um and so

in some sense even if you had an oracle that can you know give it an example it will compute whatever you want in mathematics I don't think it will solve the question for us as humans because I think the question of why will still exist same way that it will exist in science. It just will enable us to do much more with it >> as it did in chess. And then you get to, you know, games with more than one player, right? Like bridge, right? Where you have, right, where you where you have conventions and so there's

communication between players that mean something and it could be different for different groups of players and that starts getting outside the box of and that's just a simple example, right? Also um if we consider the tools that we're using for scientific problems with chess you have a set of rules right you're in a confined space you have things that certain outcomes that can happen but we still need to train people to understand what are the interesting questions to ask and what are the rules

to impose. I I've used a lot of these AI tools to answer some of the problems that we're researching, but you have to ask it the right question. And I think that's an interesting point. I think in the examples I showed too, I'm getting the data from an experiment that's already been prescribed. They know what they're attacking. They know what the question is. So, I'm just helping them um get feedback on what the data is saying. But I think there's still an open uh topic of how do we set them up

and give them the the properties that we want them to have. And then I would uh sort of analogous to mathematics, I've seen a lot of the AI tools do a very good job of connecting different topics and uh grabbing a proof that I would not have thought about that's in the appendex of another paper that's not cited well, but it's not necessarily creating a new field of mathematics and asking uh it's not creating a proof that it's never before seen. And I think that's where

mathematicians play a huge role on creating the the framework or the knowledge for these systems. >> Is anybody working on predicted markets using you know your tools for predicted markets? >> I was going to say we should defer that question to Niha Kurriigo who's over on the fourth row in the corner. Sorry for putting you on the spot. I think it's fairly big topic. Not too many people are working on it, but there are some people who are now starting to use more ML tools for this week to try to improve their

forecasting. >> I I should introduce Mihi who's a new faculty in our department um who's heading our financial math program and has worked quite a lot in machine learning applied to financial mathematics. Yeah, >> we have a deep bench. Okay. >> Yeah, we have a deep bench. Yes. >> Yes. >> So, I was curious if you can speak about the sociology of using AI in math. You represent I feel like a biased subset of the people who might be out there, but maybe I'm incorrect of of who's

accepting and what do people actually think of the use of it in like I hearken back to 10 years ago when people in physics said that's not physics. Now, everybody's kind of >> well, if it works, it works, right? So, um, that's a I mean, I'm old, so at least older than the rest of these people. Um, I mean, I remember back when latte was invented, right? Um, you know, I mean, I was hand I hand wrote the first draft of my very first paper in pencil. Um, and and was just learning

like I was we didn't have latte actually when I wrote the first draft of my paper. And we, you know, we've seen mathematicians, different mathematicians at different rates adopt, you know, different kinds of technology to help them do their work. I think that um and also the use of computers, I guess, you know, and so, right, I remember when desktop computers first came into God, I sound really old, right? I remember when CD players were invented, right? So um um I mean this is just a recurring theme I think in the

20th and the 21st century um that we're just seeing more and more technologies being adapted. What what's novel about this is that that that we're using AI now to really get up to really help us with state-of-the-art mathematics right with the improving. So that's very new. But at some level it's sort of a you know it's it's a lot of it I wouldn't say all of it but a lot of it is kind of a uh you know just a reorganization of what people have been doing for many years right um you're

teaching you have a machine that can do a lot of a lot of kind of repeatable extra I mean I remember when when we didn't even have anything on the internet and the papers like the internet was the arp I remember when the internet was the arponet right um back in like the 1970s god I feel really I can maybe answer that a different slightly different way. So, um I've kind of been using these since like the beginning with like co-pilot and uh nobody was really none of my friends were using them.

>> Um when I got to last year, I went to the Simons Institute program on LLM and generalization uh in August I guess 2024 and nobody was really using them to do any research or anything like that. I think 01 came out and uh you know people started trying to solve problems. It wasn't that great, but it did it did some things. But like I was very surprised that even within the people researching these like the more mathematically like learning theorist people like that, nobody was really

using them. And it wasn't until this like I would say March this year when like Gemini 2.5 Pro came out, that's when I started seeing more and more people being convinced because it it became like a very reliable tool with that particular release. And then of course many more models have become more reliable this year. So I think it's like a limiting factor of like patience with new technology which a lot of people don't have. They expect it to be better than it is immediately and I like I have

just a lot of patience for it because I like software. Um and uh you know just like knowledgeability like you know I was showing a colleague yesterday some prompt I wrote and he was like you write something that detailed and I was like yeah it's like otherwise you're not going to get the result you want. So, it really takes a while to get up to speed with technology and even people working on the math of it aren't up to speed or at least weren't. >> I would actually expect that our

students may be better at this than we are because they're, you know, they grew up with a lot of, you know, stuff online, right? They they do everything on their phone, you know, right? So, I I I'm I'm less concerned about the students getting into this than other people might be. Um, I think there's going to be a different filter, right? I think that's what we're going to see. They're going to be some students who are very have a lot of aptitude, right, for this sort of thing. And then they're

just going to gravitate to us and they're going to surpass their adviser very quickly in the use of these things. And then other students who may be, you know, like hitting a wall, but that happens with any new >> idea. Yeah. Stan. >> Okay. So, I'm probably one of the senior members here, which is incredible. Yeah, he's older than me. >> By about 20 years, right? Yeah. >> I got here in 1976 and numerical analysis was regarded suspicious asthmologist what people used for

>> Oh, yeah. Sure. Oh, yeah. We all have stories like that. >> Then we went through wavelets and so on which are very trendy and exciting. But this is unique. I've been here on this planet for a long time and this is the most excitement I've seen. the breath and the and the >> number of people interested in what thinking they can use it. It's incredible. >> Yes. >> And uh don't dismiss it. >> No, I'm not dismissing it at all. >> I mean, what is worrisome is jobs for

these people to get out of here. >> Yeah. >> Because companies can do a lot of these things. >> Yeah. >> That's a serious issue. >> On the other hand, the companies are going to need people who know how to use the AI. >> Not that hard. >> True. >> I can do anything. Yeah, whether you have to use the reinforce learning and from human feedback essentially what happens there you all expert and then so the AI itself alone won't be able to actually get 100%

prediction >> that's right >> and then have you considered to have like human yourself in a loop and one of the very used by alpha go and alpha Definitely. >> Every time you prompt, you're kind of in a loop, right? >> No, but like reinforcement learning, right? >> You mean like Okay. Beyond like actually changing the weights of a model >> and not just the weight, but also systematically like give them a reward and basically using forms kind of framework help the feedback closely, not

just at prompt level but more deep in your actual training process. Yes. >> Um, okay. >> I have a question. Like if you guys could wave a magic wand and get industry to build absolutely anything for math, what would you ask for? >> Industry >> like AI industry like >> like a private tool um where I it could record all interactions that I have maybe like a glass new glasses etc. Because when you do math, you don't just do it like at a computer. Although I do most of my work in tech. Um, but you use

whiteboards. You, you know, you speak to somebody. I have like a chat history with somebody that's over 10 years long where we're like just figuring out problems. If I could input that in like privately and I had some sort of like IDE like that would help me, you know, learn the styles that I have without giving it away. I'd be very happy. >> Yeah. Like a like a medium language model that could that could live on like its own little space, right? >> Yeah. like some kind of federated

learning model, right, for this stuff would be very interesting, but that's that's tricky if you're going to run it in the cloud. >> Yeah, >> I would want something that has transparency. So like uh if the if something could explain what the text embedding does, like what that represents for a lot of the applications that I work on, I need to understand the why, like has been brought up here. Um so something that has the ability to answer, okay, so you gave me this output. Why was this case for example

put in this pile? why was this patient labeled this way um that clearly you can get a little bit of that obviously but I think there's still a lot of opakqueness um that would be you know I think that's something down the road that is possible that would be my wand so I was so along those lines hallucinations right you want something that can check that carefully the other thing that we came up in a discussion was it last night with Terry I think about um like if you're if it gives you ideas for a

theorem um to be able to track the what is the word I'm I'm thinking of >> openness level. No, it's Yeah, that but that go ties back into the hallucinations, but more of the the literature, right? So, in other words, like if if it the idea shows up in a in an obscure place in a paper, you want to know where it is and you want to know that accurately so that if you're going to write a paper on this that you can accurately cite the literature rather than just sort of saying I, hey, I came

up with this idea because that's something that's important in the way we do mathematics is to give credit to the previous works in the literature. Um, so I' I've noticed that I mean just every time I which I don't do it that often, but asking AI questions about mathematics, um, the the literature is a real weak point, right? It'll it'll constantly get names mixed up. >> Specialist tools that do that, but they're not really integrated. >> Exactly. The main Yeah,

>> I have one more answer to that actually. So I so um I think a big bottleneck to using these tools is making it easy to verify what they say is correct and that can be like it not lean formalization it could just be the way that you present the the the mathematics. So um for example we were Terry and u Pata who's a professor Irvine and I were building this benchmark uh or not benchmark but basically like a list of constants that appear in optimization um in in in different branches of mathematics that

you could try to solve. um and I wanted to add like a lot of constants that were like um let's say in areas that I didn't understand like number theory or something like that. So I have to really figure out a way how I can verify these references without being like um you know an expert in the field. And so I figured out some like way to hack together a prompt where like I cite the exact sentence level details in different papers and things like that. But like if I had that ability to actually really tell that this was

correct or at least like uh just the data is presented to us in a way that is palatable then that would be ideal and it's doable. It's definitely doable. >> Well related to that just yeah as I said if an LMF would come with confidence assessments of each of its lines each paragraph I'm 80% confident this is true. I'm 100% confident it's true. I'm 20% confident. That would help a lot. >> Yeah. >> In a different direction. So all the examples I showed in my slides,

everything's built in house. So these are our architecture is taking inspiration from large language models, but we have to train the weights and the and prescribe the data ourselves. So I would like to have more than four GPUs. That would be helpful. >> I know. How does the students now can use open tools which is amazing right? We should encourage that. But how does this change our uh both the definition of learning and the assessment of learning when it comes to students? >> Um so in one of my classes I actually

allowed them to use um some of the AI tools to do the proofs for certain homework problems. However, they had to verify that it was true. So they are using it to interact with the tools in a smart way and also if it was wrong to have to correct it. and I graded them based on what they did, not what the AI tool does. And I think um so going back to a previous uh comment about when I was trained as a mathematician I was trained based on proofs and later I got into computing and I taught I I feel like programming was an add-on to my

experience and now it's a tool that we use everywhere and I feel like this is just going to be added on to our um education as another thing that you should learn and how to uh use it in a proper way. How would your advisor? >> Okay. Yes. >> Um, so I think the power of AI comes from creating new knowledge and such an AI doesn't exist yet branded by different it does creating knowledge. What do you think would be needed in your field to create an AI that generates the knowledge? Can I go

back to more than four GPUs? >> Just a question like why why just four GPUs? Why not cloud? You're like like fully elastic like >> oh what? >> Yeah. Like why are you stuck four GPUs? >> But why not go cloud like to an elastic infrastructure? >> I think we are restricted at UCLA for cloud computing. I don't know. I'm not I'm not sure what the restriction is. >> It just seems like that shouldn't be a problem. Like you shouldn't be stuck there.

>> Just ask for the money for the for the cloud. >> It's the money. We don't have >> startups are pretty resource limited and like do not run into into that like so it's it's I wonder what that policy comes from. >> I can discuss it offline if you would like. Yeah. >> Going back to the >> Oh, yeah. So, did you do you want to follow up or >> No, >> I don't think we answered the question. >> Yeah, exactly. >> Okay. >> Eight years. So, I maybe still takes the

roughly average five years to get a PhD. Um, what with AI help a lot of these non value adding activities you see your students potentially can get to the PhD maybe two years, three years or is the bar? I I think if they if they if they use it correctly, it could. But um I mean, I'll just be frank, having trained 58 PhD students in my career, um not as many as Stan, but um I I there's a lot of bottlenecks to getting a PhD that don't have too much to do with the kinds of issues you're

talking about. Um students can spend a year or more just trying to find their way in what they want to do. Once they especially if they're a good student, they pass their qualifying exams early. Um but they're they're not, you know, passionate about a specific problem. They can kind of take classes and float around for a while. I think that's the biggest time sync in terms of the time to PhD rather than what you're talking about. What you're talking about is important. And I think once they're

really like geared up and working on things in a serious way, yes, this will definitely speed things up. But there is that, you know, intermediate period. That's a different matter altogether. It'd be great if AI could help with that too. But that's a different level of AI, right? That's not right. >> I think that points to like what are you curious about? What are you motivated by? And like AI tools can like supercharge you in that direction if you find that thing, but it's not easy to

find that. Andrea basically just described my PhD. She wasn't my PhD advisor, but at some point she almost was. Um, and I floated around for quite a while and it wasn't until my fourth year, my PhD after like switching back and forth between like computer vision, low dimensional topology, like a bunch of different things that I decided that I wanted to do optimization. And it's just because I felt it. I was very motivated by it. But it's not like something you teach in some sense. You

like are introduced to it. Maybe you find a motivating speaker, maybe not. I just really liked algorithms so I picked that. Yeah. >> Okay. Question. >> Yeah. Question. So I think uh you know what you guys think about the progress right? So Terry mentioned this verdos benchmark. I guess the model hasn't really solved an acorn problem. So when will that happen? And then model really good at hill climbing these benchmarks. when the stretch part will be just mostly solved and then at the rate of

progress when do you think the AI can actually win a field medalist >> it's already got a Nobel Prize I guess >> how do we measure the age >> um I I don't know uh it's it's well Yeah, I think we'll be surprised. Um, my personal belief is that AI is best optimized for slightly different tasks than humans are. And so, and all the all these medals and things are sort of aimed for human achievers. Um, so I think there'll be other medals in the fles medal that will be sort of suited

for AIs to to to attack. I mean, I mean, of course, there best press if you can kind of compete with a human headto-head. Um, I don't know. Uh it's uh yeah wait and see. >> Yes. >> Um in addition to being an automated theory setting lean is a programming language. So I was wondering if anyone had thought about >> what >> lean is a programming language. >> I don't so I was wondering if people had thought about tighter integration along those fronts. Right.

Okay, >> you can do your computational simulations in the same language that you would do your version, >> right? >> It's it's a lot slower. >> Um, so I had a I'm in a project where we just spent a few days trying to work out that log 2 was 693. We we now figured out how to do it reasonably efficiently in lean, but this was actually a trivial task. Um so yeah it gives you this 100% guarantee but there is the big trade-off with performance. >> Uh I I read something on the uh

foundation blog and it says uh AI is like a giant without vision and as human we are trying to give the the vision to AI or something like that. So I told my 14 years old on my way here like uh before I dropped him and he said this who likes to use and he said it must be uh wrote by by a mathematician and I was wondering if he's right. >> Okay. It's an interesting analogy. Giant without eyes one of the vlog. >> Okay. Um yeah >> question. >> Yeah. Thank you. Um I have a question

about this semi-auto and automate automated theorem proof. So I think there's still a missing piece um because you need human involvement expert uh guidance. Suppose now you are given 10,000 GPUs running for a year resources. How would you scale it? How can you make it truly automated or in a way to automate it as well? I don't know that it would be fully automated in the end, but I think you could, you know, build a good harness and that's like what a lot of companies have have done recently. So like for

example, Axia Math is a company and they've just built basically a harness around I think maybe even I forget which model they use maybe something like a coin model or something like that, right? And uh they didn't have 10,000 GPUs but they used I think um uh thinking machines cluster this tinker and they got a pretty good model. they prove some results. Um I think like there's a lot to be eaked out of getting a good harness still. That's the immediate thing that I would do around a

>> more. >> So a harness is, you know, like basically building like teaching the model to use like let's say the coding environment or like read a paper or use different tools and things like that, right? And you can apply like RL on top of that to see like whether you were successful. And I think a lot of people have gotten mileage in the last six months out of building a good harness. Um so for example in one of the papers that openai released for for example that uh they mentioned that they had a

harness inhouse that was like two could work for two days straight or something like that and I think I think that was what it was that you had >> yeah in fact I will I will talk about it briefly this afternoon. >> Okay. So Seb will talk about those harnesses. I think there's a lot to be squeezed out of harnesses still um for these models. Um so I I guess I'll just >> Okay. One final question though. Yes. This is kind of orthogonal, but we all know that uh AI uses an awful lot of

electricity. Could you embed an instruction in AI to tell it that whatever it's doing, it has to find a way to use the minimum amount of electricity to do it. >> Yeah, this is a great problem and it's something that I've been thinking about and and just got a little bit of funding to work with somebody on a position paper exactly on this issue. So um I don't have an answer to your question but I think it's an important one to be asking um and it's and this is definitely something that also dovetales

with some of the research that I spoke about um today in that um there are ways to take um you know algorithms that run say on GPU CPUs instead of GPUs and do very very good calculations and pair them with you know things that have to run on GPUs language models and things like that. And I think we should be looking at those questions about how to best design algorithms to be not only top performing but also um looking at the power consumption. Think about the an the analogy with the design of automobiles, right? I mean, we went

through the whole leted gas unleted gas thing. I remember that, right? Back in the 70s and so forth. And now we're going to electric vehicles um and and looking at more efficient cars. And so there's been this pro progress of different design models for the automobile. And I think our algorithms also need to go through that at some point because we could say we could potentially save a lot in the the power needs, you know, for these models. And if and by doing so, you can do even more with them. So it's not necessarily

going to curb what you can do, you know, it could actually be a win-win situation. So really, really good question. >> That's a great point to end the panel. So, thank you very much for lunch. >> Yes. I just want to remind everybody lunchful Capital for sponsoring it. Please join us. Hi, how are you? The problem is confidence and before I originally not a dog initially but in the end of So good. Naturally something very high definition statistical train. So still people believe underlying structure is so complex to

describe more humanly understandable such as so that's why that's why I think a lot of skills are related to medical doctors with the fact that some of these things are reading the X-rays fail So the current AI is that they're best at at at sort reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them

because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes. when we use AI in these research fields, how do we ensure that it is accurate, that it is reliable? >> So, first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um, in mathematics, we are fortunate that um

that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as can trust outputs. I think uh there's a lot of emphasis

currently on on trying to make AI replace human scientists and try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit. there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for

instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh Gary on So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean so so first of all that's half of what science is. you know, we we do literature review and and we we try things that work for other people and we replicate them because no single human

knows the entire literature. >> So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um

that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as that can trust his outputs. I think uh there's a lot of emphasis

currently on on trying to make AI replace human scientists and >> try to do what humans do best. that actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for

instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single

human knows the entire literature. So having having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um

that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as that can trust his outputs. I think uh there's a lot of emphasis

currently on on trying to make AI replace human scientists and >> try to do what humans do best. actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for

instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single

human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want

um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as that can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI

replace human scientists and >> try to do what humans do best. actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of

these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So

having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want

um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI

replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of

these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So

having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want

um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI

replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of

these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single

human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um

that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis

currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of rightful automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for

instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single

human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um

that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis

currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for

instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single

human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want

um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as that can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI

replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of

these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single

human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um

that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis

currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for

instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that work for other people and we replicate them because no single human

knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want

um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as that can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI

replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of

these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single human knows the entire

literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want

um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can you can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI

replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of

these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and we we try things that work for other people and we replicate them because no single human knows the entire

literature. So having having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want

um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently of on on trying to make AI

replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of

these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and we we try things that work for other people and we replicate them because no single human knows the entire

literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want

um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently of on on trying to make AI

replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of

these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and we we try things that work for other people and we replicate them because no single human knows the entire

literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want

um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI

replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of

these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh carry on that. So the current AI is that they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single

human knows the entire literature. So having having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um

that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can you can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis

currently of on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for

instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. >> So the current AI is that they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people

and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win >> and I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that it is accurate, that it is reliable? >> So, first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in

mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can you can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs.

I think uh there's a lot of emphasis currently of on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area

of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for

other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win >> and I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in

mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs.

I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area

of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. >> So, the current AI is that they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and we we try

things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win >> and I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to

benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can you can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use

AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean

right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. >> So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and

we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to

benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. In the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use

AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean

right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and

we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to

benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use

AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean

right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. >> So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and

we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So, first of all, it it works best when it is performing a task that you already know how to do and you know how to

benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use

AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean

right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and

we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win >> and I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to

benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use

AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean

right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and

we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to

benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use

AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean

right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try

things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to

benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use

AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean

right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI, they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try

things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to

benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use

AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean

right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with car on that. >> So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and

we we try things that work for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win >> and I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So, first of all, it it works best when it is performing a task that you already know how to do and you know how to

benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. In the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use

AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean

right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try

things that work for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in

mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs.

I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think it's now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area

of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people

and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in

mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as that can trust his outputs.

I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area

of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people

and we replicate them because no single human knows the entire literature. So having having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in

mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can you can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs.

I think uh there's a lot of emphasis currently of on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area

of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for

other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win >> and I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in

mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs.

I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area

of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that work for other people and we

replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um

that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as that can trust his outputs. I think uh there's a lot of emphasis

currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for

instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single

human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So, first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um

that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis

currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for

instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them

because no single human knows the entire literature. So having having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that it is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um

that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can you can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis

currently of on on trying to make AI replace human. Oh, hello there. Hey, there we go. Uh, I haven't heard you say anything yet. Can we go ahead and check uh the microphone? I just realized I can't hear you. >> Oh, okay. There we go. >> Headphones. >> I couldn't hear you either. Do you have a door stop here? Uh, it's probably just kicked around somewhere. As >> I was wondering if you could come back and we could uh check this out a little more. >> There you go. Hello.

>> I see I see a gray square uh like on your chair. Sometimes that's the window where like the other people are. And then also I want to make sure that you don't have an echo. $1,000. >> No, I do. I was thinking the same thing as >> what the window like It's still right because I can hear anything. I think there's some sort of a window in front of your computer that's uh seeing us seeing it as a kind of a black right there. >> All right. So, give us a minute. So,

very nice to virtually meet you and uh so give us a minute as everybody sits down and then we will we will start. Hey, can you guys see this? These robots. >> Now we see nothing. Now we see top screen. >> Okay. All right. So, uh, thank you so much. So, it's a great pleasure to introduce Rich Sutton from the Open Mind Research Institute, University of Alberta, who will speak about the future of AI. Thank you so much. Yeah, there's something that Okay, now it's >> okay.

>> Um, >> great. It's uh good to be there with y'all. I wish I really could be there. It's a little um uh a little disconcerting uh speaking to you from far away, but I I attended some of the morning sessions and I got a sense of what you were thinking and uh I I I I would like to make this as interactive as we can. So, please feel free to speak up or make noise and ask questions even as we go along. So I did my part for interaction and I I uh I I as I said I saw some of the early

early talks and I I I it occurred to me that I wanted to say some things that that I hadn't prepared and so I put aside a little time today collected some more slides and so I'm going to say a few things before beginning my planned remarks. So let's start with just the way the field is now and what do we think about it? What do people think about it? I think everyone is thinking that AI is making super rapid progress and uh it's all very exciting. Um but you know when everyone is thinking the same thing, we

have to question it. Is it is this really what's going on? And so I think we can question this and um is it really making rapid progress? I mean certainly um there's been there's been a lot of progress in making computers able to use language skillfully. I think that's a real breakthrough. It's a real pro breakthrough. We wouldn't imagine that we could use neural networks for this purpose uh not so long ago, but it's absolutely proven true. We've also uh just using massive amounts of

computation to generate realistic images and video. But really, do minds do intelligent things? Do do minds have to generate images? No. It's the one thing that we never have to do. We have to process images. We have to process video, but we don't have to generate uh images or video. This is not something that minds do. It's it's something that takes enormous computation and is hard to do, but it's not something that is really a part of what we normally mean by intelligence.

Um, yeah. So, there are also new real applications that have led to whole new industries and new ways of, you know, making economic value. Most of these uh new things, real big important things are applications of super largecale computation and super large scale pattern recognition. Um they are very particular things. They're not all of intelligence. Um and a lot of it is just computation and we tend to call it intelligent just because it makes it sound more important to make it intelligent.

Um, so I have to ask you, you know, is the science of AI making rapid progress? Well, thank you for a laugh. I feel now like I like I'm married. Um, yeah. So, so I'm thinking not so much in my not so humble opinion. Uh, there is I think there's little understanding and lots of tweaking behind uh AI. And so we don't know principles of mind, principles of intelligence. It's in many ways as a science it's very unsatisfactory. Uh and I tend to think when I that a better way to think about AI models is

that they're they're they're powerful in the sense that they're informed by all human knowledge. But otherwise they are weak. They are weak minds. They're unreliable. They don't stay on topic. They meander. they they're not really at all powerful except in the sense that they have a lot of knowledge. So well maybe that's a different way to think about about uh what we call AI today. So what is this thing we call AI? Well, it's it's artificial intelligence.

So we have to define intelligence. Um and there are many definitions throughout the years of it. And so I I have some more prominent or author authorities authority authoritybacked definitions. So perhaps the oldest one is due to William James the founding father of psychology. Psychology is almost the study of mind. Um psychology 1890 William James he didn't he didn't actually talk about intelligence he talked about mind. mind. The hallmark of mind, he said, was attaining consistent ends by variable means. That means vary

what you do to get a consistent outcome, which presumably is what you want. Um, consistent ends by variable means. Now, uh, you can also, uh, ask Alan Turing, you know, what what did he say intelligence was? And he actually didn't come up with a pity quote, but he he he's been interpreted as suggesting that intelligence is is basically behaving like a person. And the touring test is a phrase that we use nowadays uh to talk about imitating and pretending to be a person. And I touring of course never

called it the touring test. I don't think he ever called it a test. I think he called it an imitation game. uh it it was a way it wasn't a test. Anyway, nowadays this is taken to be an important meaning for what we mean by intelligence behaving like a person. Um but yeah, I don't think it's what makes us powerful. People are powerful because they're intelligent and therefore uh people uh we we We look to behaving like a person, but it's really what it is that a person is that is important. So

what is that thing? Well, if you look in the dictionary, the dictionary might say intelligence is the ability, this is what it says on on my computer, the the abil intelligence is the ability to acquire and apply knowledge and skills. I think this is actually pretty good. Pretty good. You know, it's all about knowledge. It's about acquiring knowledge. It's about having knowledge and acquiring knowledge. and uh um and skills. That's a pretty good meaning. Uh if we go to the AI side, the founding

father of AI, one of the founding fathers of AI, uh John McCarthy, he said he defined intelligence as the computational part of the ability to achieve goals. So just I really like this one. I want to go through it a little bit. It's notice it's a computational part of this ability. Actually, maybe first notice it's an ability. It's an ability to do something. And like all abilities, you can have them to various degrees. It's not intelligent or non-intelligent. You just have have uh to some degree an

ability to achieve goals. And it's the computational part of that ability. It's not you're not achieving goals just because you're um stronger or you have better sensors or something like you've got to do computations. You got to do uh something mental and that is how you are achieving your goals. But and then achieving goals is almost the absolute heart of it. It's all about achieving goals. This hearkens back to William James who said a consistent ends by variable means which is what it means to

have a goal. Um yeah so I like that definition but I jumped into the game too. I made my own definition sort of taking off a little bit. I would say you know the ability to achieve goals by adapting behavior. So my definition of course definitions are a dime a dozen like it's okay every word has has like six definitions. uh and definitions are not are not even uh by authorities are not important. Uh we we make definitions that we can communicate with each other. It's okay for them to change over time.

But yeah, if we have widely different definitions, it's hard to communicate. So anyway, I'm saying I'm suggesting that intelligence when I use the word I mean the ability to achieve goals by adapting your behavior. And the only difference here perhaps is the word adapting. So I'm thinking that learning is important, the the acquisition of this knowledge and skills is particularly important, not just having it. Uh okay. So there are some different views. Um and we could try to stack up the modern

approach to AI or or meaning of the of the word AI. It's all about computation and it's all about pattern recognition. And I think many much of it about is about behaving like people. Um now let me go a little further with my personal perspective is I think there should be a new science a new a science of mind integrated science of mind. Uh this is what I try I imagine myself as doing an integrated science of mind that applies equally well to people to other animals and to machines. You know

because all these minds they all have essential commonalities people and animals their minds are very similar. Uh and machines are starting to have commonalities at least we have ambition that they would have commonalities. In the foreseeable future many minds will be machine minds and there there doesn't really ex have there isn't a really an existing field um which sits easily in this role. Uh if you ask you know psychology is it a science of mind? Well it could have been I I wish it would become but over time science

psychology has defined itself more and more as a a study of natural minds of minds in people and minds in animals and not in in what minds could be. the generic idea of minds that could be in a machine and artificial intelligence is concerned with the machine but it doesn't really consider other things and it it's it's become very much an engineering endeavor. It's all about making something. It's not really about much about understanding it. Uh and it doesn't include the natural minds.

Cognitive science cognitive science has has drifted in many different directions but has has drifted mainly towards uh natural minds. So unfortunately none of these really seems to play this role of a of a science of mind integrated science of mind across these different um unified across all the different minds. But I'm but the thing that I'm working on reinforcement learning is perhaps the beginning of such an integrated science of a mind because it does span uh all the many fields and uh anyway that's the

way I approach it but maybe it's the beginning of of it. Um what is reinforcement learning? I should say a few words about that. You know where I'm coming from uh if it isn't already obvious. Um reinforcement learning is agent oriented learning. learning from experience, interacting with an environment to achieve your goal. And it's in in these senses, it's more realistic uh and ambitious and autonomous than other kinds of machine learning because the agent is out there. It's doing things. It doesn't have a

doesn't necessarily have a helper. Uh so it's more autonomous. It's more ambitious because I don't I don't assume great help from the world. like just you interact with the world with the world and you you see if you're achieving your your goals and you change your behavior to achieve that goals. So this is also more realistic. Um you know animals don't have great health from their environment. Maybe when they're when they're growing up they do but but uh not in their normal life after they're

they're adults. And so reinforce learning is all about trial and error. Learning from with delayed feedback. All you have is a reward. Did you eventually get what you wanted? This is the kind of machine learning that's most like natural learning. It's learning that can tell for itself whether it's right or wrong. Like large language models have no way of telling when what they're saying is right or wrong. But if you learn from experience, you if you make a prediction about what will happen, you can see if

it's right or wrong. If you do things and you can have a reward, then you can tell if what you're uh behaving is a good way of behaving or a bad way of behaving. So maybe this is the beginnings of a science of mind that's neither natural science nor engineering applications technology. Okay. Did I want to say one more thing? Oh, I wanted to give this quote from Alan Touring. Alan Touring, he didn't realize he was a reinforcement learning person. Um this quote is from 1947 before there

was reinforcement learning before there was AI really there was no as far as we know this is the first ever pres public presentation on artificial intelligence in in the world 1947 in a in a lecture. Okay. So I want to make all those remarks. I hope they were fun. Uh now today's message and and with this with this preface maybe I won't get to all these messages but I want to do at least the first one and the last one. Uh the first well let's just delve into it. Okay the first one is about what's the

scientific trend in today's AI and uh the main message is that right now we're in this era of training from human data. All of our ais are trained, you know, principally they're they're they're trained to predict humans next words from the internet or they're they're trained to predict the way humans label pictures and then they they are subsequently fine-tuned by human experts saying I prefer this answer rather than that answer. I prefer you to say this rather than that. And the purpose of all the

modern machine learning is to transfer knowledge that already exists that people already have uh to the machine and the machine is then static and no longer learns. That's just the purpose of most modern machine learning technology we have. Move it to the machine. The machine will then be frozen, no longer learn. Okay, this is this is the era we're in. And I think we're reaching the limits of this era uh because we're reaching the limits of human data. We've already consumed

most high quality sources, the whole of the internet um and and pictures and videos in it. And you know just the principle of limitation is that this approach can't learn anything new. It uh it can't generate new genuinely new knowledge. is like Terrence was saying today uh we they we don't really have progress on the really hardest erdos problems the hard things you know gen doing anything genu generally genuinely new is beyond this approach because it's based upon looking in the internet and

seeing what people have already said and then and then summarizing it um okay so but I think to make further progress and We are doing this now. We're entering this new era where we're learning from experience. So we need a source of data that because ultimately because we need a source of data that grows and improves as the agent becomes more capable. Uh in this way no static data set would ever could ever be sufficient. Uh and you can get a changing data set from your experience. Um and this way as I said people and

animals learn. It's really the way successes major successes like Alph Go learned to make its creative move 37 and uh it's it's the way many of the mathematical u uh Olympiad winning agents uh worked as well. So I'd like to give this video I hope this comes across. Uh actually maybe I should mention this this little picture in the corner just to make it clear when I say experience learning from experience I don't mean any weird fuzzy thing like you know uh uh how it felt or something like that or

the qualia. I just mean the data going back and forth between the agent and the environment. the agent, you know, does things and it perceives things. So, it's these three red things, the observations that the agent gets from the world, the sensor data and the actions, the motor twitches or or um uh voltages sent out to the world and also you get back from the world a distinguished observation which is a scalar which is your reward. So, those three things that's what I mean by experience. This is what we this

is what we get interacting with the world. And this is the only thing we can really know for sure. And um okay, so we need a data set uh that grows and improves as the agent changes. And so this video suggests how that works in our lives. So the most important way. So this is an infant a little bit sped up. Okay, don't worry about that. Um, it's a little bit spit up, but as you see, it's interacting with all of its toys. And it doesn't just work on one toy. It works on one toy until it gets bored, and then

it moves on to the next. And each time it encounters the toy, it learns what it can learn. Maybe it just learns from the string that it can pull on it and and put it in its mouth, do this, and do that. Uh, but then it it moves on and changes its experience just to see what it can learn from the new thing. Okay. So this is this is our data. Data of life is generated by our activities and it's not provided to us. And because it's generated by activities, it can be leveled to our level, our level of

understanding and and ability and skill. Okay. So that's the basic thing. I also threw in this video of an an agent learning in a maze. A very simple, super simple agent. It's trying to go from start S to goal G. And uh all it knows is what cell it's in. And it's doing one or four actions up, down, right, or left. And it can learn a good a good path to get there. The path is shown by the arrows. That's what it thinks is the right way. And the green shows how good it thinks each state is. But the world

uh is not static. The world changes. We always have to learn new things. And so, um, yeah, while we're learning, we can also look at this diagram. This is how the agent works. It's got the main things. It's got a a model, transition model of the world up here in the right corner. It's got a policy that says what to do. That's what the arrows show. It's got a value function that shows how good each state is. That's the green. Uh, okay. So, now I've moved the goal up

in the on the top. It goes back where it used to be. has to stumble upon the new location of the goal. When it does stumble on it, it can learn uh the path to the goal and recover from the changes. And so this is general generally what sort of a simple case of what life is like. Uh you encounter changes and you adapt to them. Here we stuck it in the corner. We'd adapt to that. Uh eventually figure that out. We stuck it down here. It learns a new path to the goal and uh you know we can intervene further

here. We move in and we put obstacles in the way and it finds its way around. And so so it's got a sense a compelling sense for us that it has a goal and it's adapting to as circumstances change to keep achieving the goal as best it can. And of course the goal may become unattainable. And when that happens, you know, we can't help but feel a little bit sorry for the agent that that's unable to achieve its goal. Okay. Um, uh, I had another demo of learning by trial and error. There's a there's a

nice demo on on the on the web, but I couldn't get the couldn't get the YouTube to show. Uh, but uh, so we'll just skip that. Uh, yeah, I think you get the idea of learning from experience. So, let's talk about the principles a little bit. The principle of this experiential approach to AI is that the whole foundation is the agent exchanges signals with the world and those are experience and these signals are the focus and foundation of all intelligence. It's really the the the the purpose the definition of truth

is what happens in these signals. The definition of the goal is you you what happens in these signals? You want to get the reward signal to be high and you either achieve it or you don't. It's it is kind of a subjective goal. It's available only to the subject, but it's also like the most objective thing that could be. It's it's data that you're actually getting as an agent. So, uh we say that the elegant is intelligent to the extent that it can predict and control its experience. And notice that

you don't if you don't have experience and I keep saying that because uh look when when uh for example a large language model operates it's not learning at all from experience. You know your experience is something that happens after you're born and go out in the world and do things. And when you're going out in the world and you're a large language model you are no longer learning. You are frozen. You are static. So you don't uh you don't really uh have experience you know you have the

data the data was only would only be available in a special training period I mean you get examples of how humans behaved when you in the world you know you go out and do things you don't get examples of how you should have behaved okay without experience there's nothing for intelligence to be about no way to say that one thing is better than anything else because there's no goal. Because you don't have to reward, there's no goal. Language models don't have goals. There's no way to say if a

prediction is right or wrong. Uh because the agent never compares it to what actually happens. There's no sense of truth. But with experience, if you have the the interaction, the data, then there's clear goal. The goal is to get the reward. And there's a clear sense of truth, predictive truth. you make predictions and you see what actually happens whether they're true or not. So you know this is this is what you can do with an experential approach and I think the experential approach is going to

become is is becoming more common uh and more widely used. Uh we can break the recent uh decade or so into three eras. Uh the early era was the era of simulation where we would learn from simulated experience. This is what happened with Alph Go with the Atari games. Uh and and then more recently with the large language models we've been in the era of human data. Again this is all somewhat approximate. Um but we can see these switches uh totally you know fascination with large language models and then now we're realizing

their limitations. We're getting into agentic systems and computer use by the computers uh by the by the agents and and the models. And this is what we're what I'm calling the era of experience I think which will actually get us to superhuman abilities. abilities that are not just mimicking people and subject to the limitations of that those uh people but uh being going beyond their abilities. Okay. So to summarize that this first point on this trends in AI uh AI is at last turning to learning

from experience. Remember Alan Touring wanted to do it in 1947, okay, which was a long time ago. Uh but we're turning it last to to do it um uh rather than from human input. And this is going to be much more powerful because it can continually learn new things. And then despite the hype today and the fear even, I don't think Kurt AI is all that powerful. It's sort of weak and unreliable, but it is nevertheless super useful and has absolutely ignited an industry and created lots of economic

value and it's accessible to everyone. This has excited the public. It has it has done this great thing which has gotten people to think about yeah someday there's going to be uh machines that are as capable as people. Um it, you know, it's done it by by making people scared. That's they shouldn't be scared, but um uh they should be paying attention. So, this got gotten people to pay attention. That's good. But we've not reached the main event. Uh despite some of the hype, uh we've not reached

the main event of creating super intelligent AIs and super intelligent augmented people. This is a big deal. It'll bring profound change. Uh and uh I was going to talk about politics for a little while. I think I'll skip over that or maybe go to the almost the last slide. I have this slide. Um, uh, there are many calls, you know, just look around today. There are many calls for control of AI. You know, allow the AI to only have goals that are checked and authorized by people. Uh, they're calls to control to stop AI

research. there there are laws now that limit the power the computer power that it can be used for AI and you know there's so many safety institutes uh people say safety what they really mean is control they want you know they they tell you to be afraid of AI and and that might be unsafe and they want to be the ones to control it um and these remind me of this calls for centralized control of people as I want to feel sympathy and empathy For the AIS, there are controls for speech and what you can say and what

you can hear. What you can hear. There are controls on trade, you know, there are tariffs where you can work. Uh there are capital controls, economic sanctions on different countries. Uh and I just, you know, the main the main point is that these these calls for centralized control of AIS and people are very similar. They're eerily similar. They're they're based on fear. Be scared of the AIS. Be scared of, you know, the Chinese or the Russians. Uh you can't trust them. They are like

they're not hardly people. They're bad. They they don't love their children. They don't feel pain. Anyway, they are they are demon. AI is a AI. AI literally people say they they won't feel pain. and they uh uh yeah these these calls are very similar and uh we should resist them uh because I think uh human flourishing and AI us flourishing with AIs I think comes from learning and accepting that we should be cooperating with them in a decentralized way. We should not have uh big

controlling organizations. So, this is summarizing the the slides I didn't go through, but uh humans are great at cooperation, but they're also terrible at it because we like we have wars where we're not cooperating. Cooperation is not always possible, but it's the source really of all good in the world in terms of our economy and our exchange. Uh and um our governments, our all of our good things in the world come from cooperation. We have to look for it and support it. And if we look

for open eyes, it's easy as who see who is calling for mistrust and non-ooperation. And the opposite of non-oop of cooperation is centralized control. I think we should be resisting those calls. And this is a useful way to think about the calls for human and AI interaction. Okay, that's very briefly my thought about politics. So I did want to actually do sort of the philosophy uh of AI. Um, so AI is happening today and it will be ever so more so tomorrow. So how do we feel about it? You know, I

just want to ask this hard question. Is is it good or is it bad? Uh should we fear it? Will it take our jobs? Will it make us obsolete? Or will we be the AIs? You know, will it be humans that are amplified by technology? Is it an is AI an invader or is it our ch children? You know, will we lament it or whether or celebrate it? Is it us or is it not us? Okay, I think that's the fundamental question. Okay, so how are we to think about this this this thing? Uh I want you to just first realize that that we're often

asked not to think about it, but just accept that we should fear them because they're not us. They're aliens. Uh, but you know, we're making them. There's nothing more human than to understand our minds. Um, yeah, how are we to think about it? So, I mean, you can tell how I think about it. Uh, it's it's not alien technology. It's the oldest things that people do. For thousands of years, we've tried to understand ourselves and human intelligence and how our minds work and

how we could make our minds work better. And this is just a grand quest for humanity, you know, to understand how we work. Uh I like this quote from Kurs Wild that intelligence is the most powerful phenomenon in the universe and uh we're the best example of it and we should be understanding it. It's just a big important thing. But understand intelligence is like a holy grail of science, a holy grail of humanities. It's a great and glorious prize. us as academics and thinking people uh we

should be enjoying it and celebrating it and and trying to to carry it forward. Uh okay, but let's set aside whether we want it to happen or whether we think it'd be terrible if it happened. Okay, let's just try to predict what will happen. And so I I offer these tenets of realist AI prognostication sort of like analogous to like John Mirshimer talked about realist uh geopolitics. We're just going to be realistic. What's what's actually going to happen? What can we you know we can't

control everything. What's actually going to happen? So tenant number one, I think there's no consensus about how the world should be run. We we don't agree. You know, no one view of how the world should run. Capitalist, communist, uh Marxist, whatever. Uh no one view is dominant. There's no don't the religions don't agree. There's no one view that's dominant over the sum of all the others. Number two, someday people will understand intelligence, understand it well enough to create it

with technology and we will do it. Some of us at least will do it. Number three, the process will not stop the intelligence of current humans. Soon that will be vastly exceeded. We'll have super intelligent things whether they're people or or not. And number four, over time, power and resources will tend to flow to the more intelligent beings. So, putting these four things together, we end up with a picture uh kind of like like this with there's the scent of humanity is leading to succession

to AI. And I think that's reasonable. But just realize this is like it's very egocentric to to talk about this. You know, it's humanentric. You know, what's happening to us? It's all about what's happening to us. And it's good to maybe just step back and say what does, you know, what does the universe think or what what role is all this playing in the in the universe as a whole rather than primarily from our point of view. Okay. So in this and I'm going to go really grandiose now. Okay. So so I'm

going to talk about the universe and the four great ages of the universe. Okay. The age of of uh of particles like after the big bang. There wasn't even hardly any atoms. And then uh those collapsed uh into form uh the stars. And we enter the age of the stars where the stars would would form and then they would heat up and they would eventually explode and then they reform and this way we get the the heavier atoms and everything. The age of stars and then once we had uh heavier heavier atoms and

planets uh then we were able to have life and the the green areas the age of replicators. I don't want to call it the age of life because well, I'll talk about that in a minute. I think the really thing that's special about the green time is that we have these things that can make more copies of themselves and they don't really understand anything necessarily, but they can make more copies of ourselves. Like right now, we can we don't understand how we work, how our how our organs work. We don't

understand how our brains work. We don't understand how intelligence works. But we can make more intelligent beings, right? We can make children and raise them up. But we don't really understand it. And this is gets us to the fourth great age. The fourth great age of the universe where we have, you know, technology and created things. I call it the age of design because instead of replicating things, we're going to the things will exist in the mind of some replicator uh before they exist in the world. Uh like you

know you uh you if you look around the auditorium uh the building you're in the building was designed and then created. So it was first existed in the minds of some architect and you look at the chairs and your clothes you're wearing basically everything everything there was designed by people existed first in the mind of some person and then except for the people the people are replicators replicated they they they not exist more than a gleam in their par in their parents' eyes anyway. Uh so so

this is why I I tend to call these two ages the age of replication and the age of design. It's tempting to talk about age of life and the age of machines. But these terms terms are already archaic and misleading because our machines are getting more lifelike and we are thinking ever more about life as being a biological machine. Okay. So what's the real difference? The real difference is that biological things are created without a mind understanding how they work. They are replicated almost like a Xerox machine.

Don't you don't you didn't create the picture, you just replicated it. Technological machines are created first in the imagination of some mind, the designer and then in the world. So they're designed and important thing of course is that the design things are more easily varied and improved. That's why I I use these terms. I think it's kind of interesting uh to think about it this way. So, let's use these words a little bit just for practice. We can say that many non-human replicators,

you might want to call them animals. Many non-human replicators are designers like animals can make nests or burrows and people can make houses and many animals make tools like chimpanzees who strip a branch to fish for termites. And crows can shape a strip of leaf to fish for grubs. And of course, humans make stone axes. That was our original most important tool. And then, you know, plows for agriculture. And then, you know, everything computers and spaceships and factories and software many of which these things are are tool

actually tools for making other tools. Okay. So, uh now maybe we can answer the question we started with. you know, what are humans? What are people? What's our role in the universe? And maybe we can answer it sort of dispassionately uh without hubris, without too much self-importance. And we all sense that people are special. We're not just another replicator. Uh we are a special replicator. And maybe I've suggested what that is. We are the replicator that has taken design to vastly greater

heights. We are replicated. We are a replicator but we are also capable of of design. Uh and we are the the replicator that has taken design to vastly greater heights than any other any other replicator. Um we have we taken it all the way. What would it mean to take design to its limit? To take it all the way. And I think what it would mean to take design to its limit would be to design things that are themselves capable of designing. Okay? Design things in our minds that are themselves capable of designing in

their minds and this you know they have minds. So this is what we are doing with AI. we are we are fulfilling this great age um this last age. So I think humans are at least the catalyst or the midwife or the progenitor that fulfills the age of design, the fourth great agent of the universe. And that's that's our role. It's an important role. It's a his universal role. So, let me summarize then all three of my main messages, even the one that I did really quickly. Uh, the current AI,

the AI of the 2020s, it's the era of human data. It's doing really well, really powerful. Uh, but we're entering a new era of experience, which will be much more powerful because it can continually learn new things. In politics today, the politics of AI is parallels the politics of humanity. And in all cases, we should seek decentralized cooperation over centralized control. And at the philosophical level, I think AI is the inevitable next step in the development of the universe and we

should embrace it with courage, pride, and a sense of adventure. Thank you very much for your time. We're way over time, but let's maybe take a little bit of maybe a couple of questions uh very quickly. Uh any any >> Yes, go ahead. You could just speak towards this mic. It's right here on the ground. Oh, my question was uh aside from making stuff more comfortable for us, forgetting about us, is there an overreaching purpose any >> is there an overarching purpose to >> to where this is also?

>> That's a that's a cool question and there are many ways to think about that. Um I think I think that you know like many many great questions uh you have to answer them in a dialectic way. You know a dialectic way means you know you you got to say the answer is X and then you have to say well the answer is also not X and then find find the way in the way in between because I think you can say that the universe has no purpose uh or or because all the different parts of the universe have various purposes

and there's no one universal purpose. But then you could also say that the universe does have a purpose. It has uh it it it's it has a purpose of of uh maybe leading to more and more complex entities. You could argue you could argue that that the universe naturally leads to life and then you could argue that life naturally leads to uh designers and AI and and maybe it would naturally lead to something after that. You could, you know, you could. So with the dialectic, you know, you have the

thesis, the antithesis, anti-thesis, and the synthesis. I think we have to synthesize something out out of those two uh opposing answers. >> All right. Well, thank you so much. Um let's so we are a little late. Uh let's take maybe a 7 minute break and start at 25 after uh with the next panel. really perfect. iPhone. You get a phone call. After you come back, it's easier. You have a card here. That's right. I don't think it's connected. very close without >> Okay.

I don't know if you found a company >> and set up um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as that can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said

um drudge work out of out of science and mathematics. There's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit. there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh Kerry on that So the current AI they're best at at at

sort of reorganizing information that we we already know. But that's already very useful. I mean so first of all that's half of what science is. You know we we do literature review and and we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win >> and I think AI for science in a way is also a partnership I I see it as such. Um yes >> when we use AI in these research fields

how do we ensure that is accurate that it is reliable? >> So first of all it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against

simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as that can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive

as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at

sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields,

how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against

simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as

you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at

sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's half >> course on generative AI algorithms. So this will be a very small hands-on activity for learning uh for for learning deep learning and specifically stable diffusion type things. So if you're interested, uh it's still up. We still have a few seats left in the course, but we'll try to keep it very small. And Zia is one of the leading experts in this. So don't miss it out if

you are interested. >> So now I'm handing it over to Chuck. Thank you so much. >> Um okay, there you go. Well, wonderful. Thank you so much. I I think we have some really exciting presentations so far and uh it's been I love the interaction. I think a lot of you asked some really fantastic questions. So thank you so much. And of course this is also another exciting panel that we're going to have. And the way how we going to do it is this. We'll have of course uh each of our panelists will come out

uh and do a a quick uh sharing uh you know one by one and then all of us will go up together uh and uh and have some uh you know all organized questions and then of course we really wanted to be make it very active interactive. So uh you know please think about any questions that you may have. But first uh and foremost uh let me invite uh Hoyong Pun which is general manager at Microsoft research to share with us. Thank you. >> Uh can everyone hear me? Okay. Awesome. Uh let me see if my slide can come up.

>> Uh who control that slide? >> There you go. >> Uh it actually shows Sebastian's >> fun. Yes. >> Oh, okay. So then maybe we go to Sebastian the whole presentation. >> Um so so um I so so first of all it's a wonderful gathering and there are already lots of exciting discussion about math and basic sciences here. Here I want to sort of like highlight another really exciting frontier which is the medical sciences. Um so there has actually already been quietly a bunch of

sort of like giant wave uh under the current of deep innovation of AI in medical discovery and one of the kind of like key part of this paradigm shift is actually AI opening new possibility in clinical trials. So I will give you three examples um and looking forward to the discussion. Um so if you think about medical discovery uh today it basically at a grand scheme of thing it basically advance one clinical trial at a time right so and this process in is largely manual incredibly inefficient so when

you think about the single phase three trial take years to execute and cost 100 mil or more and and also despite you spend so much resources everybody still complain about is give you relatively limited information for a small sample size Okay. So as the first example uh we collaborate with Providence which is the third largest health system in US. We developed this AI called trial scope and the gist of it is that we basically enable medical scientists to utilize the real world kind of like patient journey

and then to conduct clinical trial uh uh virtually right. So essentially we basically demonstrate you can actually simulate a lot of this kind of clinical trial end to end directly from unstructured kind of electronic health records. So we showed that actually this virtual trial can be just as accurate as the real ones by comparing against the gold standard trial for some of the blockbuster cancer treatment. So for example this keynote 10 is for kichuda. Some of you might know that this is one of the best imunotherapy right. So uh

revenue of $30 billion sweet zero right. So um and obvious obviously like virtual trial can be much faster and cheaper right um now of course AI is no magic right so why this is possible is partially because the rapid digitization in the biome right so a lot of those like patient journey like from diagnosis to treatment to outcome that you study in the clinical trial are actually now routinely collected in the uh basically uh average clinical care. So basically every day you have billions and billions

of data point collecting all those patient journey right now that you are just uh primarily using them for building an operation but if we can weaponize them we can distill the insight then it become a population scale free lunch right um so this um again it's sort of like just sort of the first example right so in the grand scheme of thing you can think about it is basically it's just a appetizer right so it's already very exciting because you can start to using this kind of AI to reimagine the entire clinical trial

process right? Hundreds of billions of dollars uh in efficiency today. Right? But you can do much much more by go beyond the text modality and then start to consider multimodel AI. Right? So all those kind of like clinical text is actually highly in incomplete and uh uh sort of like noisy approximation of the patient gu. So I I over the years I make a lot of friends with medical folks. They start telling me jokes, right? So radiologists will tell me they sometime don't agree with themsel two months ago

on the same image right and then pathologists that give me a trick like turn the pathologist line 90 degree you see different things right so and these are some of the smartest people in the world but the challenge is that our watch visual cortex right didn't involve in the jungle reading mis right but then the AI can potentially enable them to start to acquire that kind of medical super intelligence um so here's one example right so I mentioned that kichuda some You might know that despite

being actually really the top uh frontier drugs right imunotherapy the overall response rate is only 20%. Right? So and you don't know which 20%. Right? So now it's well known that tumor micro environment actually hold the ultimate secret for precision imuninocology and in particular there was some of the new technologies such as this uh spatial proteomics right or in particular multipplex immunofllororescent MIF that basically allow you to simultaneously measure multiple protein at the individual

cellular uh uh level and preserve the entire spatial uh uh information right so that basically give you essentially a whole digital app encoding the tumor micro environment grammar that dictate the imunof response the life of death that of a patient. Now there is only one catch right? So um this kind of data are very expensive and uh uh time consuming to generate. So generate the data for a single tissue uh will uh will take days and cost thousands of dollar. And now imagine if we what if we want to

generate spatial proteomic for everyone in the globe right so that will bankrupt the humanity right so what we do is that we collaborate with providence and university of Washington we developed this multimodel AI called gigat time that basically can simulate this very expensive spatial proteomics information from the the kind of like the microscope pathology slide that are dirt cheap right a couple dollars a per slide and also readily available right and so for example In this example, you can see the

middle column. That's the ground true MIF. And then on the right, you can see the virtual MIF. Now, the virtual one would not be perfect anytime soon, but it already largely recapitulate sort of the spatial uh information. Um, and then with this in capability, you can start to do the good kind of hallucination at population scale, right? So, we basically apply giga time to uh cancer patient cohort 14,000 patient. we apply to all their H& pathology slide right so then we basically generate this virtual

population with 300,000 plus virtual MIF right along with all the clinical context so then you can start to run this basically virtual multimodel AI trial right you can start to correlate all those cells stay in those tumor micro environment with all the clinical variable that you care about like the disease progression tumor response right um and then through this process this enable us to uncover over a thousand kind of significant association um and and make our collaborating oncology very busy now, right? And so and also when

you think about it, this kind of large scale uh uh study of spatial plutonomic was previously unthinkable because of a cost, right? Um and finally the holy grail right is really like can we actually simulate uh the longitudinal patient journey, right? So GBD4 learn by predict next token next token next token and virtual patient can learn by predict next medical event next medical and so forth right and as a kind of like uh kind of baby step we collaborate with epic and uh Yale uh we basically portray

this uh probably by now the for now the largest uh virtual patient model called curiosity uh basically portraying from hundreds of millions of patient journey uh what's really exciting is that by doing this seemingly brain that way right but at a very very large scale it start to acquire this s of so-called emerging capability right so uh this kind of model right using seemingly pretty dumb simulation inference right we just say hey here's a history um predict what happen next in the next

year next 10 years right and then you can start to apply that to various kind of predictive tasks that people care about so actually what we find is that this model out of the box actually match and out or or outperform uh sometimes supervised model specifically built for each application for 78 tasks right so so to us this is a little bit of kind of a glimpse of or maybe using Sebastian's spark of the kind of like GBD moment for virtual patients so um so in summary I think we are at a very exciting time for

AI for medical discovery and AI clinical trial is sort of like really one of the frontier so looking forward to picking uh all your brain thanks >> I love it actually actually aful mention about Providence. We actually in fact have some friends from that area you know Brenda which is you know Brown University right as well as actually my good friend Donna which is a trustee or just she just stepped down as trustee of Brown University. So it's actually in fact uh what you mentioned I think you

should also uh kind of uh you know talk to Brown University and we're happy to facilitate as well. Of course USA has a great medical school. So well I I think this is exactly the kind of thing that foundation is here to help and facilitate. >> We love to talk to everyone. >> Oh very good. Well, that being said, um I want to uh you know, I know that uh we also mentioned about Sebastian, but I'm going to end with Sebastian, your your former colleague from Microsoft, which is now at OpenAI, but I I think my next

I'm going to have my good friend, my my buddy from Berkeley, we have the Berkeley represent representation. Uh so so you know, Hal, please come up and uh share with us from avidia's perspective the latest and greatest doesn't work. >> Yeah, but going Yeah, that >> this one. >> This one? >> Yeah. >> Doesn't work. >> Get to know how many mathematicians it takes. Is this your first one? >> Okay. >> Okay. Okay. >> Thanks everyone. It's a great pleasure

to be with IPAM. Uh there are certain things that uh in Nvidia we do that we cannot talk about. uh but today uh I think maybe I'm gonna speak on uh uh from the perspective of the scientist to talk about what I think will be the maybe the most critical uh innovation or things we can do in the next couple of years to really enable AI to make groundbreaking contributions uh in science. So I'll be talking more about world models. Uh actually through today's program we have already been hearing lots about uh lots of instances

of word models like this morning Hayden's discussion and also in the previous talk's discussion about how we can simulate uh what happened in the biological experiments. Um I want to dive a little bit deeper into this. Oh, so we need to Oh, >> it's going to be hard to understand without context. >> Uh no, >> forward. >> Okay, very good. Uh so the motivation is that uh uh we have been observing uh in development of MS for example in math encoding generally if the answer is

easily verifiable then we see very rapid progress or answers are not very easily verifiable or we see actually pretty slow progress. Uh so if we follow this rationale then for scientific discovery ideally if we can get feedback really fast in a scalable manner we'll be able to make discoveries faster. So generally the question we want to ask is that suppose I change the design variable control variable different treatments what would happen to the outcome. Uh there has been a lots of uh uh work in

the past uh in terms of simulation in many different fields. Many fields actually critical rely on simulation. I'm listing a few uh we also think about like uh uh other important industrial domains like chip design that's also extremely critical. uh so uh I want to somehow mention one point that maybe uh in era of AI uh there could be something uh sitting in between the west labs and traditional simulation. Uh so basically in traditional simulation there has been lots of efforts dedicated there to um uh

optimize the overall computation and building the physical models generally they require full specification. uh you need to write down the full state, noise, the distribution, boundary conditions, then we have a very precise mathematic equations governing the evolution of the system. Uh but generally uh if we go to another extreme like we are conducting experiments in wet lab and many things are underspecified partially observed uh actually there's also a a general issue of uh uh reproducing experiments done in

wet labs. Uh so one point uh uh I was thinking that uh uh there actually could be one approach of working in the middle. So basically uh uh we can try to apply what we learned from the beta lesson uh to simulations to try to uh absorb the under specification into latent states by feeding to real outcomes. Uh in some sense it's way cheaper than real simulation uh but also not as as expensive that's as the wet labs. Of course the devil is in the details. So I think uh there has been lots of exciting projects going on uh

for these directions. Uh it will be very exciting to see what we do um uh on all the different directions and also whether it's possible to have a unified wheel towards uh this uh this general problem. So gen what generally do I mean by word model? Uh we consider this to be a generative dynamic model that supports intervention queries and calibrated uncertainty. uh two features I consider to be quite important uh for the system to be very very useful. So in terms of uh um intermission queries basically the

world model needs to be able to predict what happens to the next state and also the observation uh condition on the uh current state ST and also the actions taken by the agent. So basically uh agents could take arbitrary actions maybe actions very hard to take in real wet lab experiments uh in a particular states that also very hard to reproduce. Um but the world model is supposed to accurately predict what actually happens for the next uh state in evolution and then we can actually roll out the whole

sequence uh given different configurations of action sequences. uh at the same time ideally uh the world model should be able to tell us how confident it is for predicting the next state and also next observation. It's very critical because it's very different from traditional simulation. Uh we are really unsure about its outcome uh prediction in many cases. Uh ideally if model is able to tell us it's really unsure about certain predictions, we can actually conduct real experiments in that setting to collect real data so

that next time uh the model can actually calibrate its predictions better. Uh so basically a very important issue is that when we are doing extra extrapolation uh we need to make sure we understand the corresponding uncertainty uh so that it really guides the the experiment design in the future. Uh so borrowing from the uh insights we gain from coding from from math in particular in terms of uh uh formally verifiable math uh if we are able to achieve a closed loop science uh which I do believe that many companies are trying

to move towards this direction um then then uh we we have we really have the potential to significantly accelerate the uh speed of scientific discovery. So basically uh this problem has been there for a very very long time. In the past we have been talking about seem to real gaps uh for many different scientific domains like in robotics and autonomous driving and recently we have been observing that uh uh in even in those domains uh the uh capability of conducting really realistic simulation has been significantly enhanced by

adopting AI actually uh considering Nvidia's technologies like DOSS and also Omni uh they actually also very good examples from this perspective and they al also like many more examples. It'd be actually very nice to also have a unified view towards all these different applications. So that uh whenever the world model predicts something then we are confident uh is actually accurate with with a very calibrated uncertainty quantification. So once we able to do that actually it can uh really

accelerate the scientific discovery and experiment design. For example here in last equation we are really talking about uh two things. So one thing is that we have learned the word model then given a particular utility U we should be able to understand given the word model if we take action A what exactly is the expected utility then we should also be able to understand what exactly uh will be the uncertainty of this utility given the word model then we can try to form a loss function or a reward

function to try to maximize that that will actually determine our actions to take and one can actually easily manipul manipulate the whole setting to try to figure out uh new actions maybe it's very hard to take uh in reality but it's very easy to simulate in the war model uh I'm going to stop here uh look forward to more engaging discussions I love it you know ladies and gentlemen we just have a new word right the beautiful word world model right so thanks to of course uh you know chat GBT

and open AI with large language model but now world model which is understanding everything about the world So, look forward to uh I'm sure you guys can ask more questions about that. Next, we have Erin uh Erin uh which is head of science from uh Amazon AWS. Erin, please. >> Well, I have similar problems. We can just move that. >> Forward. >> Oh, great. >> Okay. Um yeah, great. Um my name is Erin. Uh I think it's good to come after Hyo and Gentto. As you can see, it's

going to be really sort of uh aligned with what they're talking about. So uh today I'm going to talk about using foundation models for molecular world. Um it's a ongoing collaboration with my Stanford collaborators. And if you look at the current foundation models, there two type of foundation models. there's these general purpose um models like GBT and clots and so they're great um but you know if you give the model some structural understanding problem of protein they're actually not

uh able to learn the structure. So they may give you correct answers but most of these just remember the answer from the training data right if you give a novel protein you ask them any structural questions you know are out of luck right so um then if you look at some of these specialized foundational models like um chai 2 alpha diffusion or even specific models like alpha fog and they solve specific task and then um you know like they're not able to generalize if you give harder problem is not able to

reason about it is not able to leverage quote unquote adaptive compute right and so these are the limitations and then uh I think you know I see the there could be a paradigm shift I think in my view is that we for the first time we have models are truly intelligent and uh you know could we actually leverage all these intelligence these reasoning and to actually help the molecular world, right? And then design these uh drugs, antibodies for example and small molecules. Um so you know on a high level you know we have a vision called

we call think prote essentially if you uh you know it's just like human scientists right so you know when a human scientist give a task for example oh we want to design a binder that binds to the sask 2 spike receptor binding domain and want to block AC2 that's a question and then human scientists look at the protein sequence and putting structure and they start really contemplating you know you're kind of have a chain of thought and uh you know I'm not a b person but you know we have

uh great collaborators and then so there was some of the reasoning uh traces very reasonable and then uh so and then once you sort of have a high level understanding like hey you know like what the structural constraints where as particular spot there might be a key residue that that should built the structure and then with this and then we have a a diffusion model that's really sort of the design model they're trying to really design the uh the binder right so um you know as you can see you can

leverage um reasoning and then adaptive compute it can sort of bridge the gap and generalize out of distribution and so uh yeah we made some great progress hopefully we're going to release something soon but I think I want to highlight uh challenges and uh so the reason that you know these frontier models hasn't really solved this is that uh they're really a big data challenges they're limited amount of data actually the abundance of protein sequence data but like structure data is

only 200k right and then um if you want to do reasoning where are your turn of thoughts right so uh you Like if you talk to these bio experts and uh you know they they have some thinking process but they typically don't write about it right and then and also model architecture. So because of the limitation of data you can't really sort of brute force scale it up like the large language models and there's a reason that offer designed all these inductive biases this sort of evolutional information like the uh you

know the the sort of you know the the sequence similarity right the MSA and then also the paraphform that encode a lot of these uh sort of biases in structure and so um how do we actually uh move forward right with you know new architecture that can do design right so and then also evaluation back to sort of what Genta talked about um yeah I mean sort of we want to try to do more incilical evaluation simulation for example have a or model for for the molecular world right how does that look like so

eventually we would need to do wet lab right And then um yeah so so there are kind of really exciting future directions and so we want to sort of close the loop with RL driven optimization using both computational rewards and maybe rolling out in the sort of world model right model for molecules or model for cell people really very excited about the virtual cell uh sort of direction and also experimental validation right that uh with a lab in the loop kind of optimization and eventually we hope to

to be able to you know have systems that really self-improving right just solve all kinds of uh drug design problem. Yeah, that's my talk. Yeah, thanks. >> Thank you. That's a quick setup. Uh continuous learning, right? This is actually exactly what uh you know it's uh which sudden have talked about uh about reinforcement learning and so I said we started with uh you know hyphoon from Microsoft we're going to you know uh end this presentation with his former colleague uh Sebastian which was

actually uh VP of AI actually at Microsoft now uh a technical leader uh at open AI. So please Sebastian please come up and share your insights. Thank you. Okay. So finally we will get to see those slides. Um okay. So I'm I'm going to do something slightly ambitious. In five minutes I want to tell you a mathematical theorem and make sure that all of you understand it uh precisely. I I think it's accessible you know at at like middle school level. So so it should be okay. I mean you would see but it's very very

elementary but um the reason I'm doing this is I would like to ground the discussion in what is really the level of intelligence of those models right now and you know Terry and DK talked about some examples this morning and what I'm going to do is just do basically the same thing but trying to deep dive a little bit more into this example explain what it is and and how it compares to human uh intelligence. Okay. So this is a combinatorics uh question. So you know you have a graph so a network with you know vertices and

edges and the most basic thing like one of the most basic questions that you can ask is you can count subgraph in this graph. So maybe I count the number of clicks the number of fully connected component or the number of anti-click you know empty independent set or I count the number of you know subgraphs that looks like an H. I I have some collection of things that I care about and that I want to count and I'm asking myself are they constraints between those different objects like if I count

I have that many cleats what does it tell me about the number of hes okay so this is extremely basic in combinatorics turns out that it is incredibly hard in fact it's completely impossible so in general if I ask you a linear inequality between different subgraph you know I ask you is this true or not this is in general undecidable okay so there is no way to answer this type of question which is kind of crazy. Um but the most basic version which goes back to 1904 by mental which is the first result in

extreal combinatorics is about specifically is the relation between the number of edges and the number of triangles. Okay, if I tell you how many edges are in a graph what does it tell me about the number of triangles and mental theorem in in this picture that I will explain in a minute is exactly just this point. So let me explain uh this picture. On the x- axis you have the edge density. Okay. So the the number of edges that are present among all of those that can be present. And on the y- axis I have the triangle density. So

among all possible triangles that can be present how many what is the proportion that I actually have. And it turns out that there are constraints between those things. In particular if I have at some point if I have enough edges then I will have a triangle that appear. Okay. So this is mental theorem tells us that once we cross that fraction then we need to have triangles. Okay. And and it's a very difficult you know mathematical result to show that this is a lower bound. So there is nothing you you

cannot have graphs which have this edge density and that triangle density. Very good. Now um you will note that this shape is non-convex. Okay. We don't like non-convex things. It turns out that if you ask the same question for trees, then what I showed with nati lineal more than a decade ago is that for trees, this sets of possible, you know, relationship between sub trees is actually a convex set. And then the question became okay, what is the tree equivalent of this edge and triangle density business? A triangle is not a

tree, right? A tree is something that doesn't have cycles. So we ask, okay, what is the equivalent of this picture? So you can think about it like you know on two vertices I have only one tree which is an edge. On three I have also one tree which is just you know a path. On four vertices if I add one more vertex then either I connect it into the middle or I connect it at the end of the pass. So on four vertices I have two trees either a pass or a star. So in terms of proportion it's not interesting

because if I have a certain proportion of pass then I have one minus that of the proportion of the other one. So the first interesting case is this one on the left which is five uh vertices. Okay. So on on five vertices are three isomorphism type of trees which is either a star a pass or the thing that looks like a y. And now I can start to do something interesting which is if I tell you that I have a certain proportion of stars you know what is the possibility for the proportion of pass and the proportion of y's. Okay. And

it's really a two-dimensional picture because since I have three things, the sum of them is always one for the total proportion. So I can start to draw pictures again. I can look at proportion of path versus proportion of stars. And what we conjectured in um uh what we conjectured in in a 2013 paper in the 2013 paper is that this is the set of possibilities and the the the shape of the convex set was determined by these things that we called millipeds. So you see these are like it's a long pass and

then I have this uh thing of of degree D. If if D gets very large and I have a lot of stars and very few pass so I get up there in the corner. Okay, details don't matter. What we were able to do and now we're going to get to the AI party in a minute. We were able in 2013 to prove this is a lower bound. So the convex setters to be above this red line and we are not able to show any of those faces of the polytope to be tight. I was I have given this problem to many students when I was at Princeton. Every

year you know new crop of students would come. I would tell them this problem nobody would come with a solution. I myself spent you know a months working on it. Natalinial spent some time you know we couldn't make progress. Then finally came three very good students or mana Katherine Edwards and Katherine Subco. We they were good students before too but and they together we were able to prove that this first uh part of the polytope is actually tight. Now it corresponds to something extremely simple in in plain

language. corresponds to this inequality that for any tree whatsoever if I count the number of y's it's always going to be less than n times the number of stars plus the number of paths plus six okay very good then h in the same paper we were able to disprove everything else so nothing else that we conjecture was true everything is false and you can look at you know these these trees at the top they kind of disprove everything but kind of very weirdly this second inequality remained open so this one

could still be tight and it corresponds to this inequality. Okay, 29 * y is less than 42 * s + 144 p plus a constant. Okay, and this has remained open for uh 10 years. And with GPT5 that started to be good at mathematics, I thought it's a good time to revisit this question. If you ask this question to GPT5, you're not no luck. There is no way in hell that you know it's going to be able to solve this question. This is way too hard. So what we did is and this was uh alluded to this morning. We built a

scaffolding around GPD5. In this case it's a it's a general scaffolding. It doesn't have to do specifically with this problem. Although this is a very interesting question also to build scaffolding specifically for certain problem. If you already have a you know a proof technique in mind an approach then you could build a scaffolding to kind of execute on your approach. But here it's a general scaffold where you know there's going to be some agents that propose ideas, some agents that

execute them, some agents that verify them, some agents that merge different things etc. Not telling you exactly how much compute we spent on this, you know, because you can parallel do things in parallel. But at the end of a sequential time of computation of two days, it came back with a proof. But importantly, I did not ask the second inequality straight up. This is also something very important to understand is I knew if you just ask the second one it's going to be way too hard. So what I did is I asked

the first question first for which I already knew a solution. The model thought for two days came back with a solution and I put that one in context and then I said okay now go attack this you know generalization of it and it came back with a proof. Um you know I'm I'm up with my five minutes. Uh if I had more time I could show you the beginning of the proof because what's interesting is that um in this proof it comes up with kind of a miraculous identity on trees that I have no idea where it's

coming from and I have asked you know expert who spend a lot more time thinking about combinatorics of trees than me and uh they also don't know where it's coming from and it really kind of solves uh this problem and this you know in in the discussion of how can academia interact with you know frontier labs and all of those Here is one example of a kind of a question a little bit out of the box that academia could consider is with this scaffolding I have millions of tokens I have you know dozens of book

worth of material that the model has written to arrive at the final solution where in this you know library of knowledge that the model has written is the moment where the model got the insight you know so I give you these 10 books tell me like find an automatic way to to to discover the ins insight. This is something I think it's important like one thing that I like about academic freedom and academia is that you're able to ask questions that were never asked before like that just come you know

naturally out of the progress of technology. So we shouldn't always try you know to reuse uh questions from from before. Anyway, this was just a general comment. I'm going to stop here. Thank you. Right. If I could ask all my panelists uh to come up and sit there. Um you know obviously we actually we we're doing great with time because we caught up on time right now like you know like we have 30 minutes and I'm going to be I have some prepared questions but I as I said I want to make it very interactive.

So, I'm gonna ask our panelists to limit your time to 30 seconds each in terms of answering my questions because I certainly want you guys to answer to uh a lot of probably the audience because I I really want to make it interactive. But I think to to begin with this um I think obviously if we can turn off the uh the light. Yes. Um actually maybe the Yes, there you go. Thank you. So you know I I obviously each of them it's really experts in their respective areas but I think to kind of get to that point

it really would be great uh important for people to understand you know really about your background. So if you could uh briefly introduce yourself and share your key responsibilities at your company relating to advancing AI and AI for science. So hyphone please and then we'll go along that please. >> Cool. Um so a little bit about myself. So I am a computer science uh uh by training uh started my uh PhD in AI uh two decades ago back when AI was still in the last ice age. Um and then I

joined Microsoft research 15 years ago which coincide with the tenure and the rest of human g project. Um so I would say at that time I super foolish and hungry didn't know how hard biome is. So I find it very exciting. So I decided hey I want to work on this. Uh so I was hired as an NLP guy. Uh but I told my manager I want to work on cancer and miraculous he didn't fire me on the spot. So so that's basically where I am. So 15 years of battle scar um a little bit tiny of progress but essentially in

the medical discovery space. >> Very good Eric. >> Um yeah I similar background. So I got my PhD from Cornell. Yeah. working on good oldfashioned AI and then spent a large chunk of my career at Bell Labs and I jumped at Colombia and then uh yeah I think resist the urge to move to the west coast eventually 2015 I moved to Uber and you know working on machine learning platforms and doing self-driving cars and after that you know couple startups and at Amazon so been really working on a lot of the um

you know reasoning models for um math coding and computer use and sort of two years ago just realized you know we're on track to do scientific discovery have been really focusing on uh AI for scientific discussy in the molecular world yeah everyone uh some house I got my PhD from Stanford actually also came from theory background uh in the past I've been following lots of work by Terry Sev and I joined Berkeley faculty and I also did a startup before Recently I joined Avidia. Uh there my main responsibility

is to try to uh advance the science of post training in particular covering the data pipelines new methodologies and also the uh nova applications. So really excited about pushing the limits of uh capabilities of amps in particular in new scientific discovery areas. Hi everyone. Uh so what I presented is what I do with about 5% of my time. uh 95% of my time is is dedicated to improving the capabilities of the model and actually making this uh possible and so in the in this 5% uh you know dedicated to this this is part of the

open AI for science effort that Kevin will is leading and there I have a role of an advisor trying to help them to think about how the new capabilities that we have can be used to help scientists in all domains not only mathematics, physics, biology uh you how to integrate science workflows into our model and and things like that. >> Well, very good. Actually on that note, I I want to kind of maybe Sebastian and Chantel can answer this question then I'll move on to the next question and

then uh but actually on the AI trajectory since you mentioned that how do we view the current trajectory of AI where are your thoughts and strength and limitations of large language models and what research directions are you most excited about Sebastian? Yeah, big question but uh um yeah in in terms of you know where we are this is why I wanted to give this short five minutes presentation because you see it solved the problem on which I I spent like a month thinking about you know it's not a

huge open problem in the field by any means uh but that's roughly the time scale at which those model can work right now so the concept that maybe some of you have heard me talk about before it's not from me I I don't even know who invented it is this concept of AGI time so basically for how long can the AI mimic humans thinking? So I would say GPT4 for example was AGI seconds. So anything that a human could do in a few seconds GPT4 could do. And then as we went to 01 that was mentioned this

morning we we certainly in mathematics we moved to AGI minutes maybe with with 01. And then we went to the model that could solve IMO question and got the IMO gold medal. That's kind of AGI hours. you know, if you give if you're given an IMO problem, it's roughly an hour. Now, we are at AGI at least days, may maybe weeks in some cases. Uh, but that's roughly the the the state-of-the-art at the moment. Now, I somebody this morning was was asking like why is it that those models haven't invented a new field yet

or you know even Terry was asking about very very hard question you know that it's not there yet and obviously it's not there like there is some completely miscalibrated expectation here. If you want to solve a really hard problem, you know, I I I did it a couple of times in my life to think for a long time about hard problem without solving them. You know, on the contrary to Terry and uh like these are years of thinking that you need to do models cannot do that at all. We're limited at weeks. So this is

like a starting grad student project that they can do. No, nothing more than that. Um now in terms of you know for the second part of the question uh just on limitation by the way I think there are no limitations whatsoever. uh like I don't just don't see any limitation uh in terms of exciting research directions um well you know I can't tell you exactly what we're working on but uh but what I can say is there are many interesting research directions uh like I would say at least I I I see at least

10 direction which are kind of orthogonal and really interesting and all of them have the potential to make real progress uh at least 10 uh and this is just from what I see personally. So so really like you know I used to say maybe and I will conclude with that sentence. I I used to say that uh there is work for a generation of scientists to understand deep learning and to make progress etc. Now I think there is work for a century at least to to kind of you know understand everything from what we're doing and kind of push them to the

limit. So >> can you give us one example of interesting direction? You said you have 10. Can you give us one? Yeah, I already gave you one. It's a the hardness question. So, you know, like right now, if you want to solve a problem, you can go and and ask GP 5.2 Pro. Okay, that's one thing you can do. But you can make many calls in parallel. You can have, you know, another model that goes and try to merge them like, you know, just like using just using the model as an API and kind of building an algorithm

that is leveraging the model as an API call. Uh that's one uh direction. Okay, I will stop here. >> Chento, >> I think super exciting. Uh, similar to Seb, I'm also super bullish on the capabilities of AI. Maybe I've emphasized a bit more on different aspects of AI. So, we have been talking a lot about language models. Uh, there's also like multi multimodal models covering maybe speech, video, images. There's also physical AI actually embedding models in the physical worlds.

uh my understanding that uh uh actually the the progress in many other fields in particular the attempts of combining all the modality together is still very very limited. So generally I'm I'm super excited about the productivity gains those AI can actually give us in particular after we integrate all these capabilities together. Uh so if we think from this perspective then the working AI just started >> right >> so uh we're very very far away from realizing the full potential. So I'm

super excited about this. >> Very good. Now I I think that I'm going to ask the next question which I probably a lot of you guys probably would care about because it's actually kind of we said it's academia as well as industry and it's about production gap. Um so I want both Erin uh and Hyun to answer that uh question is what's the biggest hidden challenge when moving an AI model from research prototype to a large scale production system? How can we better bridge the gap between lab and

industry? Uh you want to start? >> How about you go first? >> Um yeah that's a awesome question. Um so I was in Davos in January and one of the buzz word uh in Davos is about uh so-called capability overhang. So basically what it means is that a little bit like sort of what Seth alluded to is like if you look at the underlying technology potential they actually grow very very fast right but when you look at the real world kind of impact uh they actually progress much much more slowly

so there is a kind of like growing gap between what might be possible and what we actually uh get to today right so and on that front I like to kind of think about sort of like a little bit about the AI uh application spanning sort of like this spectrum about what I loosely call the productivity gain versus creativity gain, right? So the productivity gain as a sort of the boring stuff like sort of what uh Taran uh talked about earlier, right? Like automating uh kind of chores or mundane stuff, right? And this are human expert

perfectly capable doing it but just very tedious, very expensive, very long time. I would say that is the region where actually a lot of this productivity uh pro productization gap is going to close very rapidly. Uh one of the area in medical discoveries the whole clinical trial process. Um so there are so many thing if you look under the hood is unbelievably inefficient right and there are so much of that actually arguably technology already there. So you basically need to figure out some of some of the mundane stuff like change

your management re recon reimagine the process workflow ecosystem business model but actually technology arguably is ready but then there is another even much more exciting thing which is the creativity game. This is arguably where actually no human being can ever get to the point right imagining can you imagine a doctor in being able to internalize a billion people as a multimodel longitudinal patient journey right it's very hard right so but AI can potentially get them to there right and um so obviously there I would say the

the the gap could be grow even larger for a long long time until actually we were able to actually materialize some of that I show a couple example that you know in the multimodel space echoing s of gentiles were um I would say longitudinal that's a holy grail can we actually build a weather forecasting system for virtual patient right to predict what exactly would happen to the patient if we can get to even some decent accuracy we get to very close to precision health and obviously we're not

there yet all right but uh that's actually the why it's such a really exciting >> great thank you Erin >> yeah I I think I really agree is hyong. I just want to add on to the creativity again. Um I think the model is sort of uh getting to the point where it can start helping on the creativity side but I think we have a huge gap of the model capabilities. Um so yeah I think the model has to really get better. So uh essentially uh you know sort of given any problem that they're they should be able to be

uh get better at proposing the right hypothesis um you know and then to essentially building a gentic system that can carry out these experiments. I mean these experiments could be sort of uh incilico and then could be you know like at some point when like you said when the um you know when the model is very short we can just move to the wet lab right have lab in the loop so I think all these um sort of infire sort of tools hasn't been built out right so in order to really close the loop um on create creativity

really sort of you need to build this whole uh close loop loop and together with models better capability is a proposing a good hypothesis. Yeah. Right. So I good to hear. Um but actually on a related matter which is something that you guys probably care about because we're in actually in fact earlier we talked about the earlier panel about the human value in the AI era. So actually in fact Sebastian I'm going to put you on the spot and perhaps whoever you guys out of the three whoever wants to answer that question

please volunteer yourself. But the question is many people worry that AI becomes more powerful researchers or anybody might lose their value or their own jobs right what are your thoughts on this and what do you believe main unique role of human researchers right so especially put you on the spot please >> sure u yeah so you know I I personally see like three roles of science and maybe there are more that I'm not aware of but you know one of them is is is to act on the world to be able to make us

humans more powerful to create more things. You know, that's kind of technology. Uh, another aspect is is really science for kind of the pure reason of understanding the world that we live in. You know, it doesn't matter if it makes us more powerful. It's just, you know, solely focused on the understanding aspect. And then there is a third one that I alluded to this morning when there was a question about chess which is uh you know science is also very fun to do like fun in in in a game sense and and with with any game

comes competition and you want to be you know the smartest and the fastest and all of that and this is definitely a big bucket that I don't think should be discarded. So there is competition understanding and kind of technology. So depending on which one we're talking about there will be different impact. So for tech for the technological aspect you know it's all about what we can build. So in that respect AI just makes us even faster even better. There's no it's just benefit for everybody. We will

be able to build even greater things. Uh wonderful for the competitive aspect. I do think that it kind of kills the game and and the people who are in it for you know for for that reason you know maybe it will be like chess. they will still do it in their spare time but it will be much less prevalent I think in the future as kind of a reason to choose uh that as a as a job and then the one that I personally care the most about is the understanding piece and for that uh I think AI you know it it's not the full

picture like it doesn't necessarily as we discussed when it comes back with a solution and you don't understand why or you know in my example I don't understand where the identity came from this remains unsatisfying and we want to push further further and and so in that respect I think um I'm hoping that in the future AI will force us in the scientific community to put back understanding at at kind of the as the center focus of our enterprise. there's technology on one side that's a

different thing but for the pure scientists you know understanding should remain more important and one one thing that I I I I tend to say is um you know maybe we should write less papers in in the future what is our human uh uni unique human expertise it's not to write more papers because AI will be better than us at that but it is maybe to kind of consolidate all of this knowledge and to explain it in a way that other human can really appreciate and understand so I think that's that's my answer to your

question. >> Okay, I like that. Uh when you want to answer that, please. >> Can can I? Yeah, I want to uh kind of build on what Zap mentioned and say maybe three points. Uh first, uh I would say my old job is has already been replaced. So that make me a fearless um because uh I some of you might know that I was trained as an NLP guy and my first half of my career was biomed NLP trained some of the early biomet. So when I saw GBD4 in the 10 a few months before they released, I know my

job is done there, right? So I have to find another job. Um but I the on the more serious note I would say is that um to me some of the obviously it's kind of like there are all kinds of serious question about how the AI will fundamentally change the nation state and the society and all those kind of uh things right but to me there is also a much more immediate point and kind of like doomsday scenario which is that the the loved ones or my friends and so forth come up telling me that they have

cancer for example right so I just have a old colleague in MSR to to have you know colactto stage 4 with lung met right so uh very depressing to think about pretty much nothing can be done there right despite all this fuss about AI so for me like the most immediate thing like like I I I'm hoping that AI will replace my job there to solve cancer and next let's solve Alzheimer neuro right autoimmune we have no clue yet right so but I think um so so that's my second point my third point is that

when I think about long term is like I think about AI as a very very powerful tool. So for example if you got a uh so so it can tell you uh something like how but the question there is also a what and why right so for example if I build a perfect virtual patient I can predict exactly what happened right on one hand you can use it to do precision health right on the other hand you can do it like for insurance company to deny your coverage or claim right so so how do we actually uh think about that I would say

part of that is like I I hope the human would actually dictate the value uh proposition there. >> Okay, very good. I have one last question and I want to open up for Q&A uh because I do have other questions but I as I said I want to make it interactive and my last question I want everybody to answer and because I think you guys will all care about my last question which is you know as sir foundation you know aims to build a collaborative ecosystem for science and AI uh what do you see industry academia

investors uh and the foundations you know which is all of us working together to build this ecosystem what what do you envision for your own company in this partnership? Um so Sebastian start with you and then come back to us. >> Yeah. U well I don't know but uh uh one one thing that that we do have at at OpenAI is is a lot of compute. Um and so >> we do have more than 40 views. Yeah. So, so what I could imagine is, you know, in the future if we really realize this dream of being able to

transform compute into intelligence, which is not at all an obvious thing to do, not automatic, there are some limits to it. But if we can really keep doing it at scale, then we could imagine like that academia and you know other partners would choose problems that they really care about. They come up to with a consensus. Okay, we want to spend that amount of compute on this specific problem and then we help realize that. So I think that's that's that would be one possible collaboration in the

future. For the moment just you know before the grand dream you can just think let's say you know we can select a few mathematical problems that we care about where we could do the hardness that I talked about and maybe do it for a week instead of two days and and that okay very good. Thank you Jenha. Yeah, I would say that maybe uh organizations like SE could help help shape up some uh uh agenda for collaboration between academic and industry. I do want to emphasize that Nvidia has academic

grants program. So currently offers like Hopper H100 GPUs. So uh maybe uh one possibility would be that uh academic and industry we can work together to figure out what would be the most exciting projects we can work on together. And then I think every culture we have a call for proposal. uh generally uh the researchers will have access to GPUs our cloud for at least a six months there will be some uh mutually agreed upon uh projects we can work on uh I think it's a great way uh to to actually collaborate and through

this uh this approach we can also try to figure out what will be the most critical questions academia can work on that have the outsized impact on the overall community great Eron >> uh yeah I would say we we have similar programs that's like by annually. Yeah, I think we've fund a lot of uh research that we think are really promising, uncertain and industry really doesn't really want to store resources. So, you know, we want to learn from uh you know, a lot of the results. We got tighter sort of uh

interactions these days. uh we're trying to expand um sort of the kind of collaboration that that can be done between um you know Amazon and the universities. Yeah. I think the key is to sort of really some promising directions and then only sort of university has the freedom to kind of look at Yeah. >> really sort of se uh connect and do the bridge. Yeah. >> Okay. Great. So first I want to call out Sam Martin sitting right there who actually is my partner in crime in doing strategy and

partnership. So feel free to harass him uh in the break. Um so so I would say that uh one of our aspiration obviously that shared by the community is like how can we build this continuous learning health system right so and when you think about it obviously take way more than a village so and I would say at least two things I can easily take off is like one is like there are the foundational research side to some extent that's like going from zero to one right turning what's technologically

impossible yesterday to kind of like what could be possible tomorrow and on that front like we kind of benefit tremendously with tons of tons of academic research and then another kind of collaboration obviously is like all this kind of like you know involve like patient datas and everything. So that has to be obviously the privacy compliance and so forth. So that we actually work closely with all the key stakeholder like big uh health system like farmers and so forth to actually uh um like uh uh to make progress together.

I would say the hardest one is the last bit which is like how do we take all this insight all this derisking to actually generalize to eight billion people right to actually apply to a societal level and I would say we have all kinds of question and we don't have answers so we love to pick all of your brain then >> all right picking all your brain now so right now it's time well set questions uh both and then dim >> uh since you're mostly outside of academia you can freely speculate

in a way that some of the deans in this room cannot. >> So, how would you know we are seven months away from fall 2026 semester? What is one radical change you'd recommend we make? >> Abolish departments for example, >> just to give you a sense of the scale. >> All right. Maybe I would make a very brief comment to just to to kind of uh uh start. Uh I would say we have interacted with a lot of medical school folks right and also uh New England Journal of Medicine. I think this is basically a big top of

mind. It's like we have to rethink the whole education right for like medical uh obviously given the AI right so um there are some mundane analogy it's like hey we have calculator now right so we we do very differently when we think about arithmetic so so and uh there are all this breathless uh hyping about how how GBDX uh cross medical exams or Germani or so for right so we have to rethink the like the entrance exams and so forth and And uh in medicine all those folks teach me about how right now

they spend like months literally come up with some vignette to teach how student think about diagnostics and so forth. Right now on one hand AI can potentially sped that up to seconds. Right? On the other hand like um I think one of the early uh speaker I forget who in the morning talk about what does it mean by learning right? What kind of skill right? So so so again I don't have answer but but I I I think about my kids and so forth like how how should they learn in the future? >> So maybe one one concrete thing is first

don't abolish anything. Uh that's a good idea. Uh I mean seriously again you know we we don't want to like um we want to be in control eventually. So to remain in control we need to have the full expertise to understand everything. We cannot have AIS make decision for us that we do not understand that that's not reasonable. So don't abolish anything re you know reinforce the value of expertise explain to all the student that this is going to be ever more important. And then I would say if there

is one addition to make it's having a course on you know AI capabilities would probably be a good idea trying to explain to them how they can use them in in many different cases and and importantly do not tell the kids that uh you know AI will never be able to do X because that you know uh never work out very well. So you know don't like it's going to be hard to select the good uh professor for for that class. But uh yeah, I love what that comment on that and then I think you and then Jason and

then perhaps someone over there we are actually by the way so which sited and I we're actually thinking of doing summer school because right now iterations right and then in future we'll invite you guys to part of it. It's like summer program is actually when you have the flexibility to adjust and learn something new and then quickly quickly and adjust that and then boom we hit it in the next sort of semester or quarter. So well said on on that comment but Dimma >> I wanted to ask sort of a similar

nature. So there's been a big change in how the federal government looks at funding research and I just wanted to basically ask your perspective on this. I mean is the industry stepping up to that? Is that something you're worried about? And I also wanted to comment that uh of all the voices out there I think it's more likely that the government is listening to industry voices. So that was my other side of the question. Is there any kind of advocacy that you foresee doing in the direction of

increased federal funding for research assuming >> maybe I can say uh first thing is like so I was uh in a NIH workshop uh last September uh one thing that it feel really depressing uh is that um hearing how you know uh NIH basically funded 80% of the biomedical foundational research in the world right so to some extent kind of like us leading uh benefit tremendously from that and but also subsidizing a lot of those innovation. Um it's so depressing to see that actually it was time to before the

shutdown right and then and then uh I I want to go to too much of the other political side but but but sort of like I think one thing that I can think about sort of the actionable part is like we need much more education to show like for example why vaccine uh works and why those biomeical research are not waste of money right so so and and all those kind of human story. So, so I think right now we are having like I talk about that capability overhang, right? I think there is also a giant gap which is

like how science is making life so much amazingly better but people don't realize that a lot of the folks right so so I feel like maybe each of us at least have some responsibility to bridge that gap but to me like if I got to say obviously way above my pigory but but we should fund way more uh for fun research >> right uh I'm going to pass it on to Jason go ahead what's your question >> hi and the great panel but I have a more technical question maybe for Sebastian you talk about trying to understand how

AI reference that make conclusions I know it's like a search problem right you stumble some conclusions but once you have that can you start tracing back to see how the knowledge or the result being created because you can see where the high attention scores are and you can keep going back we cannot do that because we don't own the open air code And uh to us it's a black box but if you are inside you can have an observability of everything going on. >> Yeah. Yeah. But you know there are lots

of open source model out there including GPTOSS. Uh and these are thinking models. So you can build your own harness and try to solve this problem you know within an open source ecosystem. And when you talk that's exactly the that's exactly the right direction to start thinking. Um it's it's a it's step zero what you said because the the problem is you know when you think about the attention it's within a sequence >> but in this harness there will be you can think there is a kind of tree of

sequences and in fact it's not even a tree there are cycles where you know some of this chain of thought is being used over there and they connect like this. So, so it's much more than just within a sequence looking at the attention. It's also looking at you can think of it's a network of chain of thoughts. And so, how do you study that? Yeah, >> I think it's a lot more exciting to look at something like a GD5 which has a higher intelligence level than the open source model. That's why I'm asking that

question. >> It is more exciting. Yes, >> that lady. Go ahead, please. And then >> kind of a follow up on that like would you not trust an LM judge approach to this problem? >> Okay, great. So um what's the question? >> The question is would you not trust an LLM, you know, as to like give the task to an LLM and let it do it. So the problem is when the problem is very simple. I told you it's going to write like 10 books worth of words. I cannot put all of that into a context of an

LLM. It's not going to do a good job. So then becomes a question okay how do I chunk it up but again it's not it doesn't have a linear structure it has this graph structure so the question starts to be if you have this graph structure over text how do you chunk it up to an LM so that it understands so again it's an interesting question like the angle that you just gave gives you more you know you keep digging there's more and more question there you go ahead what's your question

>> yeah so question is actually for and in terms of simulation and it's very interesting and you research in terms of unit simulation to actually represent the physical world. So that help us drive derive the design and my question here is how do you handle the simulation accuracy simulation for the safety critical applications how do you and guarantee right and that matter whether you go with your one model or you go to precision in terms of like minimize the you know for the forecast things like

that this actually very relevant because literally we're using this for our mission critical like explorations NASA JPL test for flight attending that sounds very interesting your insights >> I just have a quick comment I think that's a super important question maybe a problem that will never be completely solved but when you think about the progress like autonomous driving initially the simulators we built the quality was really low but currently you already see like whimo tesla robo taxi

and uh reliability is is very very high so I would say that it's really iterative process. Uh throughout the pro process we refine our our uncertainty quantification, refine on the methodology of building the simulation, sometimes to reduce cost, sometimes to improve accuracy. Uh and then then we iterate uh then generally there also could be new innovations in terms of really pushing the paral frontier of the quality of the system. >> So maybe I view on that to say a couple thoughts. Uh so if you look at the

simulation right so there are sort of uh maybe a couple different regimes. So there are the first routine is kind of like the alpha zero right like the classic rich uh work in RL right which is like if you have a perfect simulator you can generate kind of infinite training data right and then and then you basically that's what how work and uh so that work for games go chess how how AI conquer those area and then for math and coding there are sort of so-called verifiable rewards so kind of like sort of like not perfect simulator

but kind of semi okay simulator imulator right I would say uh in medicine we wish we have that kind of simulator right what if we can have the virtual vision from the get-go we don't right now there is kind of like this first order approximation which are all this a real world patient journey right so again I I kind of semi- making a joke about how uh for some of those very subtle pattern like let's say radiologist pathology they very difficult to interpret them but after 6 months after 12 months you

get a very clear clarity whether the patient die, whether cancer progress and so forth, right? So to some extent it's like again sort of like this kind of real world patient journey give you approximation of sort of like what happened in the real world. So the question is like how do we weaponize that in a good way right so to your point how do we evaluate actually again for medicine uh actually the most important thing uh is actually less about so-called interpretability but actually more about so-called

evidence-based medicine right so how can you design a very carefully designed trial eliminate all the confounders and then actually compare whether a a treatment actually work or not right so we still don't know like like uh tyleno or or aspirin how it actually work but we run rigorous trial to figure out oh they actually sort of like in the longitudinal work. So I think that's ultimately in medicine that's remain a go standard. >> Gary your last you go please questions a little bit off the wall.

>> No questions off the wall please. >> Uh if if I think of the great advances of our time I say AI is we haven't seen it all but it's one. The second one that I anticipate which isn't there yet is quantum computing and I wonder what the effect of if we do develop quantum computing in the near future how will that affect this field of AI how can it take advantage of the fact that we think in terms of not zeros and ones but more computer so how would it affect this say a little bit off the

wall >> yeah I'm I'm very bearish on quantum computing for AI. Uh um yeah, I don't really see where it's going to be useful. Uh and it's not for lack of trying like the community has looked at it for now several decades and there is really not much use case in AI. There is a lot of use case in simulating and I don't need to tell you that you know physical models and you know chemistry and all of those things. So for that yes it will it will be an amazing tool but the way and in fact this is a more

general comment maybe that I can make just quickly like the the AI is really this you know for me the direction towards AGI this kind of general intelligence humanlike intelligence that can use tools just like we can use tools and quantum computing you know quantum computer is just going to be one tool among many tools that our future AGI is going to use. So that's that's how I I think about it much more than trying to use quantum computing to improve the AI itself. >> Go ahead. You want to say something?

>> Yeah. Uh I'm actually pretty bullish on quantum maybe slightly different. >> Yeah, we do have a pretty big quantum research group and actually also uh some really exciting new products released recently uh on quantum. uh yeah I would say that maybe uh there will be se also mentioned this there'll be specific applications where quantum really uh performs very very well but maybe a connection with AI then it takes uh more time to figure out >> maybe more >> maybe more um maybe one more thing I

want to emphasize also regarding some of previous questions on how uh we can foster better academia and industry collaboration I do want to make one advertisement this semester we we are teaching a course at at Berkeley uh showing students how to build uh from scratch. So actually it's it's founded by Nvidia. So uh we are really showing students uh the real cutting edge infrastructure uh starting from uh data collection pre-training post- trainining building applications really show them

uh the inner workings of these systems they don't understand how to build the systems also understand how to use the systems in practice because one thing I think there has been some concerns in the community uh saying that in the past we ask AI our uh like college or uh our exam questions in the in college two years ago AI maybe scored 50% now AI score 100%. And the concern was that the students are not really learning. So they just give the questions to AI. So once they really understand how AI

really works, uh they could also be uh more incentivized uh to really learn themselves. So this could be a topic that we actually explore more together. So on a high note of bullishness on quantum and AI, I think that's a great way to end. Um actually thank you so much ladies and gentlemen and then you guys can come up and share and exchange more comments and questions personally but thank you so much I we should do a quick picture together uh as together so if I could ask yours Sam and also Jackie

take some picture with us in the panel >> stand up actually let's stand up >> yes there you go Okay. >> Okay. Wait there. One last one. >> Sorry. One, two, three. One, two, three. One, two, three. >> Okay, we're done. class. >> Thank you. Are you good at it? your dad. >> You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use AI as far as I

can trust his outputs. I think uh there's a lot of emphasis currently of on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean

right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do literature review and and

we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that it is accurate, that it is reliable? >> So, first of all, it it works best when it is performing a task that you already know how to do and you know how to

benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I think the rule of thumb is is only use

AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently of on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to exploit >> there's a lot of mundane work I mean

right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. >> So the current AI is that they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You know, we we do

literature review and and we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win >> and I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when it is performing a task that you already

know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can you can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I

think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to

exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. >> So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what science is. You

know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win >> and I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that it is accurate, that it is reliable? >> So, first of all, it it works best when it is performing a task that you already

know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can you can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the ability to validate the AI output. I

think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently of on on trying to make AI replace human scientists and >> trying to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right automation which I think is now time to

exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI is that they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so so first of all, that's half of what

science is. You know, we we do literature review and and we we try things that have worked for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when

it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can you can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the

ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right

automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's

half of what science is. You know, we we do literature review and and we we try things that work for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes, >> when we use AI in these research fields, how do we ensure that is accurate, that it is reliable? >> So first of all, it it works best when

it is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the

ability to validate the AI output. I think the rule of thumb is is only use AI as far as that can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right

automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very useful. I mean, so first of all, that's

half of what science is. You know, we we do literature review and and we we try things that work for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a big win. >> And I think AI for science in a way is also a partnership. I I see it as such. Um yes >> when we use AI in these research fields how do we ensure that is accurate that it is reliable. >> So first of all it it works best when it

is performing a task that you already know how to do and you know how to benchmark and how to validate. Um in mathematics we are fortunate that um that many of the math tasks that we want um to to solve uh we now actually have the capability to verify them automatically by very reliable tools. Um in the other sciences we also have other ways to validate um data. You can compare AI generated data against simulation. You can run trials. Um you can set up um um lab replications. Um so um we should never lose sight of the

ability to validate the AI output. I think the rule of thumb is is only use AI as far as I can trust his outputs. I think uh there's a lot of emphasis currently on on trying to make AI replace human scientists and >> try to do what humans do best. But actually I think at least in the medium term a much greater uh potential will be just taking away a lot of the repetitive as you said um drudge work out of out of science and mathematics there's a lot of of of of lowhanging fruit of right

automation which I think is now time to exploit >> there's a lot of mundane work I mean right now frankly right that in the area of AI including data cleaning for instance right so um you know a lot of these things before you even do any kind of like simulations anything there's so much work to be done and so I absolutely agree with uh of course carry on that. So the current AI they're best at at at sort of reorganizing information that we we already know. But that's already very

useful. I mean, so first of all, that's half of what science is. You know, we we do literature review and and we we try things that work for other people and we replicate them because no single human knows the entire literature. So having a tool that that does that for you already is a make sure not only Okay. That was not a hard problem. Like that was just like a public. He's done some Yeah, I don't know. I think about >> comment. Yeah. Yeah. Send me a brief note. >> Oh yeah.

One one more second. Okay. >> So, in the interest of more commercial announcements, I wanted to um say that so one of the things that we do here at IPAM in the summers is we run this undergraduate research program called RIPS research and industrial approaches for students. And the way this works is that we uh recruit companies that give us research questions and then we recruit undergraduates to work on these on these problems. And so it's really uh you know we recruit from all over the

US. We get really the top people. So normally we do it for nine spots and we're full already for the summer but we're thinking of maybe adding one more because really the situation for undergrads is rather dire. There are a lot of RUS that are not not recruiting students. So we were thinking of of uh maybe having one more slot available. So if you are interested as an industry sponsor uh come talk to us. Uh but also if you know undergrads there's still another week or so uh it's open. So if

you know undergrads that might be interested in that and they are very good math CS these kinds of things uh you know we have also uh they should apply. Anyways I'm handing it over to >> thank you very much Dimma. So welcome to the final session of uh of our really exciting day. It's been uh uh quite amazing. So this is the session of higher education uh transformation a AI and science higher education transformation. So, so the plan is going to make a a small introduction and then uh I will

introduce uh uh our panelists who will give a short presentation one by one and then we go we go through uh um questions and then questions from from the audience. Uh but but I wanted to start just uh need to introduce myself. My name is Miguel Garcia. I'm a professor of chemistry and biochemistry here. I'm also the dean of the division of physical sciences. And of course I have the the pleasure and the honor of uh oversee and and help uh and promote the work of really amazing colleagues in in

the math department who are of course strongly associated with IPAM but also physics and astronomy, chemistry and biochemistry uh earth planetary and space sciences, atmospheric and oceanic sciences, statistics and also the institute of the environment and sustainability and AI for science. The way we conceive it is that uh we really want to expand AI for science and AI in academia from mathematics into all really areas of endeavor and that's one of my main motivations but uh really everything started about

uh probably June last year uh when one day we wake up in the morning and uh 1.2 2 billions dollars of extra mural funding from UCLA disappeared. Our funding was frozen including of course the funding for IPAM. IPAM is a is an organization that is fantastic and runs on a on a generous budget from the National Science Foundation uh that helps do many activities and and it had just been recommended for funding for another five years and then all of a sudden it's like we don't have any money. Um and so a

research enterprise that that is has a expenditures of $1.2 2 billion dollars is a lot of people many many people in the health sciences in the physical sciences in engineering many who rely on on on on uh funding for their own salaries for their activities uh TAs posttos research scientists so I I'm saying this because really this is the context in which we started to talk about about this uh this foundation with the particular interest of Chuck on on AI the incredible incredible need that

we had also well his interest was on a on math. uh the the relation that we quickly developed with Terau and and and Dimma uh and I remember we were having a dinner actually in and the Loskin center and we started think you know we need to do something about this right and so this this all came out uh to be uh uh sire and uh so we're very excited to to that all of you are here because this transcends about that that particular episode so the foundation for science and AI research intends to create and

nurture an ecosystem that brings together leaders in academia, industry, government, foundation and individual philanthropist. We think that there's so much excitement going on in AI right now and so many opportunities that this is the right time to think about it. Uh now the role of universities we're going to talk about is primarily with there's two things. one is talent development and innovation, deep innovation. And so these are the two this is the message that that I want us to to to to explore. Uh so these are

our panelists. Uh I have to tell you that unfortunately Peter Loen was unable to to be here. Uh he had an emergency and unfortunately he told us uh a couple of days ago that he would be missing. But I will be introducing uh the panelists one by one as they as they give their short introduction. Now this is called higher education transformation. So you may ask what what is it that is being transformed? Well everything right but today we're going to care about the two things that we do in academic research which is teaching

and learning and research and discovery. And I put you know two or three concerns there to just put some context right there's many more. uh but in in terms of uh teaching and learning the the the real concern came as a result of a very sudden disruption right so many things began to happen you know when chat GPT came out and and the the types of concerns that that that that came out was what is happening to critical thinking academic integrity things like that now in terms of research uh the

concern has always been that well we we we cannot compete with industry right we don't have enough uh enough resources we don't have the enough compute. We don't have access to data. Even the talent, right? It's it's hard to retain talent in universities when when companies are just so so uh wellinvested uh and resources. So these are some of the concerns. So so we need to be thoughtful about what is the role of uh uh again uh higher education and higher education research in in in this area.

So we think well how about opportunities? Uh, so I'm just listing a few opportunities there in in in terms of teaching and learning. Of course, new forms of instruction, right? Maybe we're going to be teaching completely different next year than we were last year. And we're through the process of that personalized tutoring, supplemental instruction, instruction flow, uh, workflow, talent development, etc. Right now, in terms of, uh, research and discovery, again, a just a very partial

list, right? But synergistic partnerships again there are there there's realm of AI that really should belong in the in the in the core of a of a of industry but there are others that really could very well fit within the context of academic research talent development right uh data centric AI we saw some beautiful examples today of mathematical proofs and the list goes on and on and I I really don't need to spend much much time of it because our time is quite limited right but what I think what what is very clear is that AI

I for science in higher ed is an opportunity to shape the future, right? Because the students that come in today that will be trained and will be part of the workforce, they really are the future. And so we need the synergy and we need the opportunity uh to to do that and and we need to do that together. So the question is again with respect to sire. So why do we need an ecosystem that includes research universities, government, industry, investors and philanthropist which is just a way to say the some of

the key uh components of society. Right? So I I I prepared this uh uh uh flowchart that has research universities on one end, industry on the other and society uh on the on the uh bottom right. Of course, it's a very simplistic model of a very complex system, but that captures some of the things that we want to talk about, right? We start with research universities and we have that again our our business is to generate and and disseminate knowledge. We want to uh go through the process of developing and enhancing and and getting

to the to what you human curiosity wants to get to. Then we have of course science, technology, engineering, mathematics and medicine which are a big part of this. And then we have humanism, society and many other things. Now as I was saying the two key outcomes are innovation that can become deep tech IP and talent development. the connection with industry is immediate with respect to talent development, right? So, uh hopefully we will have the the the the people who will come into the industry

and and will transform it and and sustain it. But there is also, you know, there is trans translational research that is becoming more and more important in the business model of a university. So UCLA physical sciences today relies heavily on income that comes from intellectual property in particular for medicinal chemistry but we have other areas that are beginning to produce income that are going to help us become more sustainable right and of course all translational research will go into into high-tech

industry. So one of the things that is quite interesting of course is that AI started at a at universities right. So it was it was a deep technology at some point and it took some time to progress and in fact every technology really starts at that corner and moves through until it really becomes the industry that drives our economy in increases our standard of living. It gives us the society that we have where we have freedom, progress and everything else. Right? So the the the what we have in the yellow there that

part of this particular system what it turns out it is extremely expensive this is a really large investment is such a it's such a large investment that you need the entire society to invest on that and that's what I want to highlight here right that we as a community need to be mindful and thoughtful of this because we've seen how vulnerable we are if if if uh If research universities in basic research doesn't exist, we completely break the cycle and then we are in big trouble. So a way to address

that is uh something that I I found intriguing when I started to think about. So what is the cost of preparing science and engineering professionals and research universities and who pays for it? We're talking about undergraduates, PhD students and postocs as you see all of them working in in in in settings that are actually quite uh expensive to start with. So very high techch and you know so these are really rough estimates, right? So please don't take me to that. But I'm going to say

that a college degree in four years is about 30 $320,000 and that's largely paid for by family loans sometimes financial aid. But very often there also also investment of course from the state and federal government uh that that contribute to the sust sustainment of the university. And then we talk about a PhD and a posto and we put numbers on that and we say that now really is government foundations and endowments or philanthropy that make that possible. Right? So in STEM we don't have people

uh in general covering the their cost of their education. And then we think about all the infrastructure right so we have overhead or you know facilities and administrations research supplies and equipment uh we have to pay analytical cost so you keep adding and at the end of the day say well what's the total what's the estimate right so somebody needs to have invested probably about a half a million dollar for a bachelor's degree about $1.1 million for a PhD and probably as much as$ 1.8 eight to2

million dollars for a posttos and notice how mostly is taxpayers money right increasingly philanthropy and I think that may be the way of the future so so this is quite I think uh an eye openening so where all these people go right so this is a lot a huge investment in education so where would they go so I've selected you know a few uh companies and the question is what's the number of scientists and engineers at some tech companies all the data from Google, right? So, I didn't do a deep

research. So, you can Google it and what you find is that well, you know, Apple has 50,000 uh PhD scientists and engineers and and uh and scientists working on their MEA is 40,000, Intel 36500, Nvidia 20,000, right? Do you remember that I was saying it's about anywhere from half a million dollar to $2 million for each of these? So uni what you think if you think about it is that universities steward billions of dollars invested in innovation and in human capital by individuals governments and corporations right so we are all

investing in this human infrastructure and that I think that's really important so you know meta 40,000 so I mean that's what is it you know 40,000 million so we're talking about billions and billions millions of dollars, right? So, universities too are billions of dollars in human capital and this is in this is societal investment. Now, you say, well, is is is that even worth it? So, let's take a look at the two 2024 one year revenue. There you go. Apple almost $400 billion. Uh so you know Meta 164, Nvidia reported

almost $61 billion, Intel $53 billion. This is a staggering. This is one year earnings, right? So the total 2024 revenue of four tech companies that you just selected sort of a roundup is 6 almost80 billion. Now the total investment by our country in STEM is $280 billion. So that is just an incredible return on investment, right? And uh are we are we aware of this investment? Are we aware that of this? So I think we all need to be. So I get back to this, right? So this is our system. We rely heavily on

the left part where we generate knowledge and transmit knowledge. We develop talent. Uh we develop innovation. And if we stop supporting that, the whole thing is going to collapse. So I think we need to be very very mindful of that. Now the good thing is that it the the the the the opportunities today are so exciting. I mean there's so much good stuff happening, right? Science today is just at at its best. AI is supporting science. AI science is is developing more more AI. So I think you know we we

need to put this in the context of being mindful. But I think the the the future is absolutely incredibly uh positive uh for us as a society to continue investing on that. I will stop for that with that and now I'm going to change uh presentations here. I hope I can do this. Okay. Uh I hope this is the right one. Aha. All right. So because uh you know I am uh an an academic again I will be very traditional in the way we introduce our speakers. So I will introduce our speakers one by one. I will invite uh in

a moment uh Dr. Dubes Jain. He is going to be the first uh presenter. He is the co-director of the UPEN data uh driven discovery initiative. He is the Annenburg professor in the natural sciences at the University of Pennsylvania. His research area is cosmology. He studies the propagation of light and evolution of galaxies using massive cosm cosmological surveys. Dr. Jane was the founding spokesperson for the Rubing telescopes that energy science collaboration now one of the largest scientific collaborations in the

world. Uh in addition to the datadriven discovery initiative, he co-chairs the at the pen the pen AI console. He's a fellow of the American physics society. uh he received the frontiers of science award from the international congress in basic science. He earned his bachelor's and PhD degrees from Princeton and MIT. So please uh if you can give us your presentation. >> Thank you Miguel. Uh it's been a fascinating day. >> And um I'm going to keep my presentation pretty

light just like a bunch of pictures. Uh when I when my AI colleagues invite me to their gatherings, the joke is that I'm the light entertainment because they don't have pictures like astronomers do. Um but before I talk about the research topics, I wanted to mention that I'm really excited about teaching and um I've taught like intro to AI course to non- STEM students where we teach them how LLMs actually work. I've taught a graduate seminar with a biology colleague across the sciences and an

undergrad machine learning course. So I'd love to chat with anybody interested in pedagogy in this age of AI all of pedagogy because I also talk to my humanities colleagues frequently and they're upset they're upset about AI. Um but also how to teach AI to everybody. Let me talk a little bit about um research. Uh I work with this tool of gravitational lensing to study the expanding universe. And our questions are some of the grand ones about the origins of galaxies and the universe itself and its future which is tied to

these entities called dark matter and dark energy which we've learned experimentally. But we are still in pursuit of their true nature. Um let me jump to the ways AI has changed how we do cosmology. So on the left panel is a map made from data. So we took the images of a 100 million galaxies and studied how the images are distorted as the light travels to the telescope. From those distortions, we made a map of ma of the mass distribution. So this is the largest map of dark matter made with a galaxy survey. And the dark blue are

some of the biggest cosmic voids. The light luminous things are superclusters and clusters of galaxies. So this map does not have like it's when you use AI for this map it's not like looking at a cat and saying is it an orange tabby or a calico. This map is stochastic because we believe structure in the universe came from quantum fluctuations in the early universe. So how do we test theories? First of all, I should note that to make the map that's the published version from a couple of years ago, we have used

diffusion models to do the inverse problem from noisy data and got a map that's four times the resolution. It's still being validated, but it's on the archive uh if you want to look at it. So, that's one area where we use diffusion models. How do we compare it to theory? We've heard a lot of talk about elegant math. The real universe is a bit messier and we um generate predictions by doing massive computer simulations and AI accelerates simulations. It lets us generate super resolution simulations

with more complicated physics by learning the physics from a small set of sorry I don't I won't have time to explain that but we use AI to generate these simulations and finally there's this thing called simulationbased inference which makes some of my physicist colleagues extremely nervous where we compare maps to maps. So we don't go through the intermediate step of computing things like endpoint correlations that physicists love, but we just compare maps to maps directly. You can imagine using a convolutional

neural net to decide if that observed map is this theoretical universe or this one. In this case, you can tell it's closer to this one than this one. But the real challenge is much subtler. Um and we use AI to do this end toend inference framework. So this is the area where we create digital twins and do inference using AI methods. Now I I'm really just going to show pictures. So um this is a nice panel of pictures that show very different systems. The touring pattern is a you know you can generate it mathematically

but it's realized in nature and the rest are actual pictures of microscopic ocean turbulence surface of the sun and the cosmic structure like I showed you. And the lower panel is actually a triumph of old-fashioned physics and math. So this is like a wavelet decomposition that lets you generate these patterns pretty well using just a few dozen coefficients. So that's powerful. That means we've understood something. We have a very compact representation of it. But if I did this with a diffusion

model, it would be perfect. So I'm not even going to show it. So with AI we can capture very complex phenomena that span a range of scales. And you know one of the weird things about AI is that we want to uh sim generate a map that has a million pixels and rather than using an analytic basis function with a few dozen numbers we used a billion numbers. Like for physicists that's nuts to use such a terribly non-compact representation of data. >> Everyone. >> Yes. But the magic is that it converges

to pretty much the right solution. Um so this raises some questions that given the kind of similarity of this phenomena you know this hierarchical structure and so on can foundation models advance science in a very broad way there's dozens of foundation models out there in science and their use and their power is a work in progress I have not seen many compelling uh use cases of foundation models. Stepping even further into the biological world, you know, I wanted to make a slightly different point that after decades of

hypers specialization, pretty much a century, I believe we are on the threshold of a new era of cross-disciplinary science. And I'm as excited about how data science and AI are fostering this as I am about how they are accelerating science. So I truly believe that from the undergraduates to the posttock level we have a way of talking to each other and collaborating with each other that is unprecedented. And the most exciting part of my job at Panai is talking to people and bringing folks together. And you know, my

undergrad student did a project in linguistics and vice versa. I'll take a slightly different point of view from what our previous panel expressed. To me, the actual path of scientific discovery is actually a work in progress. We heard about a lot of types of science. We heard a little less about how to build experiments, what questions to ask. Once you have an answer and a theory doesn't work, what's the question you ask to figure out the next theory? I think their AI is pretty useful as a cognitive partner as a

different kind of intelligence. But to me, the jury is totally out on whether in a few years we will have something like AGI that will do this kind of science. Um anyway, I'll wrap up by saying that with this cognitive partner follows many possibilities of collaboration between tech and academia. Thank you. >> Thank you very much, Be. Our next speaker is Dr. Brenda Rubenstein. She is the cribble professor of chemistry and director of the data science institute at Brown University. As director of the

institute, she oversees the largest institute on campus, home to over 200 faculty affiliates that is focused on the use of data for social good. Actually, she was named popular science magazine 2021 brilliant 10 list. Uh the top early career scientist in the chemical and generic news magazine that was in 2019. uh the talented 12 I mean and so she's been recognized as as as as one of the leaders in in the field uh in many different ways. Uh prior to arriving at Brown she was a Lawrence distinguished

post-docctoral fellow fellow at Lawrence Livermore National Lab. She received her bachelor's master's and PhD degrees in chemical physics and applied mathematics from Brown University, Cambridge and Columbia University. So, Brenda, please join us. >> Thank you, Miguel, for for the introduction and thank you so much to the entire Sarah team and UCLA for hosting this. Um, it's incredibly important to be bringing us all together as was said by by Miguel at this time. Uh, and so it's it's an amazing

opportunity to be here. Um, so I was told three to five minutes and I do read my emails. Uh, so I try to to stick to that. Um, so I will start with a quick introduction to the science that I do. I'll talk about what our our data science institute at Brown does so that you have a sense of what people are doing in education. Then I'll talk about what I think is is really the uh frontier for thinking about AI uh and how education plays into that. Um so uh my expertise is is really in computational science. Uh so whenever uh

some of my deans speak uh they always have to remember what department I'm actually in. So uh as some of us uh I was trained as a computational scientist first uh and other areas of of science perhaps second. Uh so in the the first area of science uh I I work on ML for for quantum computing and that works in both ways. Uh so the answer to your question is I'm bearish and bullish superposition of both. So what we try to do is we use uh quantum computers to train machine learning models uh so that we can

understand how chemistry and and materials actually function. Uh and so we actually do use real data from quantum computers to do this. Uh I again on the bearish side I'll say you know error bars on quantum computers if we're honest are rather large. Uh if we're a little bit clever they get smaller. Um but we can we can use those to train uh machine learning architectures. And the idea there is really that if we want to model things like quantum materials or bioenzymes, inorganic enzymes that have

incredibly complicated chemistry, we do need very accurate quantum answers. And the fact of the matter is, as clever as maybe I am or other people are uh that just doesn't happen on classical computers right now. And so we are trying to develop some of the first uh quantum computing methods to give us those answers and train force fields to to understand things. Our second area is is uh really understanding machine learning for understanding protein and RNA dynamics. Um what we're interested

in is is understanding and this was kind of said earlier. If you have a protein, the protein is is moving in different ways. How does that in turn cause disease? And this is very true if you think about uh proteins that are involved in cancer. Small mutations or modifications change exactly how those proteins move. Uh and that's what actually causes the cancer in the end. Um, and so what we've developed are a series of different kinds of models and and I know someone was asking this yesterday uh earlier today. You know,

everybody's been talking about generative AI. We make our own models. We make our own models um to understand these things and that's an important aspect of science. We make our own models to try to predict protein dynamics well into the future um beyond different barriers. Uh and lastly, uh we've spent a lot of time on molecular computing. Uh that is not computational chemistry. What it is is we actually make molecules compute for us. And there AI is extremely important uh for helping

us to figure out how do we store data? How do we map different operations onto chemistry? It turns out that chemistry actually recreates a lot of things that we'd recognize as different kinds of neural networks. So I do all these things. Uh but what what I uh do for most of my day job uh today is is is running the Brown Data Science Institute. Uh and so many of our um alums come back and they say data science is so 2000 why don't you update your name to artificial intelligence or the AI center. We we actually do both.

Uh but the reason why we call ourselves the data science institute is that we believe that data actually is is a larger topic uh than AI. AI has been built on data but data is the foundation and data is something that unites all of our disciplines. If we go throughout campus and we ask you know do you what what data do you have? What data do you have? people have data. Even humanists, even humanists have data. Um, and so many of our disciplines are built on data. And so that's what we focus on.

Um, and really our mission is is to stimulate innovation uh across the spectrum of of different fields. Um, and I I want to make it clear what's what's probably different about us is is we really do mean all fields. So uh you know, we make a joke my deputy director is actually a historian. You might say, what does a historian have to do with AI? Well, historians are looking at this moment and they're asking very deep questions about what's going on in this moment and it's absolutely, you know,

it's a historical moment that that is uh ripe for historians, writers, and and many others. Um, and so we try to look at how do we bring people together across all of these these different fields. Um and just to give you a couple of examples, um you know, yes, we have some of the standard things, but we also have, for example, a center for technological responsibility and reimagination where we think about the ethical questions and and the historical questions that that AI uh and and the current society brings up. Um that said,

what what do I worry about? What do I think about what what does our institute think about? And why why do we care about this, you know, interdisciplinarity? And it's really this interface uh that I spend a lot of time thinking about in in higher ed but just in general. Uh and I know we've all been skirting around this in in different ways. Um but the point is you know we're coming to this this synthesis of of where humans are interacting with the AIS and perhaps we don't know how

that interaction is going to take shape and what form that's going to be in. Um as an educational institute we we have to think carefully about this. There are practical reasons you know number one what are our students going to do? Um you know number two uh you know also thinking about the welfare of of our students. Uh so so you can we can have large discussions about what's going on in the undergraduate population right now. Um because we are not necessarily thinking heavily about this this

interface right now. Um but also you know number three how how is it that we are going to fuse these things together um to to make both of our ourselves you know the humans and the machines better. Um so you know practical examples of this uh from the the technical perspective is is thinking about how how do we put humans in the loop for verification as was said um important to me uh I'm I'm computational scientist but maybe secondarily a physicist or a chemist. I care about interpretability.

I want to know how how do I understand what's going on? So you know Barry was saying this other people were saying this. It's great if a model can predict things but if I'm not actually understanding it that's a problem. And so why do I think that's human computer interface? Well, you know, humans think in one way. I've been brought I've been cultured to think as a biologist or as a physicist about different kinds of reasoning. Computers think in a different way and we have to bridge that

gap. Um so if I'm going to forward let's say the field of physics, I have to understand what that AI is actually telling me about physics in interpretable ways. And that's that's a huge area um at this interface. Um and and of course as a as a third example, the rise of agentic AI. And this is huge for me in education. Um because what we have typically taught our undergraduates is that they're going to be the expert, right? And they're going to be the only one, you know, of people in in the room.

But now we're going to have humans with perhaps armies of AIs or maybe armies of AIs with a few humans. Uh you know, we'll we'll we'll see what that ends up being. But the point is we're going to be collaborating with machines in in in new ways and humans are going to have to be leaders and they're going to have to learn how to lead not just other humans but actually in some sense machines. Uh and so that's going to be a brand new interface. So all of this uh you know AI

is increasing our power. It's increasing our capacity but it's definitely creating both challenges and opportunities for for higher ed. uh and this interface this important interface where we intersect um is going to be a place where we have to think deeply about moving forward. Thanks. Thank you very much. So the next presentation is uh Dr. Janice Georgeos. He is the Dolly Professor of Chemical Engineering and Sorab Capriillian Dean of Engineering at the USC Verby School of Engineering. He is an expert in fluid

uh flow transport and reaction processes in porous media. As dean of engineering, he has launched a number of educational and research initiatives and advocated the concept of engineering plus emphasizing the empowering nature of engineering which has led to the creation of several interdisciplinary education and research programs. He received a diploma of engineering from the National Technical University of Athens in Greece and then master's and PhD degrees from Caltech. Janice, please. Well, thank you Miguel. Thank you uh

Chuck for inviting me to this panel. I missed the previous panels because I had to do some work at USC, but then I dropped and I'm short on time. Um I I just wanted I I gave a plenary talk at the National Academy of Engineering annual meeting in October on the topic was AI and engineering education. So a number of the things that you I'll show you here actually are bordered by that and I just wanted to uh preface everything by saying that when I first started as a professor uh my department chair told me that

engineering is about three things uh energy, materials and information. Uh my thesis was on energy. So I said fantastic I am in this very specific area here. Well, AI is actually a combination of all these three at an extraordinary amount. It's about energy. We all know how much energy it consumes. It's about materials, chips of you know Nvidia. You see all the the stock price how much it is going and it's of course about data and information. So when I look at this, it's almost like a

manifestation of engineering that we never seen before but in a different way. And so I think that's something that permeates a lot of the things that we do. But there is an additional aspect to it which is the concept of trustworthiness because understanding and the interpretability that we mentioned before is very important part of understanding the the whole aspects of AI and this is what comes in from the human element. So to me now AI and engineering consists of all these three things plus trustworthiness and I'll say

a few things about that in a moment. So, uh, I'm pushing something. Oh, okay. Yeah. Um, when I was thinking about, uh, you know, what's what's going on in the world today, I'm asking the question, what is going to remain constant in the future? So, it's an important question to ask and I believe that what will remain constant in the future is addressing four big problems that come up that come up in four buckets. And I believe this is true for any discipline not in simply engineering. And the four buckets are

one is what I call sustainable prosperity. I don't call it sustainability for a number of reasons. Sustainability sometimes has a has taken a political view that makes it actually be a little bit um alluding to scarcity and I think we need to to get out of that. uh when I was in the Greek word for sustainability I'm sorry you have to to to to uh uh tolerate me on this is Ioria and Aphoria means forever green and so when you you don't talk about sustainability in the sense of the oimoteis which is the viability but you

talk about iOS forever green I believe if we start thinking about sustainability in this way we actually going to go much further than than than for in terms of or making this some something important. Another big bucket is health obviously. A third big bucket is security. Security whether it is cyber security or you know space or other things as well. And the fourth bucket is enriching life which I think is something that uh uh is obviously something that uh we care about a lot in many disciplines as well. And so

enriching life whether it's education, scientific discovery, entertainment, all the other things, democracy, whatever you want to call it in terms of so to me uh and this is a a more engineering sort of a chauvinistic view of things but I believe that a lot of the things that we do are falling this baggage. So I have been trying to put all this together and I created some sort of a a mlo hierarchy for humanity which is this triangle over there. By the way, people call it pyramid, but you all know that it's not

it's a triangle. Everybody understands that. U also fundraisers talk about the pyramid of fundraisers. Actually, it's a log lock plot of a power law, but that's a different story. So I think that this will remain constant for the f for many many years because we really like to have all these aspects in in our in our world today and in the future and so the question that so so so it is very important for our students for example let's say engineer student to demand that we demand from

them a deep technical domain knowledge in these areas in other words we cannot simply say that all of this will be done by AI. We have to make sure our students understand that and they are masters of this. So this is something that uh when we look at the future of education, it is very important that we have that that that that that principle. Um by the way, this this is um back in 2008, the National Academy of Engineering articulated what's known as grand challenges of engineering and essentially are these buckets that I

mentioned here as well. Uh okay. Oh okay. This is my my muscle hierarchy. Okay. Just want to make sure then the question is what accelerates clearly what accelerates is um uh AI and computing ability in some sense uh transformative moment transformational moment. It's more than an exponential nature as we know actually approaches a singularity most likely and possibly a phase transition. So I have a very simple I'm not a an innovation guru and I not a business person. However, it's very interesting to see that if you look

at the kinetics of innovation in a very simple way and make the kinetics of innovation that are autocatalytic. So you have let's say da dt is proportional to a then you get an exponential. So I discovered for you morse law just one one equation there. However if you make this to be uh a second order reaction let's say proportional to a square the kinetics then you get a singularity which is actually something interesting that in other words if this is if this acceleration is faster then you're going

to get a singularity. Singularity gives power loss. power loss uh essentially associated with phase transitions from physics. You probably know that as you go as you approach singular the singular point or the transition point. So and and and so I I believe that we all it's not my own uh uh um discovery of this but there is a it seems to me that we face transition to autonomy and when I look at AI I look in terms of three things AI as a tool AI as a catalyst is not shown here and AI as a technology

and I will explain to you in a moment what I mean by all these three things for our students demands to have deep technical knowledge of AI what does it mean uh machine learning you know all the things neural networks so a commitment that we're making to our entering undergraduates at USC is that by graduation they have a working knowledge of AI understanding the mechanics of AI whether you are in CS electrical engineering chemical or anything like that it is very fundamental for our students to

understand that and to demystify to some extent if we can what AI is So this is this is the the uh the uh uh thing I wanted to mention. So I will now give you uh and I hope you forgive me a symbolic equation of whatever I just said before and please do not throw tomatoes at me but this is my my um uh equation here. So I am asking to you to take a triangle with the muslo hierarchy then add to it the the hyperbole which is the singularity and then you're going to get a double helix and the double

helix is consists of two strands. One strand is technology and the other strand is humanity. It's the two fingers that you showed in your in your thing before. I look at it in a different way and as I said this is something that I I believe we live in this world today in a very significant way and that's why uh you have to have sort of a uh the human in the loop which is actually this intersection between technology and humanity which I think is reflect reflected here. So my my my um uh hope

is that uh we will continue trying to solve important problems whether it is on sustainability or sustainable prosperity as I call it, health which obviously is going very fast, security and all these other things with a significantly advanced uh uh uh computing to to be able to create this this um intersection that will require a a very fine tuning if you wish between our interaction between technology and humanity. Uh before I go there, I wanted to mention a little bit. Um I mentioned AI as a tool, as a as a catalyst. I'm a

chemical engineer, so I have to use a catalyst thing. And then as a technology, let me uh so uh the tool is obvious, you know, you just Google something. It's like googling something. That's fine. uh in terms of catalyst I think it has tremendous implications with respect to the acceleration of science which actually we see today but also acceleration of learning or how we do learning and all these are going to to change dramatically in many different ways. So um by the way thinking about

learning and I'm not a learning uh expert but it requires in some sense a change of your uh you know the the the connect the connections or in your neural uh uh in in your brain that requires energy that requires most likely this is an endothermic reaction. In other words you have to be able to provide spend energy in order to get from one place to another. I think AI is a cat a catalyst that can help there. But the question is to make sure that this energy that you have to put continues being there in order to be

able to get this transformation. If you think about it clearly with respect to acceleration of science this is happening in in front of our eyes and I think the important question that comes of discovery uh the important question that comes in is what is the role of PhD students in the future? Are we going to demand our PhD students five years that we do do now or will it be two years? I mean with the acceleration what how are we going to judge the the the uh the the u achievement of of our students and all

the development of talent and I wanted to mention a little bit about uh uh AI as a technology and that I think addresses the issue why AI is cutting across all disciplines. Um I use a definition for technology based on a Brian Arthur definition in the 2008 period of time in which was the following. Technology is leveraging phenomena for useful purposes. So that's my definition of technology. Uh I don't say anything about this other than saying what the phenomena are. So it could be physical, chemical, biological

and increasingly social and behavioral if you think about it. So before AI we use this phenomenon actually we use it even now when we do you know uh physics in form machine learning or chemistry inform and all these other things as well however when we talk about AI we don't leverage leverage phenomena for useful purposes we leverage data for useful purposes in other words we have removed physics chemistry everything out of it all of a sudden all these techniques become very similar to each So I think this is this

convergence that you see in in the the place as well. And that is the end of my presentation. May I ask the three panelists to come to to the table please? So all right. So we have a few questions. We have a limited time but uh but uh we will do our best. Uh still some some topics we need to explore. So, so Janice was addressing some aspects of how uh learning and education uh you know uh may be influenced by AI. So I guess what what I'll do is uh I'm going to ask um uh I'm going to start

with Brenda and ask basically the same question. How is AI changing engineering and science education? >> Yeah. Um so so first of all I wouldn't limit it to to science and and engineering education. Um, basically my my view of things is is that AI is is making us become uh experts in our field and perhaps we should have been experts in our field already. Um, but in in many cases I I felt like in the past, you know, education uh in certain STEM fields was was about producing people who had a very specific skill set but

maybe didn't rise to the level of of expert. You know, we had we produced a lot of CS degrees. We produced a lot of applied math degrees um that were, you know, use this process and and sort of do something with it. Um, but what I think AI is is really making us think about is is how do we become develop the expertise that's needed to uh guide AI u make decisions about AI and verify AI. Um, and so we're we're really uh asking that students know enough um to have an image of their head of how things need

to work um which perhaps we weren't always asking for. And that image of of of thinking about you know what what needs to work um also means that you also have to be able to communicate uh what it is that that you think needs to work. and you also have to be able to lead in those ways. And so we're we're really um what AI is doing is is forcing us to create experts at a much higher level that can integrate a number of skills much more deeply than perhaps we have in the past. Uh and and so that

requires rethinking our education to make sure that people are coming out with degrees that actually have all those facets built in and that they're able to to really see around a technology and see around a field in ways that they weren't able to before. >> Thank you. Do you anything that you would like to add to that uh book? How is AI changing engineering and science education? >> Uh just briefly since it's late in the day, I'll uh I'll just I'll tell you what I really think

AI should do. I'll just give you a sampling. When I talked about uh uh you know abolishing departments, I meant the boundaries between departments. I think it's time for us to make the boundaries much more porous and think both about biology, physics, chemistry, but also about experimental science versus theoretical science versus data analysis related science and have training that crosses departmental boundaries depending on these modalities. I think undergraduate students can do a t-fold

increase in participation in research. I think graduate students really need to learn AI methods as soon as they reach grad school. I think faculty desperately need to upskill in AI otherwise the whole enterprise is getting held back by university the structure of universities and what our faculty don't yet know and I think universities could really learn from tech companies in how to be nimble and change on a time scale of six months to one year rather than decades. Yeah, thank you. That's really

important. I think you know AI literacy is a big challenge I think for a for education. Any any last word, Janice, on the on how AI again is changing science education. Anything you would like to add? >> Uh yeah, I think we discussed all a number of the the issues. I really um trying to understand what is the role that will be played by conventionally a teaching assistant today. >> Uh is the teaching assistant going to be replaced by an AI type of thing? To me that's actually an obvious question.

>> Yeah. >> And the other question I have is about the um what it is that we expect as we develop talent let's say at the graduate level PhD level. How are we going to judge this development and how do we make sure is because you know right now typically what you expect is that you graduate with a PhD okay you publish two three papers fantastic you graduate maybe this you gradu you publish these two three papers in a year you don't because of the acceleration of science and so we may have to change the way we

think about it >> and also what it means to to to to mentor and create persons of this type >> excellent point you know I think uh in fact graduate educ ation is one of the most vulnerable aspects of uh of uh of higher education today, right? That the models that we use to support graduate students are evolving very rapidly. Let me explore another area and I like I think I will start with Brenda for this. The the question is with the rapid changes and the need for large resources, how should university

research evolve? >> Yeah. So so this comes back to my personal view of of the role of a university. So, so the role of a university um again others may may have differing opinions. Um is is really as as a place for for innovation, original ideas in a variety of ways. Um we like to think about ourselves as as as a little test bed and at least historically a cheap test bed. You know, you could think about this, you could think about this thing, the other thing. Um crazy ideas. Uh and a lot of those

ideas don't necessarily have to mesh up with reality. Oftentimes they don't. Uh a lot of those ideas may not work at all. Um but they're ideas. Uh and they teach people. they move students forward. Uh and that's that's fine. That's useful. Um but it's important that we we remain sort of a test bed of ideas uh such that we can give those ideas. Maybe the best of the ideas go to industry. Maybe the best of those ideas go to other sources. Um but you know our role is to continue producing those

ideas uh so so that uh you know others can can feed from them. Uh and it it's also uh important to to uh expose students to to how to develop ideas because that's also a key skill. Uh so you know if we don't have anybody really pushing students to think beyond the boundaries um it will be hard for them to to sort of erect their own paths uh and and and also develop new things in our society. Uh and I think our our society very much values the ability to to really build things uh from scratch

these days. And so that's the other role of of the university. >> Thank you Brenda. Anything that you'd like to add to that Bob? >> No I'll just agree with Brenda and in advance with Jiannis. I I can say something though. >> Yes, please. >> I mean research you know we we classify research as 6.1 6.2 6.3 6.7 whatever. >> Yes. >> Traditionally universities do 6.1 maybe 6.2 some 6.3 and then you do then the industry goes in the other direction. >> I think this thing has been compressed

dramatically >> and so both universities and industry now work in 6.2 6.3 area. I think 6.1 probably will continue being a property of universities >> because maybe industry is not necessarily interested in that. Um so I I I have a you know a uh I have a dream. What if so you know before Newton we did not understand nature maybe when a little bit then Newton comes in introduces calculus you know uh FM is equal to ma all kinds of things all of a sudden the world makes sense is it possible that we are in a in an era that

we have not discovered the equivalent Newton today that will allow us to understand what AI does >> so that's my >> interesting thought very >> so I have a a question here for Um, AI has transformed science in selected topics like protein folding and drug discovery. Will AI remain a specialized accelerator for wellpos dataris problems or do you think it will change scientific research? >> Thank you, Miguel. You know, I think looking back in the last uh decade or less, um like every two or three years,

we've had a 20% boost in science because of machine learning and AI. If that's all it did, that's still the most rapid accelerant of knowledge in our lifetimes. Whether AI will truly transform every each of say a hundred subdisciplines of science, I don't know. Um I do know that there are many subd disciplines that are poised to join the ranks of protein folding and drug discovery and material synthesis. the disciplines that are recognized as having been transformed. But I think you know there's machine

learning methods that go back well before 202122 and LLM multimodal models and the adoption of the AI models has been very uneven among graduate students and faculty. you know, um, recently I'm hearing increasing accounts of I too have joined the the cult of of cloud code. I'm sorry that I'm talking about the company that is not part of the of the group represented today, but they have produced this tool that really shows us how to collaborate. I mean I do think of AI as another kind of different form of

intelligence and this tool has shown me how to how that can be a cognitive partner in my cosmology research in my darkest personal thoughts. So I think um it's TBD but I think every individual scientist now has the chance to explore and boost their productivity in new ways. >> Yeah, I I totally agree. I think just it's really exciting to think how we'll influence the most diverse areas, right? Geology, space physics, you know, just take it and and everywhere there is an impact that that really can be had. any

do any of you want to add on on on this particular subject friend Janice or do we move to the next? >> Sure. >> Please go ahead. >> I I'd love to add um so so for a lot of us who who spend a lot of time doing biochemistry we never really believe that the alpha movement would would happen. Um and so you know from my perspective I I think most fields can be there though the way that AI has changed things is not just the interdicciplinarity but it's the thought that you know we can make a model that

can understand our world given enough data. And while that might sound obvious to many of us, maybe it wasn't obvious in a lot of fields. Uh and so while we don't necessarily have that data in all areas, it does suggest a path towards understanding that fields didn't have before. So perhaps we need more particle physics data. Perhaps we we need more chemistry data where we understand how reactions progress in different ways. Perhaps we need more more data on social dynamics, right? But if we have that

data, then we can uh understand things in new ways. And so I think that has very much changed the field about way the way people think about data, the way people think about how we can achieve understanding. You know, that's completely different than it was about 20 years ago. So I think many fields will will reach that moment once they can actually articulate the data that they need to get there. >> Let me switch gears. I have a question that I think I'd love the three of you to to to have an answer before we go to

the very last question. The current question is let let us start with Bob. What is lacking in or missing from the current AI for science discussion? I have a colleague Desmond Patton who wrote a article on the joy of AI. you know there are many dimensions to using AI for science and you know the point has been made that um you know it's our partner we can choose to use it how we do you know taken to the extreme we still play chess we can still do physics the way we did even if some AI model has already got the answer

um I think reflecting on collaborative science with AI as both a partner to the individual as a and as a mediator to the group is something we have only begun to do if at all. And that I think is a really fascinating exercise because AI immediately takes out a lot of the relative drudgery of um you know writing and coding and other aspects of science. So we are free to imagine more uh the more engaging I mean joyous is not a term a lot of physicists love to use a lot but that mode of science is now open

to us along with making more rapid progress. Yeah. And thank you. That's very very good. Brenda, >> sure. Um, yeah, I I think this was was somewhat said, but but I think it's really the ensemble nature of things that that's arising that that we can have an ensemble of of of AI as people and others working together in a collaborative form that wasn't there before. And I I think for people who don't necessarily use a lot of AI, they don't quite see this. They don't

necessarily see the transformations that are happening. But the the fact of the matter is now we're able to bring people on uh similar planes at least uh and have conversations that they weren't able to do before. And so that's really harnessing the full community to to solve problems in ways that we we haven't been able to do in the past. >> Wonderful. >> Um so I happen to be the editor-in chief of a new PNAS journal called PNAS Nexus commercial here. Uh so please submit to

the journal. Uh started in 2022. So it's multi-disiplinary and all that. So I think what we're are not missing but is going to become a big important issue is what does it mean to publish? What does it mean to use AI for for publications? >> The the rules that we have right now are in kind of primitive on the way to to to get there. >> But I think there's going to be a huge revolution in this area that we don't even know how it is. >> No doubt scientific publishing is sort

of been in a state of continuous change for a number of years. So uh the last question is basically the same question that uh uh Chuck as asked before uh to the other panel and again it it goes again to take us to reflect a little bit about what we want to accomplish. Right? So the foundation of science and AI research aims to build a collaborative ecosystem for science and AI. So how do you see industry, academia, investors uh and the side foundation working together to build this ecosystem and what role do you envision for for

your university in this partnership? Let let let us start uh with Janice, >> right? I mean when you look traditionally what we do today uh particularly with with respect to partnerships with the industry >> uh is sort of a has two components. One component is sort of the industry appears to be nice and philanthropic to you. Maybe they give you some some support for for scholarships and everything. Sometimes there is some partnership of some sort. uh the partnership is considered well maybe

there will be some IP maybe you so it's not exactly a very aggressive form of that I think this is going to change because uh people will expect results from you if they support you that I think was mentioned before within six months or a year and it is not the characteristic time that we have in academia which is like three years or or longer >> I think that will be a revolution coming up that we don't see it yet >> uh also So if we were to work on the 6.2 6.3 things that I mentioned it will

require tremendous amount of energy this amount of energy will not be available to institutions unless you partner in some way to do that >> and so that I think this is happen. >> Excellent point. So Brenda >> yeah I I 100% agree about the the time scales maybe I view it from a a different per perspective. Um so you know wi with with AI uh and with a variety of other technologies um what we really need to be doing is is accelerating science and one of the big barriers at least from from my

experience is is the acceleration of of interesting good and new ideas. So so this is coming from the the notion that the university is a sandbox but honestly what universities have been doing for a long time is is playing it safe because of government research. Uh I mean the way that research has historically been funded and also the way publications kind of work is is to incentivize the incremental. So uh you know most most government research maybe not DARPA maybe not a few other agencies that have

really sprung up recently you know it's very much what is your your research portfolio how do you move that forward and just kind of keep moving it forward um but now we're thinking about smaller time horizons and so I think the role that needs to be played uh between industry government and academas is how do we fund those time horizons those short time horizons to bring out really new good ideas and to make them happen fast uh as opposed to sort of saying you know big bold ideas should just should

not be in the arena. You do that on the side somewhere. Um, and also saying that if it's short, well, you know, your grant cycle is two years, the window's already over. I mean, many of us have probably gotten in CS before. I've certainly gotten this. You submit a proposal in 2024 and then you get reviews back in 2026 that say it was so 2025. You know, that's a that's a huge issue. Um, and so we have to work together to change uh that model. >> Thank you. Please, Bob. >> Nothing to add. we can keep move on.

>> Okay. So, you know, we we have probably a few minutes uh that maybe we can have a couple of questions from the audience. Uh uh let's start with Dimma. >> So, uh what IPAM does, right, is that we try to make new things to get people together. What would be your dream pro program at IPAM? We might program to bring people together. What would be your dream program in the next say two years? make it six months if that's working. The dream program I think will be for you know mathematics to be able to

understand uh how AI can be reduction of dimensionality maybe this way in which you can actually go and be able to handle it without having to deal with three billion or trillion of data and come up with some to me that actually should be an an aspiration for us humans to actually show that we're better than machines and I think That's that would be a good a good agenda. >> Other suggestions for programs. >> I I think this was was already said I mean we basically had a whole talk but

you know the path to AGI and the the understanding of cognition and math plays a role very much in this and I think we're we're all trying to understand all these different forms of cognition and what is the is the path forward and and so anything along those dimensions is going to remain valuable for a while. Sorry, sorry, sorry. Please, please, go ahead. >> Building on a chat we were having. Um, I would love to see a collection of interesting unsolved questions, hundreds of them across all the subd

disciplines of the sciences and then figuring out which of those are connected. Again going back to the multidisciplinary theme independent of which subject they came from because the AI methodology they use to tackle um may be quite related and then partnering with some of the our tech colleagues in figuring out um how to solve them. >> Thank you. >> Okay, Mario. >> Yes. So what I'm missing here a little bit from this whole discussion is you know we we heard that AI will transform

research but you know what can we actually do to transform undergraduate education in view of this uh progress right it's clear that we cannot teach let's say our calculus classes the same way we have taught it like for for centuries right so what what are some concrete ideas in this respect >> how many hours do you have Um f first of all let me say that in every university certainly at UPEN there are many individual professors who are doing amazing experiments and I couldn't even begin to capture

them in a few minutes but um you know we need to play defense to protect writing and problem solving from just to put it bluntly cheating with AI. uh but there are innovative ways of doing that but at the same time the teaching of AI and the teaching of just straight up physics chemistry history with a touch of AI innovation I think is a pretty tremendous opportunity I mean this doesn't apply to every discipline but I've for example experimented with a junior level class solving graduate

level problems you know real time with AI assistance. So there's a a lot of opportunities to um make pedagogy more fun and more ambitious. >> Yes, please. So I just one sort of framing question uh which is uh and it keeps sticking with me during your whole conversation and trying giving the specific examples about the scientific applications is that but also uh I think Giannis you had said something early in the conversation that stuck with uh with me about just the the scope of all of

it, the scope of the change and years ago I had a conversation uh very weird one with uh James Watson who made a point of commenting that he uh that the reason he thought that people remembered who he was is he was one of the last scientists who worked on something that people could understand the average person could understand whether or not you agree or not with that but it what it kept sticking in my head is that how do you take something that's so all-encompassing we talked about all the different scopes of it for

AI and it's so relevant for what we're doing here and translate it to your faculty to the students to the administration of how this is transformative but still accessible so that they can get their minds around it and communicate a strategy around it and recognize the need for change, but that it's possible rather than just being Oklahoma. >> Yeah, I I'm I'm not sure that this is u really very difficult to do. I think it's a matter of us making a decision that this is what we need to do. Um many

universities are acutely aware of the need to change their AI things. So I mean you can see this all the time. Um what working models are going to emerge I suppose after different people do different things maybe they will come to something that's much more uh acceptable and much more uh you know appropriate to the specific university and specific area. Um it is true that you know I'm sure here at UCLA definitely at USC uh there is a palpable anxiety to some extent about AI. There's no question

about that and people trying to come up with understanding what you know where we're going with that. Uh it's a administr administrators actually they get it right now. It's I mean you talk to presidents or provos they understand that this is a a very important transformative part and so and it changes very very fast. That's the other thing that happens. So yeah, it's uh let me let me say that when I was trying to put together my presentation, I mentioned at the national academy, I was

looking at my slides every day and then I realized that I had to drop some of them and put some new ones because AI there was something new that came out as AI things are happening at an extraordinary fast pace. So >> yeah, I suppose my view of it is, you know, we we've been through this before with computers, right? If we go back and we say, how did some people react to computers? Um, we can remember that some people didn't want to use computers, didn't want to deal with Wikipedia,

didn't want to deal with Google, blah blah blah. >> The point of at least our strategy at Brown, um, and Brown is a somewhat different institution than others, is is just to make sure people understand that you will be surrounded in it. It is here. It is not leaving. It is not going away. um you you're going to be immersed in it just like everybody uses Google, everybody's going to use AI. Um and so we um put out the tools in many different places. You know, that's conversations, that's uh forums, that's

projects where we work together. We make sure it's out there. Um and you know, I'm sorry, but like in higher ed, we can't knock on doors and say you got to do this today because then people just don't come to those doors anymore. Um, and so, you know, you put it out there and you see that people embibe it in the ways that they're going to embibe it and they incorporate it into their disciplines and the ways that they're going to do it and and nobody can tell you how to incorporate it into your

discipline. So, so our model is to just make sure people know that it's out there and here are the the skills and here are some people who can help you and go. >> Yeah, thank you. I I think that's a really good point perhaps to to stop because we're out of time also, but your AI is here to stay. We saw today that there's so many exciting uh opportunities and developments. You know, really uh everything that was presented today tells us that that this is something that needs to be embraced.

Uh so I'm going to invite Dimma because you have some closing remarks and uh >> well much I just basically wanted to thank first of all the panelists and and Miguel and Chuck and Terry for wonderful day. of course all of you for for coming and I just wanted to say that uh there are lots of interesting things happening at but also at IPAN so please uh look at our calendar and I hope to see all of you in the future. Thank you so much. He's enjoying >> do what humans do best. Actually, I

think at least in the medium term, a much greater uh potential will be just taking away a lot of the repetitive

