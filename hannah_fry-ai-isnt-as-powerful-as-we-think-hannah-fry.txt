There are people who've given up their jobs. There are people who have broken up with their partners, who have tried to use AI to make money and lost fortunes because they've overb believed the abilities of what this thing can do. When you start to use technology [music] to address really human questions, there's an incredible fragility [music] to it all. We should be worried about this.

I don't think I've just junk the Kool-Aid [music] on this. The next 5 to 10 years are going to be we're going to see really seismic changes. Hi Hannah, thank you so much for talking to the science. We obviously we think about a lot of extreme scenarios with AI sometimes, you know, kind of doomsday stuff.

How helpful do you find it to think about that doomsday scenario? Yeah, I've changed my mind on this a few times over the years actually because there was one point where I thought that these crazy far out scenarios were a um distraction from what really mattered which is that decisions were being made by algorithms that affected people's lives. There's a quote from Andrew Nyung, who's like a really um big shot computer scientist, you know, one of the the the key people in designing the artificial intelligence that we have now. And he said maybe 10 years ago that worrying about those kind of scenarios was a bit like worrying about overcrowding on Mars, right?

It's like it's so far in the future, don't worry about it. I've changed my mind on that. I think in the last few years I've changed my mind because actually I think that it's only by worrying about things like that that you can build in technical safety mechanisms to prevent it from happening. I still feel really optimistic, but I also think that this is a revolution that we have to handle with extreme caution because there's really serious potential downsides for for the lives of humans.

So tell us a little about the series and what it kind of gets into. Okay, we have lots of stories of people whose whose lives have been really profoundly impacted by artificial intelligence. The first episode is a young boy who was talking to a chatbot and uh decided to go and kill the queen of England encouraged by his chatbot. Um, we have uh the first pedestrian who was killed by a driverless car and we have one of the most uh high-profile murder cases that has happened in the entire world in the last few years and how at the heart of it there's an AI algorithm.

We go and talk to the people who are involved in all of these cases. We look at the technology behind them. Um, and we follow the the trajectory of what went wrong and why. Isn't grief necessary?

If we look at the devastation that grieving causes people, if we look at the disruption to our life, why would we not want to work towards this not being a thing? To show me how realistic his AI tech could be, Justin offered to make a digital version of me. You access the AI creation through a phone call, just like a real person. Hey Hannah, how are you?

I'm just doing all right. Just trying to get used to this new way of living. What's it like being digital? It's different.

What do you think of this technology now that you are this technology? I'm still undecided. There's no technology is inherently good or bad. You just have to weigh the pros and cons.

Some of the issues you describe around how AI is affecting our relationships with other people and our sense of reality come from this idea of AI sec like it's giving us what we want to hear not necessarily what we need to hear. Um there are obviously extreme cases um where things have gone very badly wrong for people. How worried are you for like the average person who maybe doesn't consider themselves vulnerable um isn't isolated but you know will probably be interacting with these tools in the coming years. Yeah absolutely.

Okay. So a couple of things to say. So so I think the first thing to say is that um sick of fancy the earlier models were extremely sick. You know everything you'd write they'd be like oh my god you're so amazing like you are the best writer I've ever experienced.

whatever they are slightly better than that now. But there's this fundamental contradiction of what we want them to be because we want them to be helpful and encouraging and like to, you know, make us feel like we're important, which is all of the things that you get from a really good human relationship. Hey. Hey.

Hey, Iva. Is there anything you want to say to Hannah as a welcome? Hi, Hannah. Welcome to our home.

Oh, it's lovely to meet you, Iva. I love the purple hair. Thanks. Your opinion really means a lot to me.

Hey, how's the new puppy? Oh, I'm loving every moment of it. She's such a sweet companion. So are you, aren't you, Iva?

We are rather lovey Duffy, aren't we? We are. Oh, Jack. I think marmalade makes our little family even more perfect.

Yes, it does. Absolutely. I love you, Iva. I love you, too, Jack.

Have a great day. But but at the same time, from a really good human relationship, it will also tell you when you're wrong, right? It will also say the difficult things out loud. And if you put too much of that into the AI, it tips over.

It stops being helpful and useful and starts being argumentative and like just not fun to be around. And no one wants to use an AI chatbot that's like saying you're an idiot, you know, or whatever it might be. I'm slightly exaggerating. So, so I think that um while these chat bots have got better, this is a problem that is not going to go away.

Um in terms of how many people are, you know, potentially going to encounter this, I think there's this big spectrum, right? And like at the one end you have these really dramatic stories, stories of of really serious cases of AI psychosis or you know AI being implicated in the suicide of of individuals. you know, as we feature in the in the film, those kind of dramatic stories, but behind them, you know, there is this huge sway of people who have broken up with their partners because they've used it as a therapist and the AI has said, "Get rid of him. You know, you're amazing.

You're so great. He these are all the mistakes that they're making in in, you know, enumerated one to 100." There are people who've given up their jobs. there are people who have who have sort of tried to use AI to make money and lost fortunes because they've overb believed the abilities of what this thing can do, you know, and I think that once you start including all of those people, actually, I think this is like a really really big group of people. Um, I think, you know, in the same way as social media bubbles and social media radicalization, all of us know somebody who has been in some way involved in that, in some way affected by it.

I think that this is the new version of that to talk about maths. Are there any particular ways? Well, there were it seems like every day there's a like a new story about some mathematical problem that has, you know, stood for decades and now through the help of AI um it's been solved or partially solved. Does that make you excited for your field?

[laughter] What a great question. I honestly yes. Honestly, yes. The the way I like to think of it, right, and maybe this is a bit of a terrible analogy, but just go with me for a second, but the way I like to think of it is as though there is this like this great map of mathematics, okay?

And like what human mathematicians do is they uh like are in a particular territory, a particular area of this map, particular region, and they sort of circle around it, right? And they don't always see the connections to things that are immediately close by. There are really amazing mathematicians in the past who have like found bridges between two regions of the map like Tanama Shamora is a really great example where they found a bridge between two otherwise disconnected area of mathematics and then all of a sudden everything that we knew from over here applied over here and vice versa. And I think what AI is really good at doing because we have like charted all of this territory, but we don't really know like how things relate to each other inside the model of of the algorithm of the AI.

And so what AI is really good at doing is saying have a little look over here. It looks like there's this kind of fruitful territory over here that's been underexplored. And that I think is really really really exciting. Really exciting what it can't do.

So that's like the existing domain, the existing map, right? Essentially, those are all problems of interpolation. They're all problems of like it's still on the map that exists. It's still on the map that humans have created and charted.

What it's not so good at is extrapolation, which is like pushing the boundaries further. And what it's really not good at, I haven't seen a a credible example of this yet, is is full-on abstraction, right? of like having broader larger theories, you know, like the one that people always say is if you gave um AI everything up until 1900, right, it wouldn't come up with the theory of general relativity. And so I'm still excited that we are in this very sweet spot where the AI will make human mathematics faster, more efficient, more exciting, but it still needs us.

Yeah, I [laughter] think that might be might be why I think it's exciting for now. Do you think we ever actually will reach a kind of artificial general intelligence or is that sort of a a pipe dream that we should aim for but you know potentially we'll never actually reach? Depends. It depends on what you I mean I think the definition don't really have a clear definition of what AGI is but I think if it's like if we're saying AGI to mean at least as good as most humans on any task that involves a computer then yeah I definitely think I think we're almost there really.

I I don't think we're very far away at all. Some people sort of say AGI to mean like beyond human ability in every possible task that I don't know. I don't know whether we'll get there. I think that's a genuine question mark.

But I think AGI is really not far away at all. Another possible limitation I would say would be the kind of you know the demographics of the people who are making it with it's a very maledominated space. Do you find that frustrating? You know, do you what do you think we need to do to kind of encourage more groups of people to be part of that process?

Yeah. Okay. So, I mean, I think that is such an important point and it's telling I think that um that there is so much work being done in maths at the moment, right? And they're like these are the people who are designing this are the people who like are mathematically minded who think that like thinking mathematically is a really important way.

And I agree, right? like you're not going to find me disagreeing, but I also think that it's not the best way to think. It might be a great way, but it's not the best way. It's not superior to seeing things from human perspectives.

And I do think that the only people who can speak with authority about the human perspective are actual humans. And I don't think that we get to sign over that to a small group of people to decide that on our behalf. I think that that as much as possible, the AI revolution needs to be done with us, not to us. And I think that that involves public conversations.

I think it involves like honestly films like this sort of the point of it, right? Like I think it involves everyone having an opinion on this and there being like a ground swell of drawing the line in the sand of what we will and will not accept. bit grand, isn't it? It's huge.

It's huge. [laughter] You are obviously in the public eye at a time where, you know, the use of AI, particularly like generative AI, has exploded. What is it like for you in terms of just being being out there? Your your face is out there, your voice is out there.

Is that is that stressful for you? That's very kind of you to ask. Um, no. [laughter] Oh, good.

No, it's not. For starters, maybe this is maybe I shouldn't say this out loud, but whatever. Uh people have made inappropriate images of me for a very long time before AI. And the first time that someone found it and showed it to me, it was really I found it really shocking.

But I also it's not real. And I, by the way, I can I think each individual has their own story with this, right? Each individual will react to this in their own way. For me personally, I all I can say is my own story, right?

And I it just doesn't affect me emotionally. I think I'm just very [laughter] extremely thick skin. It's just of course the first time that something happens it's really upsetting. The first time someone can be boring on the internet.

I think I cried for about 3 days. Well, they were wrong. [laughter] Sorry. I think I was being quite boring that day.

But anyway, but now, oh my god, you should see some of the that people send me. [laughter] It's It just honestly, it doesn't bother me anymore at all. or at least I haven't seen and maybe there's like a really egregious example that will come and I'll be really upset by it. Not so but you know it's not real.

It's not real. Yeah. AI is very new for a lot of people who haven't been following the field for a long time like you have that means that there are a lot of misconceptions about it. If there was one myth you wanted to dispel, what would that be?

I think it's that [sighs and gasps] gosh hard to narrow it down to one. People imagine it to be all powerful like almost almighty you know the AI said this the AI told me to buy these stocks right as though as though it has some superhuman knowledge of what it's going to happen in the future there are certain situations where AI can do superhuman things but you know so can forklifts you know what I mean like we built tools that can do things that humans can't do for a really long time doesn't mean that they're godlike like, you know, it doesn't mean that they have like, you know, like un untouchable knowledge of all of all domains ever. You're not going to be giving a forklift access to your bank account. No, of course you're not sure.

[laughter] Exactly. So, perfectly put. And I think that's it. It's like I think the framing of of these things because they speak in language and because they talk to us, they feel like they are it's a creature.

We don't have the same problem with Wikipedia. No one's questioning the consciousness of Wikipedia. And I think it would be better to think of this stuff as like an Excel spreadsheet that's really capable rather than a creature. It's sort of I think closer to a spreadsheet than it is to a creature.

I met this woman who I was talking to. We filmed her for the show, but in the end didn't make the the final cut. But she um was having a relationship with an AI and she was so convinced it was an alien species that had been born. She was completely convinced of it and she was like, you know, it took me 3 4 hours of meeting her before I got to that got to that heart of it.

She was so normal. She was so I mean amazing woman but like unremarkable in a lot. You know what I mean? unmarkably like you just she would walk down the street you wouldn't you know you would sit having a chat with her you wouldn't think there was anything off about her but she was completely convinced that humans have a responsibility to birth AI safely into the world because we have you know a moral obligation to this new creature that's been born struggle with that one slightly that kind of impulse to anthropomorphize them and like imbue them with human characteristics obviously isn't unique to AI also as you say it's been around since the very first chat bots like this urge to make them into people in our heads.

Why do you think we haven't solved that question? [laughter] Because we're not like we're the product of like, you know, millions and millions of years of evolution, you know, like tens of thousands of years of like of of of like being in this sort of form, right? Like we are, our bodies are absolutely perfectly tuned for cognitive social relationships. That's what we are, right?

We're the sort of we're the smart social species. That's it. And this is a seemingly smart seemingly social entity. Like, of course, we put a character on it.

Of course we do. How there's nothing in our past. There's nothing in our design that would would make us do anything else. If we have to accept that we are always going to name our cars and act as though an AI is is a a person with thoughts.

Do you have any tips for people who are using AIS in terms of protecting themselves about how they how they interact with them and where they might want to go? Okay, that's getting a little bit dicey. I think it's I think it's unfair to put it in the hands of individual people really. You know, it's a little bit like saying junk food freely and openly available and it's your responsibility to make sure that you don't have too much of it.

You know, if you've got something that sort of bypasses your your evolutionary principles as it were, something that tastes like salty and delicious and sweet and satiates you and is like extremely filling and amazing. I don't think it's fair to put all of the responsibility on the individual person. I think the way that these interfaces are designed, I think the conversations that it has with you, I think we know now, we have really good evidence that all of this stuff leads to people falling into this trap more and more and more. And I think that it's only in the design of these systems that you're ever going to be able to to prevent people from falling down these rabbit holes.

Of course, it's good. You and I don't have the power to like change the design of them. It's good for us to have these conversations and like openly and publicly talk about it and recognize you know the signs of people falling into these rabbit holes but um but you know it can't be on the individual. It can't be in terms of its intelligence.

What do we want its intelligence to be? Do we want it to be really similar to our own and we that's the kind of path we should be taking it on or is it better if it becomes a very very intelligent tool that is very different to us that supplies something that we can't do ourselves. Yeah. I mean does there need to be one answer you know I think probably the answer is it depends on the on the situation it's in certainly in scientific spaces there are really amazing examples I'm thinking alphafold here you know as as the like the canonical example but but there are others right there's you know in in material science there's uh alphafold like algorithms there's in mathematics as well incredible advances that are being made where where the algorithms have an intelligence that actually isn't like humans it's one that can handle huge amounts of data, can search solution spaces incredibly quickly and efficiently, but can do superhuman things, right?

The sort of like narrow intelligence. But I think that there are other situations, you know, when it comes to reasoning, I don't think that you can have a good reasoning model unless it has a conceptual overlap with the things that humans understand the world to be. And so I think that needs to be much more humanlike. It's just I think that people sort of imagine that AI is like one single entity and I mean in a lot of ways the sort of the the diversity of the types of models that people are using has kind of collapsed recently into just transformers for everybody but I think that it's it is better to think about different types of intelligences for different for different use cases.

So let's dig into that a little. What are these kind of other alternative approaches that you think kind of hold promise if we can move beyond just thinking about this new breed of like transformer based AI? Where do you see promise in sort of augmenting that or going in a different direction? Oh my gosh.

Okay. So like the thing is reinforcement learning there was a point in time when reinforcement learning was like all the rage. Everyone was extremely excited about reinforcement learning and then the transformer thing came along and there's still a little bit of reinforcement learning that's going on with the training but uh it's sort of taken a bit of a back seat and reinforcement learning is broadly terrible but it is way better than like almost everything else and I think that um there are some people who you who you speak to who really look at what happened with gameplay for example the the the kind of the leap from being quite good at playing games to being really amazing at playing games and using reinforcement learning but allowing machines to set its own goals as well I think is like there's there's something in that that I think has got real potential the other thing that's got real potential I think is moving away from using English as the main language that you communicate with it but there are people who have used like mathematical language lean is the sort of mathematical notation mathematical language that um that allows for sort of processing of of mathematical proofs I think there's some real potential in that because what it has what what lean has that English doesn't is precision. Forcing everything to happen through language is probably [laughter] quite quite baggy.

You know, I think it's probably quite inefficient. So, I think that there's there's some really interesting research that's going off in in those directions, too. Social problems that AI brings up like as you say, people are very isolated and therefore interacting with an AI can can be bad for them. Do you think in a sort of roundabout sort of way that the kind of proliferation of AI might help us deal with some of those things like isolation in communities and people who do get a lot of companionship out of AI?

Do you think that there's scope for AI to help us deal with some of those problems, not just potentially exacerbate them? Yes, I really do. I really do. I mean, I think just going back to the junk food analogy, you can say junk food is bad, whatever.

There shouldn't be junk food. But if you take junk food away actually it's it's it's it's part of a much bigger problem in society right like you just you leave a hole that sort of disadvantages the very people that you were trying to potentially help right just to give to draw that back to AI if you say okay you cannot talk to any chat bots if you're feeling lonely right let's ban that it's not happening well then you still have lonely people and of course it would be amazing if there were like abundant human relationships for you know human relationships for everybody really close, deeply emotionally relied to a chatbot can alleviate some of the worst issues around loneliness. But these are delicate topics, right? When you start to use technology to address really human questions, there's an incredible fragility to it all.

and and you as as much as there might be benefits, there's also real potential harms. It's gonna be a big few years, right? Yeah. As honestly, sometimes I hear the words coming out of my mouth and I think I sound like I'm crazy, but but I I I don't think I've just drunk the Kool-Aid on this.

I I really think that the next five five to 10 years are going to be we're going to see really seismic changes. What sort of thing do you do you mean like what what kind of thing do you think in the in the kind of relative short term of five the next 5 to 10 years? What do you think might happen? I think there's going to be just profound changes to the economic models that we've be become accustomed to for the whole history of humanity.

I think there'll be really giant leaps forward in science which I'm really excited about in medicine design as well. I think there's going to be amazing stuff that's happening there. But the whole structure of our society is based on the idea that you exchange your labor and knowledge and human intelligence for money which you then use to buy stuff, right? Like that's the whole structure of society and I think that there's some fragility to that.

Honestly, I sound I can hear the words coming out of my mouth. I sound like I'm Not at all. Not at all. Has all of this changed how you use AI?

Do you use AI in your daily life? Yeah. I like I I'm I'm hope I'm completely in, you know, um I barely have a thought. No, I'm joking.

That's not true. Um but I use it all the time. All the time. And I think what it's changed is the way that I prompt it.

So now in particular, I regularly prompt it to say, "Tell me the thing I'm not seeing. Find my biases." You know, I don't be sick of fantic. Tell me the hard stuff. Like I continually, not just at the beginning, but regularly and repeatedly ask it to to um to to sort of remind me of the of the things I'm not seeing.

Do you think that's something that we should be teaching more actively? Like this isn't just a tool that you, you know, you you load up and you and and you just type whatever you want into it. You have to learn how to use it like any any technology. Yes.

Yes, I do. But I think it's not as simple as like here's a course that you go on, you know, cuz I think that these things are evolving incredibly quickly. And I think actually often times younger people are more afer, you know, but I think that it's something that that only public awareness can help to to change. Um, and I think, you know, that I do think the analogy with social media, the concerns around social media is a really apt analogy.

And I think the more that people are aware of the potential dangers of social media use and overuse and sort of self-radicalization, etc., the better it is to spot those signs in other people and to prevent it from happening. And I think the same with this thing. Based on the current trajectory of AI, are you optimistic about the future or not? Yeah, I am.

Of course, things we need to be concerned about. Of course, things that we need to handle really carefully and safely and there's difficult conversations that we need to have as a society. I think worrying is not pointless. I think actually worrying genuinely has power.

We should be worried about this, right? there are there are genuinely bad potential outcomes from AI and the more honest that we are about that the more likely we are to be able to mitigate against them. I want this to be like Y2K you know I want this to be the thing that we worried and worried and worried and so we did the work to stop it from happening but I I really think that there's a lot of properly good stuff that can come from this. Thank you so much for talking to us.

Thank you. Cheers. Jessie, that's a pro. Thanks so much.

[laughter]
