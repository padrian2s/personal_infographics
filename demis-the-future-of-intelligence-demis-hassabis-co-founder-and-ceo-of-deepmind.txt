We effectively you can think of as 50% of our effort is on scaling, 50% of it is on innovation. My betting is you're going to need both to get to AGI. I've always felt this that if we build AGI and then use that as a simulation of the mind [music] and then compare that to the real mind, we will then see what the differences are and uh potentially what's special um and remaining about the human mind, [music] right? Maybe that's creativity, maybe it's emotions, maybe it's dreaming.

There's a lot of consciousness. There's a lot of um hypotheses out there about what may or may not be computable. And [music] this comes back to the chewing machine question of like what is the limit of a chewing machine. So there's nothing that cannot be done within the sort of computational.

Well, no one's put it this way. Nobody's found anything in the universe that's that's non-computable so far. So far. Welcome to Google Deep Mind the podcast with me, Professor Hannah Fry.

It has been an extraordinary year for AI. We have seen the center of gravity shift from large language models to agentic AI. We've seen AI [music] accelerate drug discovery and multimodal models integrated into robotics and driverless cars. Now, these are all topics that we've explored in detail on this podcast.

But for the final episode of this year, we wanted to take a broader view, something beyond the headlines and product launches to consider a much bigger question. Where is all this heading [music] really? What are the scientific and technological questions that will define the next phase? And someone who spends quite a lot of their time thinking about that is Demis, [music] CEO and co-founder of Google DeepMind.

Welcome back to the podcast, Deis. Great to be back. I mean, quite a lot's happened in the last year. Yes.

What's [laughter] what sort of the biggest shift do you think? Oh wow. I mean um it's just so much has happened as you said it's just it feels like we've packed in 10 years in one year. I think a lot's happened.

I mean certainly for us uh the the progress of the models um we've just released Gemini 3 which we're really happy with. Um the the cap multimodal capabilities all of those things have just advanced really well. And then probably the thing I I guess over the summer that I'm uh very excited about is world models being advanced. I'm sure we're going to talk about that.

Yeah, absolutely. We will get on to all of that stuff in a bit more detail in a moment. Um, I remember the very first time that I interviewed you for this podcast and you were talking about the root node problems about this idea that you can use AI to kind of unlock these downstream benefits. Um, and you've made pretty good on your promise, I have to say.

And do you want to give us an update on on where we are with those where what are the things that are just around the corner and and the things that we've that you've sort of solved or near solved? Yeah. Well, of course, obviously the big proof point was was AlphaFold and sort of crazy to think we're coming up to like 5year sort of anniversary of of AlphaFold being sort of announced to the world, Alpha Fold 2 at least. So that was the proof I guess that it was possible to do these root node type of problems.

And we're looking we're exploring all the other ones now. I think material science uh I'd love to do a room temperature superconductor um and uh you know better batteries these kinds of things. I think that's that's on the cards. uh better materials of all sorts.

We're also working on fusion um because there's a new partnership that's been announced fusion. Yeah, we've just announced partnership with a deep one. We we already were collaborating with them, but it's a much deeper one now with Commonwealth Fusion who, you know, I think are probably the best startup uh uh working on at least traditional TOKAC uh reactors. So they're probably closest to to having something uh uh viable and we want to help accelerate that uh you know helping them contain the plasma in the magnets and maybe even some material design there as well.

So that's exciting. And then we're collaborating also with our quantum colleagues which they're doing amazing work uh at the at the quantum AI team at Google and we're helping them with error correction codes uh where we're using our machine learning to help them and then maybe one day they'll help us. [laughter] That's perfect. Exactly.

The fusion one is particularly I mean the difference that that would make to the world that would be unlocked by that is gigantic. Yeah. I mean fusion's always been the holy grail. Of course I think solar is very promising too, right?

Effectively using the fusion fusion reactor in the in the in the clouds in the sky. But um I think if we could have uh modular fusion reactors, you know, this promise of uh almost unlimited renewable clean uh energy uh would be obviously transform everything. And that's the holy grail. Of course, that's one of the ways we could we could um uh help with climate does make a lot of our existing problems sort of disappear if we can if we can definitely I mean it opens up many this is why we think of as a root node.

Of course it helps directly with energy and and pollution and and so on um and helps with the with the climate crisis. But also, if energy really was renewable and clean and and and super cheap or almost free, then many other things would become viable. Um, like, you know, water access cuz we could have desalination plants pretty much everywhere. Uh, even making rocket fuel.

Uh, you know, it's just there's lots of seawater that contains hydrogen and oxygen. That's basically rocket fuel, but it just takes a lot of energy to split it out into hydrogen and oxygen. But if energy is cheap, uh, and and renewable and sort of clean, then why not do that? you know, you could have that producing 247.

You're also seeing a lot of change in the uh the AI that is applying itself to mathematics, right? That you know, winning medals in the International Math Olympiad and yet at the same time, these models can make quite basic mistakes in high school math. Why is there that paradox? Yeah, I think it's fascinating actually.

One of the most fascinating things and probably that needs to be fixed uh as one of the key things while we're not at AGI yet. Um, as you said, we've had a lot of success in other groups on getting like gold medals at the International Mass Olymp. You look at those questions and they're they're super hard questions that only the top students in the world can can do. And on the other hand, if you pose a question in a certain way, we've all seen that with with experimenting with chat bots ourselves uh in our daily lives that it can make some fairly trivial mistakes on logic problems.

They can't really play decent games of chess yet, which um is surprising. So there's something missing um uh still from these systems in terms of their consistency. And I think that's one of the things that's you would expect from a general intelligence and art, you know, an AGI system is that it would be consistent across the board. And so sometimes people call it jagged intelligences.

So they're really good at certain things, maybe even like PhD level, but then other things they're like not even high school level. So it's very uneven still the performances of these systems. They're very very impressive in certain dimensions. Um but they're still pretty uh uh basic in others and we've got to close those gaps.

And you know there are theories reasons to why and depending on the situation it could even be uh the way that an image is is perceived and tokenized. So sometimes actually it doesn't even get all the letters that you you know so when you count letters in words um it sometimes gets that wrong but but it may not be seeing that each individual letter. So there's sort of different reasons for some of these things. uh and each one of those can be fixed and then you can see what's left.

Um but I think consistency I think another thing is reasoning and thinking. So uh we have thinking systems now that at inference time they spend more time thinking and they're better they're better at outputting their answers. Um but it's not sort of super consistent yet in terms of like is it using that thinking time in a useful way um to actually double check and use tools to double check what it's outputting. I think we're we're on the way, but maybe we're only 50% of the way there.

I also wonder about that that story of of Alph Go and then Alpha Zero where you sort of took away all of the human experience and found that the model actually improved. Is there a sort of is there a scientific or a maths version of that in in the the models that you're creating? I think what we're trying to build today, it's more like Alph Go. So, you know, you effectively these these large language models, these foundation models, they're starting with all of human knowledge.

you know, what we put on the internet, which is pretty much everything these days, and um compressing that into some useful artifact, right, which they can look up and and generalize from. But I do think we're we're still in the in the early days of having this uh uh search or thinking on top like AlphaGo had to kind of uh use that model to direct in useful reasoning traces, useful planning uh ideas. Um and and then come up with the best, you know, solution to whatever the problem is at that point in time. So I I don't feel like we're constrained at the moment with the kind of limit of human knowledge like the internet.

I think the main issue at the moment is we don't know how to use those systems in a reliable way fully yet in the way we did with Alph Go. Um, but of course that was a lot easier because it was just it was a game. I think once you have Alph Go there, uh, you could go back just like we did with the the Alpha series and do an Alpha Zero where it starts sort of discovering knowledge for itself. I think that would be the next step, but I I that's obviously harder and so I think it's good to try and create the first step first with some kind of alphike system and then we can think about an alpha zero like system.

But that is also one of the things missing from today's systems is the ability to online learn and continually learn. So you know we train these systems, we balance them, we postrain them and then they're out in the world but they don't do they don't continue to learn out in the world like like we would. Um, and I think that's another missing critical missing piece from from these systems from from, you know, that will be needed before AGI. In terms of all of those missing pieces, I mean, I know that there's this big race at the moment to release commercial products, but but I also know that that Google Deep Mind's roots really lie in in that idea of scientific research.

And I I found a quote from you where you recently said, "If I had had my way, we would have left AI in the lab for longer and done more things like AlphaFold, maybe cured cancer or something like that." Mhm. Do do you think that we lost something by not taking that slower route? Um I think we lost and gained something. So I feel like that would have been the more pure scientific approach.

At least that was my original plan say 15 20 years ago that you know when almost no one was working on AI. We just started we were just about to start Deep Mind. People thought it was a crazy thing to work on. Um but we believed in it and and and and I think that the idea was if we would make progress we would continue to sort of um incrementally build towards AGI be very careful about what each step was and and the safety aspects of it and so on analyze what the system was doing and so on.

But in the meantime you wouldn't have to wait till AGI arrived before it was useful. You could branch off that technology and use it in really beneficial ways to society namely advancing science and medicine. So exactly what we did with AlphaFold actually which um it's not it's not a foundation model itself general model but it uses the same techniques you know transformers and other things and then blends it with um uh more specific things to that domain. So I imagined a whole bunch of those things getting done while which would be hugely you know you'd release to the world for just like we did with AlphaFold and indeed do things like cure cancer and so on.

um whilst we were working on the sort of more the AGI track in the lab. Now it's turned out uh that chat bots were possible at scale and people find them useful and then they've now morphed into these foundation models that can do more than chat and text obviously including Gemini. Uh they can do images and video and all sorts of things and um that's also been very successful commercially and in terms of a product and I love that too. Like I've always dreamed of having the ultimate assistant that would help you in everyday life, make it more productive, maybe even protect your brain space a bit as well from an attention so that you can focus and be in flow and so on cuz you know today with social media it's just noise noise and I think AI can actually that works for you could help us with that.

Um, so I think that's good, but it has created this pretty crazy race condition where there's many commercial organizations and even nation states all rushing to, you know, improve and overtake each other and that makes it hard uh to do sort of rigorous science at the same time. We try to do both and I think we're getting that balance right. On the other hand, there are lots of pros of the way it's happened which is of course there's a lot more resources coming uh into the area. So that's definitely accelerated progress.

Um and also um I think the general public are actually interestingly only a couple of months behind the absolute frontier in terms of what they can use. So everyone gets the chance to sort of feel for themselves what AI is going to be like. And I think I think that's a good thing and then governments sort of understanding this better. The thing that's strange is that I mean this time last year I think there was a lot of talk about um you know scaling eventually hitting a wall about us running out of data and yet you know we're recording now Gemini 3 has just been released and it's leading on this whole range of different benchmarks.

Um how how has that been possible? Like wasn't there supposed to be a problem with scaling hitting a wall? I think a lot of people thought that especially as other companies have sort of had slower progress should we say but I think we've never really seen any wall as such like what I would say is um maybe there's like diminishing returns and people when I say that people think only think like oh so there's no returns like it's zero or one it's either exponential or or it's asmtopic no actually there's a lot of room between those two regimes and I think we're in in between those so it's not like you're going double the performance on all the benchmarks every time you release a new iteration. Maybe that's what was happening in the early very early days, you know, three four years ago.

But you are getting significant improvements like we've seen with Gemini 3 that are well worth the investment and the return on that investment and doing. So I that we haven't seen any slowdown on. There are issues like are we running out of just available data but there are ways to get around that you know synthetic data uh generating your you know these systems are good enough they can start generating their own data especially in certain domains like coding and math where you can verify the answer in some sense you could produce unlimited data so all of these things though are research questions and I think that's the advantage that we've always had is that um we've we've always been sort of research first and We I think we have the broadest and deepest research bench always have done. Um and if you look back at the last decade of advances whether that's transformers or alpha zero any of the things we just discussed that they all came out of Google or deep mind.

So I've always said like if if more innovations are needed uh scientific ones then I would back us to be the place to do it just like we were you know in the previous sort of 15 years for a lot of the big breakthroughs. So I think that's just what's transpiring and I actually really like it when the terrain gets harder because then it's not just worldass engineering you need which is already hard enough um but you have to ally that with worldclass research and science which is what we specialize in uh and on top of that we also have the advantage of world-class infrastructure with our TPUs and and other things that we've invested in a lot for a long time um and so that combination I think allows us to uh uh sort be at the frontier of the innovations as well as the scaling part and we effectively you can think of as 50 50% of effort is on scaling 50% of it is on innovation and I think my betting is you're going to need both to get to AGI [snorts] I mean one thing that we are still seeing even in Gemini 3 which is an exceptional model is uh this idea of hallucinations so I think um there was one metric that said uh it can still give an answer when actually it should decline um I mean could you build the system where Gemini gives a confidence score in the same way that Alpha Fold does. Yeah, I think so. And I think we need that actually.

And I think that's sort of one of the missing things. I think we're getting close. I think the better the models get, the more they know about what they know, if that makes sense. And so, and I think the more reliable we could sort of rely on them to actually introspect in some way or do more thinking and actually realize for themselves that they're uncertain or there's there's there's uncertainty over this answer.

Uh, and then we've got to sort of work out how to train it in a way that where it can it can output that as a as a reasonable answer. Um, we're getting better at it, but it still sometimes, you know, it sort of forces itself to answer when it probably shouldn't. Um, and then that can lead to a hallucination. So, I think, you know, a lot of the hallucinations are of that type currently.

So, there's a missing piece there that that sort of has to be solved. And you're right, as we did solve it with Alpha Fold, but in in obviously a much more limited way cuz presumably behind the scenes there is some sort of measure of probability of whatever the next token might be. Yes, there is of the next token. That's how it all works.

But that doesn't tell you the overall arching piece is this is you know how confident are you about this entire fact or this entire um statement. And I think that's why you'll need this. I I think we'll need to use the thinking steps and the planning steps to go back over what you just output. At the moment, it's a little bit like the systems are just it's like talking to some a person and they just, you know, when when they're in on a bad day, they're just literally telling you the first thing that comes to their mind.

Most most of the time that would be okay. But then sometimes when it's very difficult thing, uh you'd want to like stop pause for a moment and maybe go over what you were about to say and adjust what you were about to say. But perhaps that's happening less and less in the world these days, but um that's still the better way of having a discourse. So, you know, I think you can think of it like that.

These models need to do that better. I also really want to talk to you about um the the simulated worlds and putting agents in them because we got to talk to your genie team earlier today. Tell me why you care about simulation. What What can a world model do that that a language model can't?

Well, look, I it's it's actually been it's probably my longest standing passion is world models and simulations. uh in addition to AI and of course it's all coming together in our most recent work like Genie and I think um language models are able to understand a lot about the world I think actually more than we expected more than I expected because language is actually probably richer than we thought it contains more about the world than we maybe even even linguist maybe imagined and that's you know proven now with these new systems but there's still a lot about the the spatial dynamics of the world you know how spatial awareness um and the cont the physical context we're in um and how that works mechanically that um isn't is hard to describe in words and isn't generally described in in corpuses of of words and a lot of this is allied to learning from experience online experience there's a lot of things which you can't really describe something you have to just experience it um maybe the sensors and so on are very hard to put into words you know whether that's you know motor angles and smell and you know these kind of sensors it's very difficult to describe that in any kind of language. So I think there's a whole set of things around that and I think if we want robotics to work or a universal assistant that maybe comes along with you in your daily life maybe on glasses or you know on your phone um and helps you in your everyday life not just on your computer um you're going to need this kind of world understanding and uh world models are at the core of that. So this what we mean by a world model is this this sort of model that understands the causitative and effect of of the mechanics of the world right intuitive physics but um how things move how things behave.

Um now we're seeing a lot of that in our video models actually and one way to show how do you test you have that kind of understanding well can you generate realistic worlds cuz if you can generate it then in a sense you must have understood uh uh the system must have encapsulated a lot of the mechanics of the world so that's why Genie and VO and these models are our video models and our sort of interactive world models are really uh impressive but also important steps towards showing we have generalized models and then hopefully some point we can apply it to, you know, robotics and and and universal assistance. And then of course, one of my favorite things I'm definitely going to have to do at some point is reapplying it back to games and and uh you know, game simulations and create the ultimate games, which of course was maybe always my subconscious plan. All of this. Yeah.

All of the time. [laughter] Exactly. What about science too though? Could you use it in that in that domain?

Yes, you could. So uh science you know again I think building models of scientifically complex uh uh domains uh whether that's materials on atomic level um you know in biology uh but also like some physical things as well like weather one way to um understand those systems is to build simula learn simulations of those systems from the raw data right so you have a bunch of raw data let's say it's about the weather and obviously we have some amazing weather projects going on um and then you have a model that kind of learns those dynamics and can recreate those dynamics uh more efficiently. So uh than doing it by brute force. So I think there's huge potential for simulations and uh kind of world models maybe specialized ones for aspects of of science and mathematics.

But then also I mean you can drop an agent into that simulated world too, right? Yes. your Genie 3 team, they had this really lovely quote which was almost no prerequisite to any major invention was made with that invention in mind. And they were talking about dropping agents into these simulated environments and allowing them to explore with sort of curiosity being their main motivator, right?

And so that's that's another really exciting use of these these uh world models is you can we have another project called Simma. We just we just released Simma 2. sim, you know, simulated agents where you have an avatar or an agent and you put it down into a virtual world. It can be a normal, it can be a kind of actual commercial game or something like that, very complex one like No Man's Sky, kind of open world space game.

Uh, and then you can you can instruct it with because it's got Gemini under the hood, you can just talk to the agent and and give it give it tasks. But then we thought, well, wouldn't it be fun if we plug Genie into Simma and sort of drop Simmer, a Simma agent into a another AI that was creating the world on the fly. So now the the two AIs are kind of interacting in the minds of each other. So Simmer's, you know, the Simma agents trying to navigate this world and Genie is, as far as Genie is concerned, that's just a player and uh an avatar doesn't care.

There's another AI. So it's just generating the world around whatever Sim is trying to do. So, so that it's kind of amazing to see them both uh interacting together. And I think this could be the beginning of an interesting training loop where uh you [snorts] almost have infinite training uh examples because uh whatever the simmer agent's trying to learn, Genie can basically create on the fly.

So, I think that you could imagine a whole world of like uh setting and solving tasks, just millions of tasks automatically, and they're just getting increasingly more difficult. So, we might try to set up a kind of loop like that. Um, as well as obviously those simmer agents could be great as game companions. Um, also some of the things that they learn could be useful also for robotics.

Yeah. The end of boring NPCs basically. [laughter] Exactly. It's going to be amazing for these games.

Yeah. Those worlds that you're creating though, how do you make sure that they really are realistic? I mean, how do you ensure that you don't end up with physics that looks plausible but is actually wrong? Yeah, it that's that's a great question and and and and can be an issue.

It's basically hallucinations again. So some hallucinations are good cuz cuz you it also means you you might create something interesting and new. So in fact sometimes if you're trying to do create creative things or trying to get your system to create new things, novel things, um a bit of hallucination might be good, but you want it to be intentional, right? So not uh so you kind of switch on the hallucinations now, right?

Or the the creative um exploration. But yes, with with the with when you're trying to train a simmer agent, you don't want genie hallucinating kind of physics that are wrong. So actually what we're doing now is we're almost creating a physi physics benchmark where um we can use game engines which are very accurate with physics to create lots of like um fairly simple like the sorts of things you would do in your physics A level uh lab uh lessons, right? like you know rolling little balls down different tracks and seeing how fast they go and so like really teasing a part on a very basic uh level like Newton's three laws of motion has it encapsulated it um whether that's VO or Genie have these models encapsulated the physics of that 100% accurately and right now they're not they're kind of approximations and they look um realistic when you just casually look at them but they're not uh they're not accurate enough yet to rely on for say robotics So now we've got these really interesting models.

Um, and with physics, I think that's going to probably involve generating loads and loads of ground truth. Simple videos of pendulums, you know, what happens when two pendulums go around each other, but then very quickly you get to like three body problems which are not solvable anyway. So I think it's going to be interesting. But what's amazing already is when you look at the the video models like VO and just the way it treats reflections and liquids, it's pretty unbelievably accurate already, at least to the naked eye.

So the next step is actually going beyond what a human can amateur can perceive and uh would it really hold up to a proper physicsgrade experiment? I know you've been thinking about these simulated worlds for a really long time and uh I went back to the transcript of our first interview and in it you said that you really like the theory that consciousness was this consequence of evolution um that you know at some point in our evolutionary past there was like an advantage to understanding the internal state of another and then we sort of turned it in on ourselves. Does that make you curious about running sort of an a agent in evolution inside of a simulation? Sure.

[laughter] Um, I mean, I'd love to run that experiment at some point. Kind of re rerun evolution, rerun um almost social dynamics as well. Like the the Santa Fe used to run lots of cool experiments on little grid worlds. I used to love some of these, but they're mostly economists and they were trying to like, you know, run like little uh artificial societies and they found that things all sorts of interesting things got invented like that uh if you let agents run around for long enough with the right incentive structures.

markets and banks and all sorts of crazy things. So I think it would be really cool and also just to understand the origin of life and the origin of consciousness. And I think that is the one of the big passions I had for for working on AI from the beginning was I think you're going to need these kinds of tools to really understand where we came from and what these phenomena are. Um, and I think simulations is is is one of the most powerful tools to do that because you can then do it statistically because you can run the simulation many times with control slightly different initial starting conditions and then um maybe run it millions of times and then understand what the slight differences are in a very uh controlled experiment sort of way which of course is you know very difficult to do in the real world for any of the really interesting questions we want to answer.

So I think accurate simulations will be an unbelievable boon to science given you know what we've discovered about sort of emergent properties of these models right having sort of conceptual understanding that we weren't expecting do you also have to be quite careful about running this sort of simulation uh I think you would have to be yes but that that's the other nice thing about simulations you can run them in you know pretty safe sandboxes maybe eventually you want to air gap them uh and you can of course monitor what's happening in the in the in the simulation 24/7 uh and you have access to all the data. So we may need AI tools to help us monitor the simulations because um they'll be so complex they'll be and there'll be so much going on in them. If you imagine loads of AIs running around in a simulation uh uh it will be hard for any human scientist to keep up with it on but we could probably use other AI systems to help us analyze and flag anything interesting or worrying in those simulations uh automatically. I mean this I guess we're still talking sort of medium to long term in terms of this stuff.

So so just going back to the trajectory that we're on at the moment. Um I also want to talk to you about the the impact that AI and AGI are going to have on on wider society. Um and last time we spoke you said that you thought AI was overhyped in the short term but underhyped in the long term. Um and I know that this year there's been a lot of chatter about an AI bubble.

Yes. What happens if there is a bubble and it bursts? What happens? Well, look, I I think yes that I still subscribe to it's overhyped in the short term still and still underappreciated in the in the medium to long term what's going to you know how transformative it's going to be.

Um yeah, there is a lot of talk of course right now about AI bubbles. Um in my view uh I I think it there isn't it's not one thing binary thing are we or aren't we? I think there are parts of the AI ecosystem that are probably in bubbles. What one example would be, you know, just seed rounds for startups uh that basically haven't even got going yet and they're raising at tens of billions of dollars uh valuations just out of the gate.

It's sort of interesting to see how how can that be sustainable? Um you know, my guess is probably not uh at least not in general. Um so there's that area. Then the people are worrying about obviously there's there's the big tech valuations and other things.

I think there's a lot of real business underlying that. So um but it remains to be seen. I mean I think maybe for any any uh new unbelievably transformative and profound technology of which of course AI is probably the most profound. Uh you're going to get this uh overcorrection in a way.

So when we started Deep Mind no one believed in it. No one thought it was possible. People were wondering what's AI for anyway. And then now fast forward 10 15 years and now obviously it seems to be the only thing people talk about in business.

And um so it's a but you're sort of going to get it's almost an overreaction to the underreaction. Um so I think that's natural. I think we saw that with the internet. I think we saw with mobile and I think we're we're seeing or going to see it again with AI.

Um I don't worry too much about are we in a bubble or not because from my perspective as you know leading Google deep mind and also obviously with Google as as and alphabet as a whole our job and my job is to make sure either way we uh are come out of it very strong and I think and we're very well positioned and I think we are tremendously well positioned either way. So if it continues going like it is now fantastic. we'll carry on, you know, all of these great things that we're doing and experiments and progress towards AGI. If there's a retrenchment, fine.

Then also, I think we're in a great position because, uh, we have our own stack with TPUs. We also have, um, all these incredible Google products and, you know, the profits that all makes to plug in our AI into. And we're doing that with search is totally revolutionized by AI overviews, AI mode, with Gemini under the hood. We're looking at workspace at email, you know, at YouTube.

So, there's all these amazing things in Chrome. There's a lot of these amazing things that um AI we can see already are lowhanging fruit to apply uh Gemini 2 as well of course as Gemini app which is doing really well as well now and and and the idea of universal assistant. So, there's new products and I think they will in the fullness of time be super valuable, but we don't have to rely on that. we can just power up our existing uh ecosystem.

Uh which is all sort of I think that's what's happened over the last year. We've got that really efficient now. In terms of the the AI that people have access to at the moment, I I know you said recently how important it is not to build AI to maximize user engagement just so we don't repeat the the mistakes of social media. But I but I also wonder whether we are already seeing this in a way.

I mean people spending so much time talking to their chat bots that they end up kind of spiraling into self-radicalizing. Yeah. Um, how do you stop that? How do you build AI that that puts users at the center of their own universe, which is sort of the point of this in a lot of ways, but without creating echo chambers of one?

Yeah, it's a very, you know, um, careful balance that, you know, I think is one of the most important things that we as an industry have got to get right. So I think we've seen what happens with uh you know some systems that were overly syopantic or you know then you get these these sort of echo chamber reinforcements that are really bad for the person. So I think part of it is and actually what we want to build with with Gemini and I'm really pleased with the Gemini 3 persona that we had a great team working on and I helped with too personally is um just this sort of almost like a scientific uh personality that's um it's warm, it's helpful, it's light, but it's it's it's succinct to the point and it will push back on things in a friendly way that don't make sense. you know, rather than trying to reinforce you, you know, the idea that the earth's flat and you said it and it's like wonderful idea, you know, I don't think that's good in general for society if that were to happen.

Um, but you got to balance it with what people want cuz people want uh these systems to be supportive um to be helpful with their with with their ideas and their brainstorming. So, you've got to get that balance right. And I think I think we are we're sort of developing a science of of personality and persona of like how to to to kind of measure what it's doing and where do we want it to be like on authenticity on humor you know these sorts of things. And then you can imagine there's a kind of base personality that it ships with.

And then everyone has their own preferences. You know do you want it to be more humorous less humorous or or more succinct or more verbose? People like different things. So you add that additional personalization layer on it as well.

But there's still the core base personality that everyone gets, right? Which is trying to try and adhere to the scientific method, which is the whole point of these. And we want people to use these for science and for medicine and health issues and so on. Uh and so um I think it's it's it's part of the science of getting these uh large language models right.

And um I'm I'm quite happy with the direction we're going in currently. uh we got to talk to Shane Le a couple weeks ago um about uh AGI in in particular across everything that's happening in in AI at the moment the language models the world models you know and so on what's closest to your vision of AGI I think actually the combination of obviously there's Gemini 3 which I think is very capable but the Nano Banana Pro system we also launched last week which is an advanced version of our image creation tool what's really amazing about that it has also Gemini under the hood. So, it can understand not just images, it sort of understands uh what's going on semantically in those images. Uh and people have been only playing with it for a week now, but I've seen so much cool stuff on on social media about uh what people are using it for.

So for example um you know you can give it a picture of a of of a of a complex plane or something like that and it can label all the diagrams of uh you know all the different parts of the plane and even visualize it in in a for like with all the different parts sort of exposed. Um so it has some kind of deep understanding of mechanics and and what make what you know makes up parts of objects what's materials. So it's a sort of um and it can you know render text really really uh accurately now. So I think that's sort of um it's getting towards a kind of AGI for imaging.

Um I think it's uh a kind of general purpose system that can do anything across images. So I think that's very exciting. And then the advances in in world models, you know, Genie and Simma and what we're doing there. And then eventually we got to kind of converge all of those different they're kind of different projects at the moment and they're they're they're intertwined but we need to you know converge them all into one one big model and then that might be start becoming you know candidate for protoagi.

I know you've been reading quite a lot about the industrial revolution recently. Um, are there things that we can learn from what happened there to try and mitigate against the the sort of some of the disruption that that we can expect AGI comes? I think there's a lot we can learn. It's it's something you sort of study in school at least in the in in Britain, but but on a very superficial level like it was really interesting for me to look into how it how it all happened, what it started with, the reasons behind the economic reasons behind that which is like the textile industry and then the first computers were really the sewing machines, right?

And then they became punch cards for the early forran computers, mainframes. And for a while it was very successful in Britain became like the center of the the textile world because they could make these amazingly high quality things for very cheap uh because of the automated systems. Um and then obviously the steam engines and all of those things came in. I think there's a lot of um incredible advances that came out of industrial revolution.

So um child mortality went down and all of modern medicine uh and and um sanitary conditions, the kind of work life uh uh split and how that all worked was kind of worked out during the industrial revolution. But it also came with a lot of challenges like in it took quite a long time um roughly a century and um different parts of the labor force were dislocated at certain times and then new uh things had to be created new organizations like unions and other things had to be created in order to rebalance that. So like it was fascinating to see the whole of society sort of had to over time adapt and then you've got the modern world now. So there were I think there were lots of obviously pros and cons of the industrial revolution why it was happening but no one would want if you think about what it's done in total like abundance of you know people you know of food and in the western world and and modern medicine and all these things modern transport um that was all because of the industrial revolution.

So, we wouldn't want to go back to pre-industrial revolution, but maybe we can figure out ahead of time by learning from it what those dislocations were and maybe mitigate those um earlier or more effectively this time. And we're probably going to have to because the difference this time is that it's probably going to be 10 times bigger than industrial revolution and it'll probably happen 10 times faster. So, more like a decade then unfold over a decade than a century. One of the things that Shane told us was that that the kind of current economic system where you know you exchange your labor for resources effectively, it it just won't function the same way in a post AGI society.

Do you have a vision of of how society should be reconfigured or might be reconfigured in a way that works? Yeah, I'm spending more time thinking about this now and Shane's actually leading an effort here on that to sort of think about what a post AGI world might look like and what we need to prepare for. But I think society in general needs to spend more time thinking about that. Economists and social scientists and governments because I I I as with the industrial revolution you know the whole working world and working week and everything got changed from from pre-industrial revolution war agriculture and I think that's going to at least that level of change is going to happen again.

So it's not surprising. I don't would not be surprised if we needed new economic systems, new economic models to uh to basically um help with that transformation and make sure for example the benefits are widely um distributed and maybe things like universal basic income and things like that are part of the solution. But I don't think that's the complete uh I think that's just what we can model out now, right? Because that would be a almost an add-on to what we have today.

But I think there might be something way better systems where um more like direct democracy type systems where you can you know vote with a certain amount of of credits or something for what you want to see. It happens actually on local uh community level. You know here's a bunch of money. Do you want a playground or a tennis court or an extra classroom on the school?

And then you let the community um sort of vote for it, right? So, and then and then maybe you could even measure the outcomes and then and then the people that sort of consistently vote for the for for things that that end up being um more wellreceived, they they have proportionally more influence for the next vote. So, there's there's a lot of interesting things I hear, you know, economist friends of mine who are are kind of brainstorming this and I think that would be great if we had a lot more work on that. And then there's the philosophical side of it of like okay so jobs will change and other things like that but then um but maybe we'll have fusion will have been solved and so we have this sort of abundant free energy so we're post scarcity so what happens to money um maybe everyone's better off but then what happens to purpose right because a lot of people get their purpose from you know their jobs and then providing for their families uh which is a very noble purpose so if that's you know so there's a lot of I I think some of these questions blend from economic questions into almost philosophical questions.

Do you do you worry that people don't seem to be paying attention sort of or moving as quickly as you'd like to see? What would it take for for people to sort of recognize that we need international collaboration on this? I am worried about that and I wish that and and again in a sort of ideal world there would have been a lot more collaboration already and international specifically uh and a lot more research and and sort of um I guess exploration and discussion going on about these topics. I'm actually pretty surprised there isn't more of that being discussed given that you know even our timelines which were there are some very short timelines out there but even ours are 5 to 10 years which is not long for for for for institutions or things like that to be built to to handle this.

Um and one of the worries I have is that the institutions that do exist they you know seem to be very fragmented and not very influential to to the level that you would need. Um, so it may be that that that that there are there aren't the right institutions to deal with this currently. And then of course if you add in the geopolitical tensions that are going on at the moment around the world, it seems like collaboration, cooperation is harder than ever. Um, just look at climate change and and um how hard it is to get any agreement on anything to do with that.

So um so we'll see. I think as the stakes get higher and as these systems get more powerful and maybe this is one of the benefits of them being in products is uh the the you know everyday uh person that's not working on this technology will get to feel the increase in the power of these things and the capability and so that will then reach government and then maybe um uh they'll see sense as we get closer to to AGI. Do you think it will take a moment an incident for everyone to sort of sit up and pay attention? I don't know.

I mean, I hope not. Most of the main labs are pretty pretty responsible. We try to be as responsible as possible. You know, that's always something we've, as you know, if you followed us over the years, that's been at the heart of what everything we do.

Doesn't mean we'll get everything right, but we try to be as thoughtful and as scientific in our approach as possible. Um, I think most of the major labs are are trying to be responsible. Also, there's good commercial pressure actually to be responsible. If you think about agents, uh, and you're renting an agent to another company, let's say, to do something, um, that other company is going to want to know what the limits are and the boundaries are and the guardrails are on those agents, you know, in terms of what they might do and not just mess up the data and all of this stuff.

So, I think that's good because the pe the more kind of carboy operations, they won't um get the business because the enterprises won't choose them. So I think the kind of capitalist system will actually be useful here to reinforce responsible behavior which is good but then there will be rogue actors um maybe rogue nations maybe rogue organizations um maybe people building on top of open source I don't know like obviously it's very difficult to stop that then um something may go wrong and uh hopefully it's just sort of medium-sized and then that will be a kind of warning shot to to to humanity across the bow and then that might be the moment to kind of um advocate for uh international uh standards or international cooperation or collaboration at least on some the high level basic or you know kind of like what's the basic standards we we we would want and and and agree to I'm hopeful that that will be possible in the long term so beyond AGI and and towards ASI right artificial super intelligence do you think that there are some things that that humans can do that machines will ever be able to manage? Well, I think that's the big question and I feel like this is related to as you know, one of my favorite topics is cheuring machines. I've always felt this that if we build a GI and then use that as a simulation of the mind and then compare that to the real mind, we will then see what the differences are and uh potentially what's special um and remaining about the human mind, right?

Maybe that's creativity, maybe it's emotions, maybe it's dreaming. There's a lot of consciousness. There's a lot of um hypotheses out there about what may or may not be computable. And this comes back to the chewing machine question of like what is the limit of a chewing machine?

And I think that's the central question of my life really ever since I found out about chewing and chewing machines. And um you know I think that's that's I fell in love with that. That's my core passion. And I think um everything we've been doing is been sort of pushing the notion of what a cheuring machine can do to the limit including you know folding proteins right and so it turns out I'm not sure what the limit is maybe there isn't one right and of course the my quantum computing friends would would say there are limits and and you need quantum computers to do quantum systems but I'm really not so sure and I've actually you know discussed that with some some some of the quantum folks and it may that we need data from these quantum systems in order to create a classical simulation.

Um and then that that comes back to the mind which is is it all classical computation or is there something else going on you know like Roger Penrose believes you know there's quantum effects in the brain. If there are then and that's what consciousness is do with then machines will never have that at least the the the classical machines we'll have to wait for quantum computers. Um but if they if there isn't then there may not be any limit maybe in the universe everything is computationally tractable and therefore if you look at it in the right way and therefore chewing machines might be able to model everything in the universe I I'm currently if you were to get make me guess I would guess that and I'm working on that basis until physics um shows me otherwise so there's nothing that cannot be done within these sort of computational well no one's put it this way nobody's found anything in the universe that's that's non-computable So far so far, right? And I think we've already shown you can go way beyond the the usual complexity theorist P= MP view of like what a classical computer could do today.

Things like protein folding and go and so on. So I don't think anyone knows what that limit is. And that's really if you boil down to what we're doing at Deep Mind and Google and what I'm trying to do is is find that limit. But then in the limit of that though, right, is that in the limit of that idea is that, you know, we're sitting here sort of there's like the warmth of the lights on our face.

We kind of hear the wear of the machine in the background. There's like the feel of the desk under our hands. All of that could be replicable by a classical computer. Yes.

Well, I think in the end, my view on this is why I love K as well is all all of all all of my two favorite philosophy is a construct of the mind. I think that's true. And so, yes, all of those things you mentioned, they're coming into our sensory apparatus and they feel different, right? The light, the warmth of the light, the feel, the touch of the table, but in the end, they're it's all information.

And we're information processing systems. And I think that's what biology is. This is what we're trying to do with isomeorphic. That's how I think we'll end up curing all diseases is by thinking about biology um as an information processing system.

And I think in the end that's going to be and I'm working on my spare time, my 2 minutes of spare time, you know, physics theories about uh things like information being the most fundamental unit, should we say, of the universe, not energy, not matter, but information. And um so it may be that these are all interchangeable in the end, right? But we just sense it. We feel it in a different way.

Um but you know, as far as we know, this is still all these amazing sensors that we have, they're still computable by a chewing machine. But this is why your simulated world is so important, right? Yes. Exactly.

Because that would be the way to get one of the ways to get to it. What's the limits of what we can simulate? Because if you can simulate it, then in some sense, you've understood it. I wanted to to finish with some personal reflections of of what it's like to be at the forefront of this.

I mean, does the emotional weight of this ever sort of weigh you down? Does it ever feel quite isolating? Yes. Um, look, I I don't sleep very much, partly because it's too much work, but also I have trouble sleeping.

It's very complex emotions to deal with because it's unbelievably exciting. Um, you know, I'm I'm basically doing everything I ever dreamed of. And we're at the absolute frontier of science on in so many ways, um, applied science as well as machine learning. And that's exhilarating as all scientists know that that feeling of being at the frontier and discovering something for the first time.

And that's happening almost on a monthly basis for us. So, which is amazing. Um, but then of course we as as and Shane and I and others who've been doing this for a long time, we understand it better than anybody. Um, the enormity of what's coming and this thing about is still under actually appreciated.

In fact, what's going to happen in more of a 10-year time scale. Um, including to things like the the phil philosophical uh, you know, what it means to be human, what's important about that? all of these questions are going to come up. Um, and so it's it's it's a big responsibility.

Um, but we have an amazing team thinking about these things. Um, but also it's something I guess at least myself I've trained for my whole life. So, you know, ever since my early days playing chess and and then working on computers and games and simulations and neuroscience, it's all been for uh this kind of moment. Um, and it's roughly what I imagined it was going to be.

So, that's partly how I cope with it is just training. Are there parts of it that have hit you harder than you expected though? Uh, yes, for sure. On the way, I mean, even the Alpha Go match, right?

Just seeing you know that how we managed to to crack Go, but Go was this beautiful mystery and it changed it. And so, that was that was interesting and kind of bittersweet. I think even the the more recent things of like language and then imaging and you know what does it mean for creativity uh I I'm you know have huge respect and passion for the creative arts and having done game design myself and you know I talked to film directors and it's it's an interesting dual moment for them too. There's like first on one hand they've got these amazing tools that speed up prototyping ideas by 10x but on the other hand um is it replacing certain creative skills?

So I think there's there's sort of these trade-offs going on um all over the place which um I think is inevitable with something as uh a technology as powerful and as transformative as as AI is as in the past electricity was and internet and we've you know we've seen that that is the story of humanity is we are tool making uh animals and that's what we love to do and for some reason we also have a brain that can can understand science and do science which is amazing. but also sort of insatiably curious. I think that's the heart of what it means to be human. And I think I've just had that bug from the beginning.

And my expression of trying to answer that is is to build AI. When [snorts] you and the other AI leaders are in a room together, is there sort of sense of solidarity between you that that this is a group of people who all know the stakes, who all really understand their things, or or does the competition kind of keep you apart from one another? Well, we all Yeah, we all know each other. I get on with pretty much all of them.

Some of the others don't get on with each other. Uh and there is it's hard because that we're also in the most ferocious uh uh capitalist sort of competition there's ever been probably. You know, investor friends of mine and VC friends of mine who who who were around in the dotcom era say this is like 10x more ferocious and intense than that was. In many ways, I love that.

I mean, I I live for competition. It's it's it's it's you know I've always loved that since my chess days but stepping back uh I understand I hope everyone understands that there's a much bigger thing at stake than just you know company successes and and and you know that type of thing when it comes to the next decade when you think about it are there big moments coming up that you're personally most apprehensive about I think right now the systems are you know I I call them passive systems you you put the energy in as the user you know the question or the what's the task and then they uh these systems kind of provide you with some summary or some answer. Um so very much it's it's human directed and human energy going in uh and human ideas going in. The next stage is agent-based systems, which I think we're going to start seeing.

We're seeing now, but they're pretty primitive. Like in the next couple of years, I think we'll start seeing some really impressive reliable ones. And um I think those will be incredibly useful and capable if you think about them as an assistant or something like that, but also they'll be more autonomous. So I think the risks go up as well uh with those types of systems.

So I'm I'm quite worried about uh what those sorts of systems will be able to do maybe in two, three years time, you know. So, we're working on cyber defense in preparation for uh a world like that where maybe there's millions of agents, you know, roaming around on the internet. And what about what you're most looking forward to? I mean, is there is there a day when you'll be able to retire sort of knowing that your work is done or or is there more than a lifetime's worth of work left to do?

Yeah, I always Well, I I could definitely do with sabbatical [snorts] um and I would spend it doing stuff. Yeah, a week off for even even a day would be good. Um, but look, I think my mission has always been to get to kind of help uh the world steward AGI safely over the line for all of humanity. So, I think when we get to that point, of course, there's then there's super intelligence and there's post AGI and there's all the economic stuff we were discussing and societal stuff and maybe I can help in some way there.

But I think um that will be my core part of my mission, my life mission uh will be done if it's a I mean it's only a small job, you know, just get that over the line or help the world get that over the line. You know, I think it's going to require collaboration like we talked earlier. Um and I'm quite a collaborative person. So I hope I can I can help with that from the position that I have.

And then you get to have a holiday and then I'll get I'll have the Yeah, exactly. a well- earned sbatical. Yeah, absolutely. [laughter] Deis, thank you so much.

helpful as always. Well, that is it for this season of Goo Deep [music] Mind the podcast with me, Professor Hannah Fry. But be sure to subscribe so you will be among the first to hear about our return in 2026. And in the meantime, why not revisit our vast episode library because we have covered so much this year.

From driverless cars to robotics, world models to drug discovery. Plenty to keep you occupied. See you soon.
